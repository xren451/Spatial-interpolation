{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T04:04:44.315272Z",
     "start_time": "2024-07-30T04:04:44.311201Z"
    }
   },
   "source": [
    "###############\n",
    "##Version 1:One \n",
    "###############"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:04:45.921754Z",
     "start_time": "2024-07-30T04:04:44.316863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import six.moves.cPickle as pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Correct file path\n",
    "# file_path = '/home/xren451/rxb/phd/Spatial_interpolation/XBSPA/ModIGNNK/data/NDBC/all.npy'\n",
    "file_path = 'data/NDBC/all.npy'\n",
    "station_value = np.load(file_path)\n",
    "station_value=station_value.transpose(2,0,1)\n",
    "lat_file_path = 'data/NDBC/Station_info_edit.csv'\n",
    "station_info=np.array(pd.read_csv(lat_file_path,header=None))\n",
    "station_value = station_value[:, :, 5:13]\n",
    "station_value=torch.tensor(station_value)"
   ],
   "id": "8707d0e087936f8b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:04:59.460576Z",
     "start_time": "2024-07-30T04:04:45.925158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MOESTKF_functions import Toy_generation, get_complete_stations, Feature_wise_Subgraph\n",
    "complete_stations, complete_indices = get_complete_stations(station_info, station_value)\n",
    "K = 5\n",
    "subgraph_matrix = Feature_wise_Subgraph(station_info, station_value, complete_stations, complete_indices, K)#Subgraph Matrix: (16, 8)\n",
    "\n",
    "print(\"Feature-wise Subgraph Matrix:\")\n",
    "print(subgraph_matrix.shape)#Feature-wise Subgraph Matrix: (16, 8)\n",
    "\n",
    "# Initialize the new matrix with the desired shape\n",
    "complete_sub_matrix = np.empty((subgraph_matrix.shape[0], subgraph_matrix.shape[1], 6), dtype=object)\n",
    "\n",
    "# Fill the new matrix\n",
    "for i, complete_station in enumerate(complete_stations):\n",
    "    for j in range(subgraph_matrix.shape[1]):\n",
    "        complete_sub_matrix[i, j] = np.insert(subgraph_matrix[i, j], 0, complete_station)\n",
    "\n",
    "# Example output for verification\n",
    "print(\"Complete_Sub_matrix.shape\",complete_sub_matrix.shape)"
   ],
   "id": "6147d2c3634d1067",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-wise Subgraph Matrix:\n",
      "(35, 8)\n",
      "Complete_Sub_matrix.shape (35, 8, 6)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:04:59.464943Z",
     "start_time": "2024-07-30T04:04:59.461392Z"
    }
   },
   "cell_type": "code",
   "source": "complete_sub_matrix[:,0,:]",
   "id": "e6b8d522822f293e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['41012', '41008', 'fwyf1', '41013', '42036', '41047'],\n",
       "       ['41013', '41037', '41038', 'clkn7', '41024', '41008'],\n",
       "       ['41043', '41046', '42060', '41044', '41052', '42059'],\n",
       "       ['41047', 'fwyf1', '41049', '41046', '41012', '41048'],\n",
       "       ['41048', '41049', '41047', '41008', '41013', 'fwyf1'],\n",
       "       ['41049', '41047', '41048', '41044', '41046', 'fwyf1'],\n",
       "       ['42002', '42020', '42035', '42001', '42055', 'fwyf1'],\n",
       "       ['42012', 'dpia1', '42040', '42036', 'cdrf1', '41008'],\n",
       "       ['42020', 'babt2', '42035', '42002', '42055', '46047'],\n",
       "       ['42035', '42020', '42040', '42002', '42001', '42012'],\n",
       "       ['42036', 'cdrf1', '42012', '42040', 'dpia1', '41008'],\n",
       "       ['42040', '42012', '42036', 'dpia1', '42001', 'cdrf1'],\n",
       "       ['42055', '42001', '42002', '42020', '42057', '42035'],\n",
       "       ['42057', '42055', 'mlrf1', '42001', '42058', '41052'],\n",
       "       ['42058', '42059', '42060', '42057', '41043', '42001'],\n",
       "       ['44008', '44020', '44025', 'buzm3', '44065', '44011'],\n",
       "       ['44020', 'buzm3', '44008', '44025', '44065', '44029'],\n",
       "       ['44025', '44065', '44009', '44008', '44020', 'buzm3'],\n",
       "       ['44065', '44025', '44009', '44008', '44020', 'buzm3'],\n",
       "       ['46011', '46076', '46028', '46042', '46013', '46054'],\n",
       "       ['46012', '46013', '46042', '46028', '46076', '46014'],\n",
       "       ['46027', '46014', 'desw1', '46013', '46041', '46088'],\n",
       "       ['46028', '46042', '46013', '46011', '46012', '46054'],\n",
       "       ['46029', '46089', '44011', '46050', '46041', 'desw1'],\n",
       "       ['46042', '46013', '46028', '46012', '46014', '46011'],\n",
       "       ['46047', '46069', '46076', '44030', '46054', '46012'],\n",
       "       ['46050', '46089', '46029', '46041', 'desw1', '46088'],\n",
       "       ['46053', '46086', '46054', '46011', '46042', '46028'],\n",
       "       ['46069', '46047', '46076', '46012', '41047', '46054'],\n",
       "       ['46076', '46011', '46069', '46047', '46012', '46028'],\n",
       "       ['46086', '46053', '46011', '46047', '46054', '46042'],\n",
       "       ['46088', '46041', 'desw1', '46089', '46027', '46014'],\n",
       "       ['46089', '46029', '46041', '46050', 'desw1', '46088'],\n",
       "       ['51000', '51101', '51002', '44033', '44032', 'disw3'],\n",
       "       ['51101', '51000', '51002', 'caro3', 'disw3', 'mlww3']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:04:59.480767Z",
     "start_time": "2024-07-30T04:04:59.465660Z"
    }
   },
   "cell_type": "code",
   "source": "station_value.shape",
   "id": "ba0aa8ced9b6dfa4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 8784, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:06:20.030313Z",
     "start_time": "2024-07-30T04:05:10.025504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate station locations\n",
    "np.random.seed(42)\n",
    "num_stations = 10\n",
    "station_coords = np.random.rand(num_stations, 2)\n",
    "\n",
    "# Temperature data for one year (one data point per hour, 24 hours * 365 days)\n",
    "time_steps = 24 * 365\n",
    "temperature_data = np.random.rand(num_stations, time_steps) * 30  # Temperature range 0 to 30 degrees\n",
    "\n",
    "# Min-Max normalization for each station's temperature series\n",
    "min_temp = np.min(temperature_data, axis=1).reshape(-1, 1)\n",
    "max_temp = np.max(temperature_data, axis=1).reshape(-1, 1)\n",
    "temperature_data_normalized = (temperature_data - min_temp) / (max_temp - min_temp)\n",
    "\n",
    "# Generate interpolation point location and true temperature values\n",
    "interpolation_point = np.random.rand(1, 2)\n",
    "true_interpolation_temp = np.random.rand(time_steps) * 30  # Assume true temperature range is also 0 to 30 degrees\n",
    "\n",
    "# Normalize true_interpolation_temp\n",
    "true_min_temp = np.min(true_interpolation_temp)\n",
    "true_max_temp = np.max(true_interpolation_temp)\n",
    "true_interpolation_temp_normalized = (true_interpolation_temp - true_min_temp) / (true_max_temp - true_min_temp)\n",
    "\n",
    "# Define two subgraphs\n",
    "subgraph_1 = [0, 1, 2, 3, 4]\n",
    "subgraph_2 = [5, 6, 7, 8, 9]\n",
    "\n",
    "# Inverse Distance Weighting (IDW) interpolation\n",
    "def idw_interpolation(station_coords, temperatures, target_point, power=2):\n",
    "    distances = np.linalg.norm(station_coords - target_point, axis=1)\n",
    "    weights = 1 / (distances ** power)\n",
    "    weights /= weights.sum()\n",
    "    interpolated_value = np.dot(weights, temperatures)\n",
    "    return interpolated_value\n",
    "\n",
    "# Apply IDW interpolation to the two subgraphs\n",
    "idw_estimate_1 = np.array([idw_interpolation(station_coords[subgraph_1], temperature_data_normalized[subgraph_1, t], interpolation_point) for t in range(time_steps)])\n",
    "idw_estimate_2 = np.array([idw_interpolation(station_coords[subgraph_2], temperature_data_normalized[subgraph_2, t], interpolation_point) for t in range(time_steps)])\n",
    "\n",
    "# Define GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, adj):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def calculate_inverse_distance_adj(station_coords, decay):\n",
    "    num_nodes = station_coords.shape[0]\n",
    "    adj = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                distance = np.linalg.norm(station_coords[i] - station_coords[j])\n",
    "                adj[i, j] = np.exp(-decay * distance)\n",
    "    return torch.tensor(adj, dtype=torch.float)\n",
    "\n",
    "def prepare_data(subgraph, temperature_data, idw_estimate, decay):\n",
    "    edge_index = torch.tensor([[i, j] for i in range(len(subgraph)) for j in range(len(subgraph))], dtype=torch.long).t().contiguous()\n",
    "    adj = calculate_inverse_distance_adj(station_coords[subgraph], decay)\n",
    "    x = torch.tensor(temperature_data[subgraph], dtype=torch.float).t()\n",
    "    y = torch.tensor(idw_estimate, dtype=torch.float).t()\n",
    "    data = Data(x=x, edge_index=edge_index, y=y, adj=adj)\n",
    "    return data\n",
    "\n",
    "# Initialize models\n",
    "def initialize_models(hidden_dim):\n",
    "    model_1 = GCNModel(num_features=len(subgraph_1), hidden_dim=hidden_dim, output_dim=1)\n",
    "    model_2 = GCNModel(num_features=len(subgraph_2), hidden_dim=hidden_dim, output_dim=1)\n",
    "    return model_1, model_2\n",
    "\n",
    "# Define MoE model\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self, gcn1, gcn2, hidden_dim):\n",
    "        super(MoEModel, self).__init__()\n",
    "        self.gcn1 = gcn1\n",
    "        self.gcn2 = gcn2\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, edge_index1, adj1, x2, edge_index2, adj2):\n",
    "        out1 = self.gcn1(x1, edge_index1, adj1).view(-1, 1)\n",
    "        out2 = self.gcn2(x2, edge_index2, adj2).view(-1, 1)\n",
    "        gate_input = torch.cat([out1, out2], dim=1)\n",
    "        gate_output = self.gate(gate_input)\n",
    "        out = gate_output[:, 0].unsqueeze(1) * out1 + gate_output[:, 1].unsqueeze(1) * out2\n",
    "        return out\n",
    "\n",
    "# Train MoE model\n",
    "def train_model(moe_model, data_1, data_2, optimizer, criterion, num_epochs=200):\n",
    "    for epoch in range(num_epochs):\n",
    "        moe_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = moe_model(data_1.x, data_1.edge_index, data_1.adj, data_2.x, data_2.edge_index, data_2.adj)\n",
    "        \n",
    "        loss_1 = criterion(out.squeeze(), data_1.y)\n",
    "        loss_2 = criterion(out.squeeze(), data_2.y)\n",
    "        \n",
    "        total_loss = loss_1 + loss_2\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss_1: {loss_1.item()}, Loss_2: {loss_2.item()}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "# Predict temperature for the interpolation point\n",
    "def predict(moe_model, data_1, data_2):\n",
    "    moe_model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_temp = moe_model(data_1.x, data_1.edge_index, data_1.adj, data_2.x, data_2.edge_index, data_2.adj)\n",
    "    return predicted_temp.squeeze().numpy()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# MCMC for evaluating decay coefficients\n",
    "def mcmc_decay_selection(decay_coefficients, num_samples=100):\n",
    "    samples = []\n",
    "    current_decay = np.random.choice(decay_coefficients)\n",
    "    current_mse = evaluate_decay(current_decay)\n",
    "    samples.append((current_decay, current_mse))\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        proposed_decay = np.random.choice(decay_coefficients)\n",
    "        proposed_mse = evaluate_decay(proposed_decay)\n",
    "\n",
    "        acceptance_prob = min(1, np.exp(current_mse - proposed_mse))\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            current_decay = proposed_decay\n",
    "            current_mse = proposed_mse\n",
    "        \n",
    "        samples.append((current_decay, current_mse))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def evaluate_decay(decay):\n",
    "    hidden_dim = 16  # Define hidden_dim here\n",
    "    data_1 = prepare_data(subgraph_1, temperature_data_normalized, idw_estimate_1, decay)\n",
    "    data_2 = prepare_data(subgraph_2, temperature_data_normalized, idw_estimate_2, decay)\n",
    "    model_1, model_2 = initialize_models(hidden_dim)\n",
    "    moe_model = MoEModel(model_1, model_2, hidden_dim)\n",
    "    optimizer = optim.Adam(moe_model.parameters(), lr=0.01)\n",
    "    \n",
    "    train_model(moe_model, data_1, data_2, optimizer, criterion)\n",
    "    predicted_temp_normalized = predict(moe_model, data_1, data_2)\n",
    "    mse = mean_squared_error(true_interpolation_temp_normalized, predicted_temp_normalized)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Evaluate different decay coefficients using MCMC\n",
    "decay_coefficients = np.arange(0, 1.6, 0.1)\n",
    "samples = mcmc_decay_selection(decay_coefficients)\n",
    "best_sample = min(samples, key=lambda x: x[1])\n",
    "best_decay = best_sample[0]\n",
    "best_mse = best_sample[1]\n",
    "\n",
    "print(f'Best decay coefficient: {best_decay}, MSE: {best_mse}')\n"
   ],
   "id": "e6ec417b71dd30f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss_1: 0.028705375269055367, Loss_2: 0.025190144777297974, Total Loss: 0.05389551818370819\n",
      "Epoch 40/200, Loss_1: 0.015229105949401855, Loss_2: 0.01403720024973154, Total Loss: 0.02926630526781082\n",
      "Epoch 60/200, Loss_1: 0.01108667254447937, Loss_2: 0.015253136865794659, Total Loss: 0.026339810341596603\n",
      "Epoch 80/200, Loss_1: 0.012538804672658443, Loss_2: 0.012368292547762394, Total Loss: 0.024907097220420837\n",
      "Epoch 100/200, Loss_1: 0.012026399374008179, Loss_2: 0.012182282283902168, Total Loss: 0.024208681657910347\n",
      "Epoch 120/200, Loss_1: 0.012132907286286354, Loss_2: 0.011661911383271217, Total Loss: 0.02379481866955757\n",
      "Epoch 140/200, Loss_1: 0.011930824257433414, Loss_2: 0.011592824012041092, Total Loss: 0.023523647338151932\n",
      "Epoch 160/200, Loss_1: 0.011829941533505917, Loss_2: 0.011536753736436367, Total Loss: 0.023366695269942284\n",
      "Epoch 180/200, Loss_1: 0.011751854792237282, Loss_2: 0.011522194370627403, Total Loss: 0.023274049162864685\n",
      "Epoch 200/200, Loss_1: 0.011689988896250725, Loss_2: 0.011529052630066872, Total Loss: 0.023219041526317596\n",
      "Epoch 20/200, Loss_1: 0.046457745134830475, Loss_2: 0.01947863958775997, Total Loss: 0.0659363865852356\n",
      "Epoch 40/200, Loss_1: 0.02152927592396736, Loss_2: 0.013451079837977886, Total Loss: 0.03498035669326782\n",
      "Epoch 60/200, Loss_1: 0.014347829855978489, Loss_2: 0.013053643517196178, Total Loss: 0.027401473373174667\n",
      "Epoch 80/200, Loss_1: 0.011650169268250465, Loss_2: 0.013819189742207527, Total Loss: 0.025469359010457993\n",
      "Epoch 100/200, Loss_1: 0.011181386187672615, Loss_2: 0.01346119586378336, Total Loss: 0.02464258298277855\n",
      "Epoch 120/200, Loss_1: 0.011213256977498531, Loss_2: 0.012936345301568508, Total Loss: 0.02414960227906704\n",
      "Epoch 140/200, Loss_1: 0.011470782570540905, Loss_2: 0.012398379854857922, Total Loss: 0.023869162425398827\n",
      "Epoch 160/200, Loss_1: 0.011605815030634403, Loss_2: 0.012108244933187962, Total Loss: 0.023714059963822365\n",
      "Epoch 180/200, Loss_1: 0.011626116000115871, Loss_2: 0.011992501094937325, Total Loss: 0.02361861616373062\n",
      "Epoch 200/200, Loss_1: 0.011635445058345795, Loss_2: 0.011912656016647816, Total Loss: 0.023548100143671036\n",
      "Epoch 20/200, Loss_1: 0.03323744609951973, Loss_2: 0.030513111501932144, Total Loss: 0.06375055760145187\n",
      "Epoch 40/200, Loss_1: 0.026250621303915977, Loss_2: 0.019673626869916916, Total Loss: 0.045924246311187744\n",
      "Epoch 60/200, Loss_1: 0.015949729830026627, Loss_2: 0.01988690160214901, Total Loss: 0.03583662956953049\n",
      "Epoch 80/200, Loss_1: 0.012965847738087177, Loss_2: 0.018803328275680542, Total Loss: 0.031769175082445145\n",
      "Epoch 100/200, Loss_1: 0.011320140212774277, Loss_2: 0.0182054340839386, Total Loss: 0.029525574296712875\n",
      "Epoch 120/200, Loss_1: 0.0105241434648633, Loss_2: 0.017613818868994713, Total Loss: 0.028137963265180588\n",
      "Epoch 140/200, Loss_1: 0.010780956596136093, Loss_2: 0.016233354806900024, Total Loss: 0.027014311403036118\n",
      "Epoch 160/200, Loss_1: 0.011061979457736015, Loss_2: 0.014777989126741886, Total Loss: 0.025839969515800476\n",
      "Epoch 180/200, Loss_1: 0.011167846620082855, Loss_2: 0.013478915207087994, Total Loss: 0.024646762758493423\n",
      "Epoch 200/200, Loss_1: 0.01097885798662901, Loss_2: 0.012888425029814243, Total Loss: 0.023867283016443253\n",
      "Epoch 20/200, Loss_1: 0.038801614195108414, Loss_2: 0.018857445567846298, Total Loss: 0.05765905976295471\n",
      "Epoch 40/200, Loss_1: 0.02866513468325138, Loss_2: 0.012240546755492687, Total Loss: 0.040905680507421494\n",
      "Epoch 60/200, Loss_1: 0.024729730561375618, Loss_2: 0.008083618246018887, Total Loss: 0.03281334787607193\n",
      "Epoch 80/200, Loss_1: 0.019189313054084778, Loss_2: 0.00904296338558197, Total Loss: 0.028232276439666748\n",
      "Epoch 100/200, Loss_1: 0.013175809755921364, Loss_2: 0.012242382392287254, Total Loss: 0.025418192148208618\n",
      "Epoch 120/200, Loss_1: 0.01177271455526352, Loss_2: 0.012619590386748314, Total Loss: 0.024392304942011833\n",
      "Epoch 140/200, Loss_1: 0.011929573491215706, Loss_2: 0.012133403681218624, Total Loss: 0.024062976241111755\n",
      "Epoch 160/200, Loss_1: 0.011980834417045116, Loss_2: 0.011892580427229404, Total Loss: 0.02387341484427452\n",
      "Epoch 180/200, Loss_1: 0.012007303535938263, Loss_2: 0.01172979548573494, Total Loss: 0.023737099021673203\n",
      "Epoch 200/200, Loss_1: 0.011988680809736252, Loss_2: 0.01164317224174738, Total Loss: 0.023631852120161057\n",
      "Epoch 20/200, Loss_1: 0.02293856255710125, Loss_2: 0.02273908257484436, Total Loss: 0.04567764699459076\n",
      "Epoch 40/200, Loss_1: 0.022997405380010605, Loss_2: 0.0148514024913311, Total Loss: 0.037848807871341705\n",
      "Epoch 60/200, Loss_1: 0.018684586510062218, Loss_2: 0.013471276499330997, Total Loss: 0.03215586394071579\n",
      "Epoch 80/200, Loss_1: 0.01615370251238346, Loss_2: 0.012762613594532013, Total Loss: 0.028916316106915474\n",
      "Epoch 100/200, Loss_1: 0.014709589071571827, Loss_2: 0.012488828040659428, Total Loss: 0.027198417112231255\n",
      "Epoch 120/200, Loss_1: 0.013721424154937267, Loss_2: 0.012301352806389332, Total Loss: 0.0260227769613266\n",
      "Epoch 140/200, Loss_1: 0.013058610260486603, Loss_2: 0.012072701007127762, Total Loss: 0.025131311267614365\n",
      "Epoch 160/200, Loss_1: 0.013271935284137726, Loss_2: 0.011022963561117649, Total Loss: 0.0242948979139328\n",
      "Epoch 180/200, Loss_1: 0.013111253269016743, Loss_2: 0.010699715465307236, Total Loss: 0.023810967803001404\n",
      "Epoch 200/200, Loss_1: 0.012445234693586826, Loss_2: 0.011110275983810425, Total Loss: 0.023555509746074677\n",
      "Epoch 20/200, Loss_1: 0.026082832366228104, Loss_2: 0.014821167103946209, Total Loss: 0.04090400040149689\n",
      "Epoch 40/200, Loss_1: 0.013934286311268806, Loss_2: 0.013153071515262127, Total Loss: 0.02708735689520836\n",
      "Epoch 60/200, Loss_1: 0.011371864005923271, Loss_2: 0.013437903486192226, Total Loss: 0.024809766560792923\n",
      "Epoch 80/200, Loss_1: 0.012221168726682663, Loss_2: 0.011598867364227772, Total Loss: 0.02382003515958786\n",
      "Epoch 100/200, Loss_1: 0.0117038544267416, Loss_2: 0.011835822835564613, Total Loss: 0.023539677262306213\n",
      "Epoch 120/200, Loss_1: 0.011643638834357262, Loss_2: 0.01174500584602356, Total Loss: 0.02338864468038082\n",
      "Epoch 140/200, Loss_1: 0.01156242098659277, Loss_2: 0.01171774324029684, Total Loss: 0.02328016422688961\n",
      "Epoch 160/200, Loss_1: 0.011531462892889977, Loss_2: 0.011668526567518711, Total Loss: 0.023199990391731262\n",
      "Epoch 180/200, Loss_1: 0.011494925245642662, Loss_2: 0.011644111014902592, Total Loss: 0.02313903719186783\n",
      "Epoch 200/200, Loss_1: 0.011475283652544022, Loss_2: 0.011618487536907196, Total Loss: 0.023093771189451218\n",
      "Epoch 20/200, Loss_1: 0.014015481807291508, Loss_2: 0.011402917094528675, Total Loss: 0.025418398901820183\n",
      "Epoch 40/200, Loss_1: 0.011643165722489357, Loss_2: 0.012039652094244957, Total Loss: 0.023682817816734314\n",
      "Epoch 60/200, Loss_1: 0.011605366133153439, Loss_2: 0.011727478355169296, Total Loss: 0.02333284541964531\n",
      "Epoch 80/200, Loss_1: 0.011643647216260433, Loss_2: 0.011555342935025692, Total Loss: 0.023198990151286125\n",
      "Epoch 100/200, Loss_1: 0.011577953584492207, Loss_2: 0.01152931246906519, Total Loss: 0.023107266053557396\n",
      "Epoch 120/200, Loss_1: 0.011522692628204823, Loss_2: 0.011519095860421658, Total Loss: 0.02304178848862648\n",
      "Epoch 140/200, Loss_1: 0.011494830250740051, Loss_2: 0.011507409624755383, Total Loss: 0.02300224080681801\n",
      "Epoch 160/200, Loss_1: 0.011485625058412552, Loss_2: 0.011489814147353172, Total Loss: 0.022975439205765724\n",
      "Epoch 180/200, Loss_1: 0.011471807025372982, Loss_2: 0.011485389433801174, Total Loss: 0.022957196459174156\n",
      "Epoch 200/200, Loss_1: 0.011465391144156456, Loss_2: 0.011479277163743973, Total Loss: 0.02294466830790043\n",
      "Epoch 20/200, Loss_1: 0.017585070803761482, Loss_2: 0.02165229246020317, Total Loss: 0.0392373651266098\n",
      "Epoch 40/200, Loss_1: 0.011756564490497112, Loss_2: 0.01824791356921196, Total Loss: 0.030004478991031647\n",
      "Epoch 60/200, Loss_1: 0.0106674088165164, Loss_2: 0.016218431293964386, Total Loss: 0.02688584104180336\n",
      "Epoch 80/200, Loss_1: 0.01131101418286562, Loss_2: 0.01390662882477045, Total Loss: 0.02521764300763607\n",
      "Epoch 100/200, Loss_1: 0.011845557950437069, Loss_2: 0.012302964925765991, Total Loss: 0.024148523807525635\n",
      "Epoch 120/200, Loss_1: 0.012103352695703506, Loss_2: 0.01159575954079628, Total Loss: 0.023699112236499786\n",
      "Epoch 140/200, Loss_1: 0.011806221678853035, Loss_2: 0.011679504066705704, Total Loss: 0.02348572574555874\n",
      "Epoch 160/200, Loss_1: 0.011645112186670303, Loss_2: 0.011715126223862171, Total Loss: 0.0233602374792099\n",
      "Epoch 180/200, Loss_1: 0.011612915433943272, Loss_2: 0.011661711148917675, Total Loss: 0.023274626582860947\n",
      "Epoch 200/200, Loss_1: 0.011576775461435318, Loss_2: 0.011635989882051945, Total Loss: 0.023212764412164688\n",
      "Epoch 20/200, Loss_1: 0.030805910006165504, Loss_2: 0.02038310281932354, Total Loss: 0.051189012825489044\n",
      "Epoch 40/200, Loss_1: 0.019348394125699997, Loss_2: 0.013472680002450943, Total Loss: 0.03282107412815094\n",
      "Epoch 60/200, Loss_1: 0.017467619851231575, Loss_2: 0.010996423661708832, Total Loss: 0.028464043512940407\n",
      "Epoch 80/200, Loss_1: 0.011119445785880089, Loss_2: 0.013954698108136654, Total Loss: 0.025074142962694168\n",
      "Epoch 100/200, Loss_1: 0.010912778787314892, Loss_2: 0.013220453634858131, Total Loss: 0.02413323149085045\n",
      "Epoch 120/200, Loss_1: 0.011373481713235378, Loss_2: 0.012325516901910305, Total Loss: 0.023698998615145683\n",
      "Epoch 140/200, Loss_1: 0.011417577043175697, Loss_2: 0.012102988548576832, Total Loss: 0.023520566523075104\n",
      "Epoch 160/200, Loss_1: 0.011527180671691895, Loss_2: 0.011910246685147285, Total Loss: 0.02343742735683918\n",
      "Epoch 180/200, Loss_1: 0.011518025770783424, Loss_2: 0.011853301897644997, Total Loss: 0.02337132766842842\n",
      "Epoch 200/200, Loss_1: 0.011503374204039574, Loss_2: 0.01180995162576437, Total Loss: 0.02331332489848137\n",
      "Epoch 20/200, Loss_1: 0.017934570088982582, Loss_2: 0.030341729521751404, Total Loss: 0.04827629774808884\n",
      "Epoch 40/200, Loss_1: 0.019397463649511337, Loss_2: 0.023234419524669647, Total Loss: 0.042631883174180984\n",
      "Epoch 60/200, Loss_1: 0.01707669533789158, Loss_2: 0.019152048975229263, Total Loss: 0.03622874617576599\n",
      "Epoch 80/200, Loss_1: 0.016858527436852455, Loss_2: 0.015294035896658897, Total Loss: 0.03215256333351135\n",
      "Epoch 100/200, Loss_1: 0.01708572916686535, Loss_2: 0.012389862909913063, Total Loss: 0.029475592076778412\n",
      "Epoch 120/200, Loss_1: 0.01660744845867157, Loss_2: 0.011042829602956772, Total Loss: 0.02765027806162834\n",
      "Epoch 140/200, Loss_1: 0.015619798563420773, Loss_2: 0.010664274916052818, Total Loss: 0.026284072548151016\n",
      "Epoch 160/200, Loss_1: 0.014441278763115406, Loss_2: 0.010798251256346703, Total Loss: 0.025239530950784683\n",
      "Epoch 180/200, Loss_1: 0.013440355658531189, Loss_2: 0.011048239655792713, Total Loss: 0.024488594383001328\n",
      "Epoch 200/200, Loss_1: 0.012722484767436981, Loss_2: 0.011276149190962315, Total Loss: 0.02399863302707672\n",
      "Epoch 20/200, Loss_1: 0.015488320961594582, Loss_2: 0.012108725495636463, Total Loss: 0.02759704738855362\n",
      "Epoch 40/200, Loss_1: 0.011918583884835243, Loss_2: 0.01240827701985836, Total Loss: 0.024326860904693604\n",
      "Epoch 60/200, Loss_1: 0.011925196275115013, Loss_2: 0.011610752902925014, Total Loss: 0.023535948246717453\n",
      "Epoch 80/200, Loss_1: 0.011833876371383667, Loss_2: 0.011516505852341652, Total Loss: 0.02335038222372532\n",
      "Epoch 100/200, Loss_1: 0.01163533702492714, Loss_2: 0.011611002497375011, Total Loss: 0.023246340453624725\n",
      "Epoch 120/200, Loss_1: 0.011635948903858662, Loss_2: 0.01154540665447712, Total Loss: 0.023181356489658356\n",
      "Epoch 140/200, Loss_1: 0.011584627442061901, Loss_2: 0.011551341973245144, Total Loss: 0.023135969415307045\n",
      "Epoch 160/200, Loss_1: 0.011554955504834652, Loss_2: 0.011545895598828793, Total Loss: 0.023100851103663445\n",
      "Epoch 180/200, Loss_1: 0.011534171178936958, Loss_2: 0.01154045108705759, Total Loss: 0.023074623197317123\n",
      "Epoch 200/200, Loss_1: 0.01152381394058466, Loss_2: 0.011530790477991104, Total Loss: 0.02305460348725319\n",
      "Epoch 20/200, Loss_1: 0.03759974241256714, Loss_2: 0.02479545958340168, Total Loss: 0.06239520013332367\n",
      "Epoch 40/200, Loss_1: 0.02237856388092041, Loss_2: 0.010485942475497723, Total Loss: 0.03286450728774071\n",
      "Epoch 60/200, Loss_1: 0.01792874187231064, Loss_2: 0.01032944954931736, Total Loss: 0.028258191421628\n",
      "Epoch 80/200, Loss_1: 0.015259345062077045, Loss_2: 0.010737785138189793, Total Loss: 0.025997130200266838\n",
      "Epoch 100/200, Loss_1: 0.013255493715405464, Loss_2: 0.011313517577946186, Total Loss: 0.024569012224674225\n",
      "Epoch 120/200, Loss_1: 0.0123061528429389, Loss_2: 0.011535384692251682, Total Loss: 0.023841537535190582\n",
      "Epoch 140/200, Loss_1: 0.011890716850757599, Loss_2: 0.011670144274830818, Total Loss: 0.023560861125588417\n",
      "Epoch 160/200, Loss_1: 0.011777669191360474, Loss_2: 0.011667267419397831, Total Loss: 0.02344493567943573\n",
      "Epoch 180/200, Loss_1: 0.011712821200489998, Loss_2: 0.011660713702440262, Total Loss: 0.02337353490293026\n",
      "Epoch 200/200, Loss_1: 0.011674427427351475, Loss_2: 0.011646706610918045, Total Loss: 0.023321133106946945\n",
      "Epoch 20/200, Loss_1: 0.02901703119277954, Loss_2: 0.011107902973890305, Total Loss: 0.040124934166669846\n",
      "Epoch 40/200, Loss_1: 0.017539050430059433, Loss_2: 0.010412629693746567, Total Loss: 0.027951680123806\n",
      "Epoch 60/200, Loss_1: 0.01246269978582859, Loss_2: 0.012346475385129452, Total Loss: 0.024809174239635468\n",
      "Epoch 80/200, Loss_1: 0.011571258306503296, Loss_2: 0.01206215936690569, Total Loss: 0.02363341674208641\n",
      "Epoch 100/200, Loss_1: 0.011716877110302448, Loss_2: 0.011586514301598072, Total Loss: 0.02330339141190052\n",
      "Epoch 120/200, Loss_1: 0.011586022563278675, Loss_2: 0.011583481915295124, Total Loss: 0.0231695044785738\n",
      "Epoch 140/200, Loss_1: 0.01156645081937313, Loss_2: 0.011529258452355862, Total Loss: 0.023095708340406418\n",
      "Epoch 160/200, Loss_1: 0.01153559610247612, Loss_2: 0.011514217592775822, Total Loss: 0.023049812763929367\n",
      "Epoch 180/200, Loss_1: 0.011518736369907856, Loss_2: 0.011499580927193165, Total Loss: 0.02301831729710102\n",
      "Epoch 200/200, Loss_1: 0.011504989117383957, Loss_2: 0.011490315198898315, Total Loss: 0.022995304316282272\n",
      "Epoch 20/200, Loss_1: 0.020278947427868843, Loss_2: 0.027279425412416458, Total Loss: 0.04755837470293045\n",
      "Epoch 40/200, Loss_1: 0.011976621113717556, Loss_2: 0.01778530701994896, Total Loss: 0.02976192906498909\n",
      "Epoch 60/200, Loss_1: 0.012531210668385029, Loss_2: 0.013067005202174187, Total Loss: 0.02559821680188179\n",
      "Epoch 80/200, Loss_1: 0.012207322753965855, Loss_2: 0.011821351014077663, Total Loss: 0.024028673768043518\n",
      "Epoch 100/200, Loss_1: 0.011817777529358864, Loss_2: 0.011745755560696125, Total Loss: 0.023563534021377563\n",
      "Epoch 120/200, Loss_1: 0.01159535814076662, Loss_2: 0.011775102466344833, Total Loss: 0.02337045967578888\n",
      "Epoch 140/200, Loss_1: 0.011580221354961395, Loss_2: 0.011685417965054512, Total Loss: 0.023265639320015907\n",
      "Epoch 160/200, Loss_1: 0.011556818149983883, Loss_2: 0.011641432531177998, Total Loss: 0.02319825068116188\n",
      "Epoch 180/200, Loss_1: 0.011513091623783112, Loss_2: 0.011637356132268906, Total Loss: 0.023150447756052017\n",
      "Epoch 200/200, Loss_1: 0.011496131308376789, Loss_2: 0.011617925949394703, Total Loss: 0.023114057257771492\n",
      "Epoch 20/200, Loss_1: 0.015766743570566177, Loss_2: 0.015644710510969162, Total Loss: 0.03141145408153534\n",
      "Epoch 40/200, Loss_1: 0.013848129659891129, Loss_2: 0.011295057833194733, Total Loss: 0.02514318749308586\n",
      "Epoch 60/200, Loss_1: 0.01164809986948967, Loss_2: 0.012314338237047195, Total Loss: 0.023962438106536865\n",
      "Epoch 80/200, Loss_1: 0.011637664400041103, Loss_2: 0.012125920504331589, Total Loss: 0.023763585835695267\n",
      "Epoch 100/200, Loss_1: 0.011727840639650822, Loss_2: 0.011899099685251713, Total Loss: 0.023626940324902534\n",
      "Epoch 120/200, Loss_1: 0.01167716458439827, Loss_2: 0.011848542839288712, Total Loss: 0.02352570742368698\n",
      "Epoch 140/200, Loss_1: 0.011676313355565071, Loss_2: 0.01176335010677576, Total Loss: 0.023439664393663406\n",
      "Epoch 160/200, Loss_1: 0.01165244821459055, Loss_2: 0.011713574640452862, Total Loss: 0.02336602285504341\n",
      "Epoch 180/200, Loss_1: 0.011633955873548985, Loss_2: 0.011668347753584385, Total Loss: 0.02330230362713337\n",
      "Epoch 200/200, Loss_1: 0.011614583432674408, Loss_2: 0.01163305900990963, Total Loss: 0.023247642442584038\n",
      "Epoch 20/200, Loss_1: 0.01378551870584488, Loss_2: 0.01446138322353363, Total Loss: 0.02824690192937851\n",
      "Epoch 40/200, Loss_1: 0.01283075287938118, Loss_2: 0.011486673727631569, Total Loss: 0.02431742660701275\n",
      "Epoch 60/200, Loss_1: 0.011936669237911701, Loss_2: 0.011859167367219925, Total Loss: 0.02379583567380905\n",
      "Epoch 80/200, Loss_1: 0.011939593590795994, Loss_2: 0.01154049951583147, Total Loss: 0.023480093106627464\n",
      "Epoch 100/200, Loss_1: 0.011721641756594181, Loss_2: 0.011571948416531086, Total Loss: 0.023293590173125267\n",
      "Epoch 120/200, Loss_1: 0.011632310226559639, Loss_2: 0.011535149067640305, Total Loss: 0.023167459294199944\n",
      "Epoch 140/200, Loss_1: 0.01158964354544878, Loss_2: 0.011498981155455112, Total Loss: 0.023088624700903893\n",
      "Epoch 160/200, Loss_1: 0.011556969955563545, Loss_2: 0.011485368944704533, Total Loss: 0.023042339831590652\n",
      "Epoch 180/200, Loss_1: 0.011533563025295734, Loss_2: 0.011479820124804974, Total Loss: 0.023013383150100708\n",
      "Epoch 200/200, Loss_1: 0.011519180610775948, Loss_2: 0.01147485338151455, Total Loss: 0.022994033992290497\n",
      "Epoch 20/200, Loss_1: 0.016209028661251068, Loss_2: 0.03474724292755127, Total Loss: 0.05095627158880234\n",
      "Epoch 40/200, Loss_1: 0.012393140234053135, Loss_2: 0.02361663058400154, Total Loss: 0.0360097698867321\n",
      "Epoch 60/200, Loss_1: 0.010887538082897663, Loss_2: 0.017811093479394913, Total Loss: 0.02869863063097\n",
      "Epoch 80/200, Loss_1: 0.011480936780571938, Loss_2: 0.014643748290836811, Total Loss: 0.026124686002731323\n",
      "Epoch 100/200, Loss_1: 0.012181267142295837, Loss_2: 0.012713277712464333, Total Loss: 0.02489454485476017\n",
      "Epoch 120/200, Loss_1: 0.012396639212965965, Loss_2: 0.01190464198589325, Total Loss: 0.024301281198859215\n",
      "Epoch 140/200, Loss_1: 0.012286019511520863, Loss_2: 0.011675992049276829, Total Loss: 0.02396201156079769\n",
      "Epoch 160/200, Loss_1: 0.01211467757821083, Loss_2: 0.011614850722253323, Total Loss: 0.023729529231786728\n",
      "Epoch 180/200, Loss_1: 0.01196992676705122, Loss_2: 0.011591918766498566, Total Loss: 0.02356184646487236\n",
      "Epoch 200/200, Loss_1: 0.011855141259729862, Loss_2: 0.011584913358092308, Total Loss: 0.023440055549144745\n",
      "Epoch 20/200, Loss_1: 0.009260838851332664, Loss_2: 0.019102739170193672, Total Loss: 0.028363578021526337\n",
      "Epoch 40/200, Loss_1: 0.011628863401710987, Loss_2: 0.012992198579013348, Total Loss: 0.024621061980724335\n",
      "Epoch 60/200, Loss_1: 0.011595700867474079, Loss_2: 0.011764832772314548, Total Loss: 0.023360533639788628\n",
      "Epoch 80/200, Loss_1: 0.011613668873906136, Loss_2: 0.011570421978831291, Total Loss: 0.023184090852737427\n",
      "Epoch 100/200, Loss_1: 0.011490050703287125, Loss_2: 0.011615236289799213, Total Loss: 0.023105286061763763\n",
      "Epoch 120/200, Loss_1: 0.011497427709400654, Loss_2: 0.011561183258891106, Total Loss: 0.023058611899614334\n",
      "Epoch 140/200, Loss_1: 0.011483825743198395, Loss_2: 0.011545873247087002, Total Loss: 0.02302969992160797\n",
      "Epoch 160/200, Loss_1: 0.011478672735393047, Loss_2: 0.011530031450092793, Total Loss: 0.02300870418548584\n",
      "Epoch 180/200, Loss_1: 0.011477463878691196, Loss_2: 0.011514931917190552, Total Loss: 0.022992394864559174\n",
      "Epoch 200/200, Loss_1: 0.011475853621959686, Loss_2: 0.011503766290843487, Total Loss: 0.022979620844125748\n",
      "Epoch 20/200, Loss_1: 0.024660592898726463, Loss_2: 0.008669723756611347, Total Loss: 0.033330317586660385\n",
      "Epoch 40/200, Loss_1: 0.012859650887548923, Loss_2: 0.013092286884784698, Total Loss: 0.025951936841011047\n",
      "Epoch 60/200, Loss_1: 0.012986441142857075, Loss_2: 0.01145031489431858, Total Loss: 0.02443675696849823\n",
      "Epoch 80/200, Loss_1: 0.011837509460747242, Loss_2: 0.012053677812218666, Total Loss: 0.023891188204288483\n",
      "Epoch 100/200, Loss_1: 0.01192261092364788, Loss_2: 0.011733614839613438, Total Loss: 0.023656226694583893\n",
      "Epoch 120/200, Loss_1: 0.011838765814900398, Loss_2: 0.01167147234082222, Total Loss: 0.023510238155722618\n",
      "Epoch 140/200, Loss_1: 0.01174959633499384, Loss_2: 0.011657695285975933, Total Loss: 0.023407291620969772\n",
      "Epoch 160/200, Loss_1: 0.011700169183313847, Loss_2: 0.011628837324678898, Total Loss: 0.023329006507992744\n",
      "Epoch 180/200, Loss_1: 0.011663483455777168, Loss_2: 0.011602828279137611, Total Loss: 0.02326631173491478\n",
      "Epoch 200/200, Loss_1: 0.01163956243544817, Loss_2: 0.011573733761906624, Total Loss: 0.023213297128677368\n",
      "Epoch 20/200, Loss_1: 0.022993717342615128, Loss_2: 0.009290489368140697, Total Loss: 0.0322842076420784\n",
      "Epoch 40/200, Loss_1: 0.010009333491325378, Loss_2: 0.014577016234397888, Total Loss: 0.024586349725723267\n",
      "Epoch 60/200, Loss_1: 0.012727628462016582, Loss_2: 0.011022577993571758, Total Loss: 0.02375020645558834\n",
      "Epoch 80/200, Loss_1: 0.011939042247831821, Loss_2: 0.011504440568387508, Total Loss: 0.02344348281621933\n",
      "Epoch 100/200, Loss_1: 0.01164326723664999, Loss_2: 0.01164449006319046, Total Loss: 0.023287758231163025\n",
      "Epoch 120/200, Loss_1: 0.011636979877948761, Loss_2: 0.011555574834346771, Total Loss: 0.023192554712295532\n",
      "Epoch 140/200, Loss_1: 0.011616728268563747, Loss_2: 0.011513937264680862, Total Loss: 0.023130666464567184\n",
      "Epoch 160/200, Loss_1: 0.011598601005971432, Loss_2: 0.011490005068480968, Total Loss: 0.0230886060744524\n",
      "Epoch 180/200, Loss_1: 0.011574388481676579, Loss_2: 0.011483910493552685, Total Loss: 0.023058298975229263\n",
      "Epoch 200/200, Loss_1: 0.011551720090210438, Loss_2: 0.011482900008559227, Total Loss: 0.02303462103009224\n",
      "Epoch 20/200, Loss_1: 0.02560093253850937, Loss_2: 0.02654036320745945, Total Loss: 0.05214129388332367\n",
      "Epoch 40/200, Loss_1: 0.020088396966457367, Loss_2: 0.015584789216518402, Total Loss: 0.03567318618297577\n",
      "Epoch 60/200, Loss_1: 0.016283901408314705, Loss_2: 0.011487298645079136, Total Loss: 0.027771200984716415\n",
      "Epoch 80/200, Loss_1: 0.013417317532002926, Loss_2: 0.011258706450462341, Total Loss: 0.024676024913787842\n",
      "Epoch 100/200, Loss_1: 0.011863276362419128, Loss_2: 0.011798009276390076, Total Loss: 0.023661285638809204\n",
      "Epoch 120/200, Loss_1: 0.01178678311407566, Loss_2: 0.01154070533812046, Total Loss: 0.02332748845219612\n",
      "Epoch 140/200, Loss_1: 0.011770188808441162, Loss_2: 0.01141669787466526, Total Loss: 0.023186886683106422\n",
      "Epoch 160/200, Loss_1: 0.011657572351396084, Loss_2: 0.01145830936729908, Total Loss: 0.02311588078737259\n",
      "Epoch 180/200, Loss_1: 0.011627882719039917, Loss_2: 0.011449651792645454, Total Loss: 0.02307753451168537\n",
      "Epoch 200/200, Loss_1: 0.011592046357691288, Loss_2: 0.01146128959953785, Total Loss: 0.023053336888551712\n",
      "Epoch 20/200, Loss_1: 0.02163645066320896, Loss_2: 0.01947128027677536, Total Loss: 0.04110772907733917\n",
      "Epoch 40/200, Loss_1: 0.021562209352850914, Loss_2: 0.011176586151123047, Total Loss: 0.03273879736661911\n",
      "Epoch 60/200, Loss_1: 0.01620885729789734, Loss_2: 0.01104852743446827, Total Loss: 0.027257384732365608\n",
      "Epoch 80/200, Loss_1: 0.013891365379095078, Loss_2: 0.011942251585423946, Total Loss: 0.0258336178958416\n",
      "Epoch 100/200, Loss_1: 0.012881067581474781, Loss_2: 0.012248625047504902, Total Loss: 0.025129692628979683\n",
      "Epoch 120/200, Loss_1: 0.012503152713179588, Loss_2: 0.012145258486270905, Total Loss: 0.024648411199450493\n",
      "Epoch 140/200, Loss_1: 0.012347565963864326, Loss_2: 0.011952566914260387, Total Loss: 0.02430013194680214\n",
      "Epoch 160/200, Loss_1: 0.012228721752762794, Loss_2: 0.011811521835625172, Total Loss: 0.02404024451971054\n",
      "Epoch 180/200, Loss_1: 0.01211581565439701, Loss_2: 0.011725973337888718, Total Loss: 0.02384178899228573\n",
      "Epoch 200/200, Loss_1: 0.012013192288577557, Loss_2: 0.011671514250338078, Total Loss: 0.023684706538915634\n",
      "Epoch 20/200, Loss_1: 0.03009134903550148, Loss_2: 0.025104854255914688, Total Loss: 0.05519620329141617\n",
      "Epoch 40/200, Loss_1: 0.019800251349806786, Loss_2: 0.01326233521103859, Total Loss: 0.033062584698200226\n",
      "Epoch 60/200, Loss_1: 0.014258967712521553, Loss_2: 0.013339849188923836, Total Loss: 0.02759881690144539\n",
      "Epoch 80/200, Loss_1: 0.011939732357859612, Loss_2: 0.013468757271766663, Total Loss: 0.025408489629626274\n",
      "Epoch 100/200, Loss_1: 0.011806890368461609, Loss_2: 0.012866441160440445, Total Loss: 0.024673331528902054\n",
      "Epoch 120/200, Loss_1: 0.012100918218493462, Loss_2: 0.01216427143663168, Total Loss: 0.024265188723802567\n",
      "Epoch 140/200, Loss_1: 0.01213141530752182, Loss_2: 0.01185937412083149, Total Loss: 0.02399078942835331\n",
      "Epoch 160/200, Loss_1: 0.01200015563517809, Loss_2: 0.011789744719862938, Total Loss: 0.0237899012863636\n",
      "Epoch 180/200, Loss_1: 0.01194656454026699, Loss_2: 0.01169551070779562, Total Loss: 0.023642074316740036\n",
      "Epoch 200/200, Loss_1: 0.011920671910047531, Loss_2: 0.011607270687818527, Total Loss: 0.02352794259786606\n",
      "Epoch 20/200, Loss_1: 0.04647086188197136, Loss_2: 0.010624914430081844, Total Loss: 0.05709577724337578\n",
      "Epoch 40/200, Loss_1: 0.03585994243621826, Loss_2: 0.008765382692217827, Total Loss: 0.04462532699108124\n",
      "Epoch 60/200, Loss_1: 0.02767976187169552, Loss_2: 0.008265129290521145, Total Loss: 0.03594489023089409\n",
      "Epoch 80/200, Loss_1: 0.02068564109504223, Loss_2: 0.009466445073485374, Total Loss: 0.030152086168527603\n",
      "Epoch 100/200, Loss_1: 0.014134258031845093, Loss_2: 0.01236734725534916, Total Loss: 0.026501605287194252\n",
      "Epoch 120/200, Loss_1: 0.012296692468225956, Loss_2: 0.012897945940494537, Total Loss: 0.02519463747739792\n",
      "Epoch 140/200, Loss_1: 0.012489271350204945, Loss_2: 0.012116409838199615, Total Loss: 0.024605680257081985\n",
      "Epoch 160/200, Loss_1: 0.012241431511938572, Loss_2: 0.012021294794976711, Total Loss: 0.024262726306915283\n",
      "Epoch 180/200, Loss_1: 0.012092714197933674, Loss_2: 0.011964059434831142, Total Loss: 0.024056773632764816\n",
      "Epoch 200/200, Loss_1: 0.012074621394276619, Loss_2: 0.011851067654788494, Total Loss: 0.02392568811774254\n",
      "Epoch 20/200, Loss_1: 0.01024226751178503, Loss_2: 0.02019268460571766, Total Loss: 0.030434951186180115\n",
      "Epoch 40/200, Loss_1: 0.013839881867170334, Loss_2: 0.01056542806327343, Total Loss: 0.024405309930443764\n",
      "Epoch 60/200, Loss_1: 0.011170065961778164, Loss_2: 0.01242833398282528, Total Loss: 0.02359839901328087\n",
      "Epoch 80/200, Loss_1: 0.011834154836833477, Loss_2: 0.011528411880135536, Total Loss: 0.02336256578564644\n",
      "Epoch 100/200, Loss_1: 0.011564528569579124, Loss_2: 0.011682194657623768, Total Loss: 0.023246724158525467\n",
      "Epoch 120/200, Loss_1: 0.011560157872736454, Loss_2: 0.0116163594648242, Total Loss: 0.023176517337560654\n",
      "Epoch 140/200, Loss_1: 0.011521070264279842, Loss_2: 0.011605829000473022, Total Loss: 0.02312690019607544\n",
      "Epoch 160/200, Loss_1: 0.011518171057105064, Loss_2: 0.011571334674954414, Total Loss: 0.02308950573205948\n",
      "Epoch 180/200, Loss_1: 0.01150371041148901, Loss_2: 0.011556132696568966, Total Loss: 0.023059843108057976\n",
      "Epoch 200/200, Loss_1: 0.011488610878586769, Loss_2: 0.011547665111720562, Total Loss: 0.023036275058984756\n",
      "Epoch 20/200, Loss_1: 0.011123664677143097, Loss_2: 0.021197574213147163, Total Loss: 0.03232123702764511\n",
      "Epoch 40/200, Loss_1: 0.012651330791413784, Loss_2: 0.012480361387133598, Total Loss: 0.025131691247224808\n",
      "Epoch 60/200, Loss_1: 0.011415733955800533, Loss_2: 0.012042735703289509, Total Loss: 0.023458469659090042\n",
      "Epoch 80/200, Loss_1: 0.011543266475200653, Loss_2: 0.011723032221198082, Total Loss: 0.023266298696398735\n",
      "Epoch 100/200, Loss_1: 0.011459823697805405, Loss_2: 0.011714708060026169, Total Loss: 0.023174531757831573\n",
      "Epoch 120/200, Loss_1: 0.011489207856357098, Loss_2: 0.011631135828793049, Total Loss: 0.023120343685150146\n",
      "Epoch 140/200, Loss_1: 0.011465828865766525, Loss_2: 0.011611748486757278, Total Loss: 0.023077577352523804\n",
      "Epoch 160/200, Loss_1: 0.011457306332886219, Loss_2: 0.011586423963308334, Total Loss: 0.02304372936487198\n",
      "Epoch 180/200, Loss_1: 0.011454617604613304, Loss_2: 0.01156284287571907, Total Loss: 0.023017460480332375\n",
      "Epoch 200/200, Loss_1: 0.011450509540736675, Loss_2: 0.011546812951564789, Total Loss: 0.02299732342362404\n",
      "Epoch 20/200, Loss_1: 0.007754982449114323, Loss_2: 0.034205492585897446, Total Loss: 0.041960474103689194\n",
      "Epoch 40/200, Loss_1: 0.009580006822943687, Loss_2: 0.019460288807749748, Total Loss: 0.029040295630693436\n",
      "Epoch 60/200, Loss_1: 0.011744437739253044, Loss_2: 0.0128660062327981, Total Loss: 0.024610444903373718\n",
      "Epoch 80/200, Loss_1: 0.011972553096711636, Loss_2: 0.011612987145781517, Total Loss: 0.023585539311170578\n",
      "Epoch 100/200, Loss_1: 0.011441868729889393, Loss_2: 0.011917016468942165, Total Loss: 0.023358885198831558\n",
      "Epoch 120/200, Loss_1: 0.011580062098801136, Loss_2: 0.011694367974996567, Total Loss: 0.023274429142475128\n",
      "Epoch 140/200, Loss_1: 0.011488720774650574, Loss_2: 0.011736271902918816, Total Loss: 0.02322499267756939\n",
      "Epoch 160/200, Loss_1: 0.011499923653900623, Loss_2: 0.011687708087265491, Total Loss: 0.023187631741166115\n",
      "Epoch 180/200, Loss_1: 0.011482727713882923, Loss_2: 0.011672868393361568, Total Loss: 0.02315559610724449\n",
      "Epoch 200/200, Loss_1: 0.011479086242616177, Loss_2: 0.0116485096514225, Total Loss: 0.023127596825361252\n",
      "Epoch 20/200, Loss_1: 0.02503024786710739, Loss_2: 0.02068568766117096, Total Loss: 0.04571593552827835\n",
      "Epoch 40/200, Loss_1: 0.022575540468096733, Loss_2: 0.01576453261077404, Total Loss: 0.03834007307887077\n",
      "Epoch 60/200, Loss_1: 0.01778402365744114, Loss_2: 0.013235462829470634, Total Loss: 0.031019486486911774\n",
      "Epoch 80/200, Loss_1: 0.014028736390173435, Loss_2: 0.013861589133739471, Total Loss: 0.027890324592590332\n",
      "Epoch 100/200, Loss_1: 0.011974782682955265, Loss_2: 0.01420322060585022, Total Loss: 0.02617800235748291\n",
      "Epoch 120/200, Loss_1: 0.011745908297598362, Loss_2: 0.013445590622723103, Total Loss: 0.025191498920321465\n",
      "Epoch 140/200, Loss_1: 0.011791912838816643, Loss_2: 0.0127779021859169, Total Loss: 0.024569815024733543\n",
      "Epoch 160/200, Loss_1: 0.011734220199286938, Loss_2: 0.012408765032887459, Total Loss: 0.024142984300851822\n",
      "Epoch 180/200, Loss_1: 0.0117152389138937, Loss_2: 0.01212052907794714, Total Loss: 0.023835767060518265\n",
      "Epoch 200/200, Loss_1: 0.01171512808650732, Loss_2: 0.011896728537976742, Total Loss: 0.023611856624484062\n",
      "Epoch 20/200, Loss_1: 0.04257115349173546, Loss_2: 0.006195488851517439, Total Loss: 0.048766642808914185\n",
      "Epoch 40/200, Loss_1: 0.035107359290122986, Loss_2: 0.006758139468729496, Total Loss: 0.04186549782752991\n",
      "Epoch 60/200, Loss_1: 0.028654521331191063, Loss_2: 0.008307370357215405, Total Loss: 0.03696189075708389\n",
      "Epoch 80/200, Loss_1: 0.023870281875133514, Loss_2: 0.008887413889169693, Total Loss: 0.03275769576430321\n",
      "Epoch 100/200, Loss_1: 0.018627190962433815, Loss_2: 0.010486776940524578, Total Loss: 0.02911396697163582\n",
      "Epoch 120/200, Loss_1: 0.014696013182401657, Loss_2: 0.011942930519580841, Total Loss: 0.026638943701982498\n",
      "Epoch 140/200, Loss_1: 0.013000414706766605, Loss_2: 0.012369425967335701, Total Loss: 0.02536984160542488\n",
      "Epoch 160/200, Loss_1: 0.01252755243331194, Loss_2: 0.012192130088806152, Total Loss: 0.024719681590795517\n",
      "Epoch 180/200, Loss_1: 0.012291411869227886, Loss_2: 0.012013866566121578, Total Loss: 0.024305278435349464\n",
      "Epoch 200/200, Loss_1: 0.012126079760491848, Loss_2: 0.011880976147949696, Total Loss: 0.024007055908441544\n",
      "Epoch 20/200, Loss_1: 0.015160039067268372, Loss_2: 0.016571246087551117, Total Loss: 0.03173128515481949\n",
      "Epoch 40/200, Loss_1: 0.020472578704357147, Loss_2: 0.013058909215033054, Total Loss: 0.03353148698806763\n",
      "Epoch 60/200, Loss_1: 0.0133970333263278, Loss_2: 0.01336885616183281, Total Loss: 0.026765890419483185\n",
      "Epoch 80/200, Loss_1: 0.012930853292346, Loss_2: 0.012867349199950695, Total Loss: 0.02579820156097412\n",
      "Epoch 100/200, Loss_1: 0.012934999540448189, Loss_2: 0.01221922505646944, Total Loss: 0.025154225528240204\n",
      "Epoch 120/200, Loss_1: 0.012636885978281498, Loss_2: 0.012071563862264156, Total Loss: 0.024708449840545654\n",
      "Epoch 140/200, Loss_1: 0.012327335774898529, Loss_2: 0.01202687993645668, Total Loss: 0.02435421571135521\n",
      "Epoch 160/200, Loss_1: 0.012124677188694477, Loss_2: 0.011949878185987473, Total Loss: 0.024074554443359375\n",
      "Epoch 180/200, Loss_1: 0.011974085122346878, Loss_2: 0.01188095286488533, Total Loss: 0.023855037987232208\n",
      "Epoch 200/200, Loss_1: 0.011840748600661755, Loss_2: 0.011843068525195122, Total Loss: 0.023683816194534302\n",
      "Epoch 20/200, Loss_1: 0.028380636125802994, Loss_2: 0.027391871437430382, Total Loss: 0.055772505700588226\n",
      "Epoch 40/200, Loss_1: 0.030521465465426445, Loss_2: 0.01637379266321659, Total Loss: 0.046895258128643036\n",
      "Epoch 60/200, Loss_1: 0.019094092771410942, Loss_2: 0.013425923883914948, Total Loss: 0.03252001851797104\n",
      "Epoch 80/200, Loss_1: 0.016526339575648308, Loss_2: 0.012662026099860668, Total Loss: 0.0291883647441864\n",
      "Epoch 100/200, Loss_1: 0.015232592821121216, Loss_2: 0.011910599656403065, Total Loss: 0.027143191546201706\n",
      "Epoch 120/200, Loss_1: 0.014143098145723343, Loss_2: 0.011724971234798431, Total Loss: 0.025868069380521774\n",
      "Epoch 140/200, Loss_1: 0.01318418886512518, Loss_2: 0.01184672862291336, Total Loss: 0.025030918419361115\n",
      "Epoch 160/200, Loss_1: 0.012498154304921627, Loss_2: 0.011982578784227371, Total Loss: 0.024480734020471573\n",
      "Epoch 180/200, Loss_1: 0.012095833197236061, Loss_2: 0.012015359476208687, Total Loss: 0.024111192673444748\n",
      "Epoch 200/200, Loss_1: 0.011883961968123913, Loss_2: 0.011969286948442459, Total Loss: 0.023853249847888947\n",
      "Epoch 20/200, Loss_1: 0.016026094555854797, Loss_2: 0.011694337241351604, Total Loss: 0.027720432728528976\n",
      "Epoch 40/200, Loss_1: 0.012828649021685123, Loss_2: 0.011035614646971226, Total Loss: 0.02386426366865635\n",
      "Epoch 60/200, Loss_1: 0.011521661654114723, Loss_2: 0.011923028156161308, Total Loss: 0.02344468981027603\n",
      "Epoch 80/200, Loss_1: 0.01152426190674305, Loss_2: 0.011702096089720726, Total Loss: 0.023226357996463776\n",
      "Epoch 100/200, Loss_1: 0.011567183770239353, Loss_2: 0.01155386958271265, Total Loss: 0.023121053352952003\n",
      "Epoch 120/200, Loss_1: 0.011524938978254795, Loss_2: 0.011531392112374306, Total Loss: 0.023056332021951675\n",
      "Epoch 140/200, Loss_1: 0.01150000374764204, Loss_2: 0.011511096730828285, Total Loss: 0.02301109954714775\n",
      "Epoch 160/200, Loss_1: 0.011489247903227806, Loss_2: 0.011489930562675, Total Loss: 0.02297917753458023\n",
      "Epoch 180/200, Loss_1: 0.0114826625213027, Loss_2: 0.011474880389869213, Total Loss: 0.022957542911171913\n",
      "Epoch 200/200, Loss_1: 0.011477184481918812, Loss_2: 0.011466112919151783, Total Loss: 0.022943297401070595\n",
      "Epoch 20/200, Loss_1: 0.03447558730840683, Loss_2: 0.03522252291440964, Total Loss: 0.06969811022281647\n",
      "Epoch 40/200, Loss_1: 0.023012246936559677, Loss_2: 0.016144193708896637, Total Loss: 0.039156440645456314\n",
      "Epoch 60/200, Loss_1: 0.017718913033604622, Loss_2: 0.013405551202595234, Total Loss: 0.03112446516752243\n",
      "Epoch 80/200, Loss_1: 0.014040347188711166, Loss_2: 0.013070319779217243, Total Loss: 0.027110666036605835\n",
      "Epoch 100/200, Loss_1: 0.012089693918824196, Loss_2: 0.013158301822841167, Total Loss: 0.02524799481034279\n",
      "Epoch 120/200, Loss_1: 0.011710012331604958, Loss_2: 0.012734169140458107, Total Loss: 0.024444181472063065\n",
      "Epoch 140/200, Loss_1: 0.01187665481120348, Loss_2: 0.01214052364230156, Total Loss: 0.024017177522182465\n",
      "Epoch 160/200, Loss_1: 0.011858114041388035, Loss_2: 0.011915604583919048, Total Loss: 0.023773718625307083\n",
      "Epoch 180/200, Loss_1: 0.011796532198786736, Loss_2: 0.011831947602331638, Total Loss: 0.02362848073244095\n",
      "Epoch 200/200, Loss_1: 0.011769848875701427, Loss_2: 0.01176542416214943, Total Loss: 0.02353527396917343\n",
      "Epoch 20/200, Loss_1: 0.01442223321646452, Loss_2: 0.009937840513885021, Total Loss: 0.02436007373034954\n",
      "Epoch 40/200, Loss_1: 0.01164840068668127, Loss_2: 0.011420718394219875, Total Loss: 0.023069119080901146\n",
      "Epoch 60/200, Loss_1: 0.011440539732575417, Loss_2: 0.011503039859235287, Total Loss: 0.02294357866048813\n",
      "Epoch 80/200, Loss_1: 0.011540470644831657, Loss_2: 0.011383908800780773, Total Loss: 0.022924378514289856\n",
      "Epoch 100/200, Loss_1: 0.01149789709597826, Loss_2: 0.011418738402426243, Total Loss: 0.022916635498404503\n",
      "Epoch 120/200, Loss_1: 0.01144982036203146, Loss_2: 0.011462641879916191, Total Loss: 0.022912461310625076\n",
      "Epoch 140/200, Loss_1: 0.01146859023720026, Loss_2: 0.011441226117312908, Total Loss: 0.02290981635451317\n",
      "Epoch 160/200, Loss_1: 0.011459573172032833, Loss_2: 0.011448281817138195, Total Loss: 0.022907854989171028\n",
      "Epoch 180/200, Loss_1: 0.011459749191999435, Loss_2: 0.01144661195576191, Total Loss: 0.022906361147761345\n",
      "Epoch 200/200, Loss_1: 0.011458535678684711, Loss_2: 0.011446638964116573, Total Loss: 0.022905174642801285\n",
      "Epoch 20/200, Loss_1: 0.030317559838294983, Loss_2: 0.023555375635623932, Total Loss: 0.053872935473918915\n",
      "Epoch 40/200, Loss_1: 0.016940897330641747, Loss_2: 0.013595016673207283, Total Loss: 0.03053591400384903\n",
      "Epoch 60/200, Loss_1: 0.013519125990569592, Loss_2: 0.012251902371644974, Total Loss: 0.02577102929353714\n",
      "Epoch 80/200, Loss_1: 0.01214850228279829, Loss_2: 0.012253507040441036, Total Loss: 0.024402009323239326\n",
      "Epoch 100/200, Loss_1: 0.011939538642764091, Loss_2: 0.011854705400764942, Total Loss: 0.02379424497485161\n",
      "Epoch 120/200, Loss_1: 0.011750375851988792, Loss_2: 0.011753933504223824, Total Loss: 0.023504309356212616\n",
      "Epoch 140/200, Loss_1: 0.011672603897750378, Loss_2: 0.0116795739158988, Total Loss: 0.023352177813649178\n",
      "Epoch 160/200, Loss_1: 0.011626116931438446, Loss_2: 0.011639012955129147, Total Loss: 0.023265130817890167\n",
      "Epoch 180/200, Loss_1: 0.011606586165726185, Loss_2: 0.011601981706917286, Total Loss: 0.02320856787264347\n",
      "Epoch 200/200, Loss_1: 0.011588983237743378, Loss_2: 0.011578045785427094, Total Loss: 0.02316702902317047\n",
      "Epoch 20/200, Loss_1: 0.021747417747974396, Loss_2: 0.016928058117628098, Total Loss: 0.03867547586560249\n",
      "Epoch 40/200, Loss_1: 0.015582109801471233, Loss_2: 0.015931572765111923, Total Loss: 0.03151368349790573\n",
      "Epoch 60/200, Loss_1: 0.014154420234262943, Loss_2: 0.015317768789827824, Total Loss: 0.029472189024090767\n",
      "Epoch 80/200, Loss_1: 0.013040110468864441, Loss_2: 0.01455747615545988, Total Loss: 0.027597587555646896\n",
      "Epoch 100/200, Loss_1: 0.01260035578161478, Loss_2: 0.013801916502416134, Total Loss: 0.026402272284030914\n",
      "Epoch 120/200, Loss_1: 0.012490729801356792, Loss_2: 0.013124288059771061, Total Loss: 0.025615017861127853\n",
      "Epoch 140/200, Loss_1: 0.012524692341685295, Loss_2: 0.012536250054836273, Total Loss: 0.02506094239652157\n",
      "Epoch 160/200, Loss_1: 0.012522650882601738, Loss_2: 0.012146000750362873, Total Loss: 0.024668652564287186\n",
      "Epoch 180/200, Loss_1: 0.012468069791793823, Loss_2: 0.011922226287424564, Total Loss: 0.024390295147895813\n",
      "Epoch 200/200, Loss_1: 0.012415456585586071, Loss_2: 0.011767784133553505, Total Loss: 0.024183239787817\n",
      "Epoch 20/200, Loss_1: 0.029053043574094772, Loss_2: 0.00797748938202858, Total Loss: 0.03703053295612335\n",
      "Epoch 40/200, Loss_1: 0.022270748391747475, Loss_2: 0.00914178229868412, Total Loss: 0.031412530690431595\n",
      "Epoch 60/200, Loss_1: 0.018893830478191376, Loss_2: 0.010067852213978767, Total Loss: 0.028961682692170143\n",
      "Epoch 80/200, Loss_1: 0.015510459430515766, Loss_2: 0.01095127034932375, Total Loss: 0.026461729779839516\n",
      "Epoch 100/200, Loss_1: 0.01348511315882206, Loss_2: 0.011825517751276493, Total Loss: 0.025310631841421127\n",
      "Epoch 120/200, Loss_1: 0.012330926954746246, Loss_2: 0.012342702597379684, Total Loss: 0.02467362955212593\n",
      "Epoch 140/200, Loss_1: 0.011793702840805054, Loss_2: 0.012529621832072735, Total Loss: 0.024323325604200363\n",
      "Epoch 160/200, Loss_1: 0.011615687049925327, Loss_2: 0.012480478733778, Total Loss: 0.024096164852380753\n",
      "Epoch 180/200, Loss_1: 0.011586923152208328, Loss_2: 0.012339422479271889, Total Loss: 0.023926345631480217\n",
      "Epoch 200/200, Loss_1: 0.011595136485993862, Loss_2: 0.012196686118841171, Total Loss: 0.023791823536157608\n",
      "Epoch 20/200, Loss_1: 0.028782673180103302, Loss_2: 0.04435517638921738, Total Loss: 0.07313784956932068\n",
      "Epoch 40/200, Loss_1: 0.012962798587977886, Loss_2: 0.026219313964247704, Total Loss: 0.039182111620903015\n",
      "Epoch 60/200, Loss_1: 0.009705962613224983, Loss_2: 0.025766409933567047, Total Loss: 0.03547237068414688\n",
      "Epoch 80/200, Loss_1: 0.007959243841469288, Loss_2: 0.02569105662405491, Total Loss: 0.03365030139684677\n",
      "Epoch 100/200, Loss_1: 0.006992672570049763, Loss_2: 0.025861706584692, Total Loss: 0.03285437822341919\n",
      "Epoch 120/200, Loss_1: 0.00739925354719162, Loss_2: 0.024448983371257782, Total Loss: 0.0318482369184494\n",
      "Epoch 140/200, Loss_1: 0.00860347505658865, Loss_2: 0.020460549741983414, Total Loss: 0.029064025729894638\n",
      "Epoch 160/200, Loss_1: 0.010982627980411053, Loss_2: 0.013922744430601597, Total Loss: 0.02490537241101265\n",
      "Epoch 180/200, Loss_1: 0.011723131872713566, Loss_2: 0.012512752786278725, Total Loss: 0.024235885590314865\n",
      "Epoch 200/200, Loss_1: 0.0113722775131464, Loss_2: 0.012574834749102592, Total Loss: 0.023947112262248993\n",
      "Epoch 20/200, Loss_1: 0.023210730403661728, Loss_2: 0.03712863847613335, Total Loss: 0.060339368879795074\n",
      "Epoch 40/200, Loss_1: 0.021081633865833282, Loss_2: 0.020512446761131287, Total Loss: 0.04159408062696457\n",
      "Epoch 60/200, Loss_1: 0.019554926082491875, Loss_2: 0.01655651442706585, Total Loss: 0.036111440509557724\n",
      "Epoch 80/200, Loss_1: 0.017846107482910156, Loss_2: 0.015473798848688602, Total Loss: 0.033319905400276184\n",
      "Epoch 100/200, Loss_1: 0.01636471040546894, Loss_2: 0.01476904097944498, Total Loss: 0.031133752316236496\n",
      "Epoch 120/200, Loss_1: 0.015176508575677872, Loss_2: 0.01423701737076044, Total Loss: 0.029413525015115738\n",
      "Epoch 140/200, Loss_1: 0.014221133664250374, Loss_2: 0.013892495073378086, Total Loss: 0.028113629668951035\n",
      "Epoch 160/200, Loss_1: 0.013569026254117489, Loss_2: 0.013578896410763264, Total Loss: 0.027147922664880753\n",
      "Epoch 180/200, Loss_1: 0.01316901110112667, Loss_2: 0.013245680369436741, Total Loss: 0.026414692401885986\n",
      "Epoch 200/200, Loss_1: 0.012890951707959175, Loss_2: 0.01295627560466528, Total Loss: 0.02584722638130188\n",
      "Epoch 20/200, Loss_1: 0.01999724842607975, Loss_2: 0.018399788066744804, Total Loss: 0.038397036492824554\n",
      "Epoch 40/200, Loss_1: 0.01366394106298685, Loss_2: 0.012412243522703648, Total Loss: 0.0260761845856905\n",
      "Epoch 60/200, Loss_1: 0.012018115259706974, Loss_2: 0.01188356801867485, Total Loss: 0.02390168234705925\n",
      "Epoch 80/200, Loss_1: 0.011676924303174019, Loss_2: 0.011882251128554344, Total Loss: 0.023559175431728363\n",
      "Epoch 100/200, Loss_1: 0.011645174585282803, Loss_2: 0.011740999296307564, Total Loss: 0.023386172950267792\n",
      "Epoch 120/200, Loss_1: 0.011605272069573402, Loss_2: 0.01166629884392023, Total Loss: 0.023271571844816208\n",
      "Epoch 140/200, Loss_1: 0.011579609476029873, Loss_2: 0.011616738513112068, Total Loss: 0.023196347057819366\n",
      "Epoch 160/200, Loss_1: 0.011557304300367832, Loss_2: 0.011583881452679634, Total Loss: 0.02314118668437004\n",
      "Epoch 180/200, Loss_1: 0.011539884842932224, Loss_2: 0.011558592319488525, Total Loss: 0.023098476231098175\n",
      "Epoch 200/200, Loss_1: 0.01152635645121336, Loss_2: 0.011538439430296421, Total Loss: 0.02306479588150978\n",
      "Epoch 20/200, Loss_1: 0.04272734746336937, Loss_2: 0.03298138082027435, Total Loss: 0.07570873200893402\n",
      "Epoch 40/200, Loss_1: 0.01675986498594284, Loss_2: 0.018766658380627632, Total Loss: 0.035526521503925323\n",
      "Epoch 60/200, Loss_1: 0.012848163023591042, Loss_2: 0.01465192623436451, Total Loss: 0.02750008925795555\n",
      "Epoch 80/200, Loss_1: 0.012275132350623608, Loss_2: 0.013250768184661865, Total Loss: 0.025525901466608047\n",
      "Epoch 100/200, Loss_1: 0.012101702392101288, Loss_2: 0.012660985812544823, Total Loss: 0.02476268820464611\n",
      "Epoch 120/200, Loss_1: 0.011868884786963463, Loss_2: 0.012490574270486832, Total Loss: 0.024359459057450294\n",
      "Epoch 140/200, Loss_1: 0.011849201284348965, Loss_2: 0.012243080884218216, Total Loss: 0.024092283099889755\n",
      "Epoch 160/200, Loss_1: 0.011825701221823692, Loss_2: 0.01207683328539133, Total Loss: 0.023902535438537598\n",
      "Epoch 180/200, Loss_1: 0.011815203353762627, Loss_2: 0.011943810619413853, Total Loss: 0.023759014904499054\n",
      "Epoch 200/200, Loss_1: 0.011807075701653957, Loss_2: 0.011839667335152626, Total Loss: 0.02364674210548401\n",
      "Epoch 20/200, Loss_1: 0.023289641365408897, Loss_2: 0.028305204585194588, Total Loss: 0.051594845950603485\n",
      "Epoch 40/200, Loss_1: 0.01110941544175148, Loss_2: 0.020560836419463158, Total Loss: 0.03167024999856949\n",
      "Epoch 60/200, Loss_1: 0.011266889981925488, Loss_2: 0.01501979399472475, Total Loss: 0.026286683976650238\n",
      "Epoch 80/200, Loss_1: 0.01328396424651146, Loss_2: 0.01108939852565527, Total Loss: 0.024373363703489304\n",
      "Epoch 100/200, Loss_1: 0.01169227808713913, Loss_2: 0.011951029300689697, Total Loss: 0.023643307387828827\n",
      "Epoch 120/200, Loss_1: 0.011561740189790726, Loss_2: 0.011787799187004566, Total Loss: 0.023349538445472717\n",
      "Epoch 140/200, Loss_1: 0.011631532572209835, Loss_2: 0.011628157459199429, Total Loss: 0.023259690031409264\n",
      "Epoch 160/200, Loss_1: 0.011590424925088882, Loss_2: 0.011608118191361427, Total Loss: 0.02319854311645031\n",
      "Epoch 180/200, Loss_1: 0.01153354812413454, Loss_2: 0.011617874726653099, Total Loss: 0.023151423782110214\n",
      "Epoch 200/200, Loss_1: 0.011522405780851841, Loss_2: 0.011591155081987381, Total Loss: 0.023113559931516647\n",
      "Epoch 20/200, Loss_1: 0.022411897778511047, Loss_2: 0.033838964998722076, Total Loss: 0.056250862777233124\n",
      "Epoch 40/200, Loss_1: 0.010148351080715656, Loss_2: 0.020845817402005196, Total Loss: 0.030994169414043427\n",
      "Epoch 60/200, Loss_1: 0.009796058759093285, Loss_2: 0.01684357039630413, Total Loss: 0.026639629155397415\n",
      "Epoch 80/200, Loss_1: 0.010814657434821129, Loss_2: 0.014180046506226063, Total Loss: 0.024994704872369766\n",
      "Epoch 100/200, Loss_1: 0.011606400832533836, Loss_2: 0.012471985071897507, Total Loss: 0.024078385904431343\n",
      "Epoch 120/200, Loss_1: 0.011962288990616798, Loss_2: 0.011674349196255207, Total Loss: 0.02363663911819458\n",
      "Epoch 140/200, Loss_1: 0.01190306805074215, Loss_2: 0.011529486626386642, Total Loss: 0.023432554677128792\n",
      "Epoch 160/200, Loss_1: 0.011756455525755882, Loss_2: 0.011561648920178413, Total Loss: 0.023318104445934296\n",
      "Epoch 180/200, Loss_1: 0.011686835438013077, Loss_2: 0.011556355282664299, Total Loss: 0.023243190720677376\n",
      "Epoch 200/200, Loss_1: 0.011624161154031754, Loss_2: 0.011567067354917526, Total Loss: 0.02319122850894928\n",
      "Epoch 20/200, Loss_1: 0.02731456235051155, Loss_2: 0.01092909649014473, Total Loss: 0.03824365884065628\n",
      "Epoch 40/200, Loss_1: 0.01706635020673275, Loss_2: 0.017619822174310684, Total Loss: 0.034686170518398285\n",
      "Epoch 60/200, Loss_1: 0.013347918167710304, Loss_2: 0.015406825579702854, Total Loss: 0.028754744678735733\n",
      "Epoch 80/200, Loss_1: 0.012243690900504589, Loss_2: 0.0149861304089427, Total Loss: 0.02722982130944729\n",
      "Epoch 100/200, Loss_1: 0.011999870650470257, Loss_2: 0.014030490070581436, Total Loss: 0.026030361652374268\n",
      "Epoch 120/200, Loss_1: 0.012170747853815556, Loss_2: 0.01296062208712101, Total Loss: 0.02513137087225914\n",
      "Epoch 140/200, Loss_1: 0.012219730764627457, Loss_2: 0.012341916561126709, Total Loss: 0.024561647325754166\n",
      "Epoch 160/200, Loss_1: 0.012070167809724808, Loss_2: 0.01213705725967884, Total Loss: 0.02420722506940365\n",
      "Epoch 180/200, Loss_1: 0.01197595801204443, Loss_2: 0.011980959214270115, Total Loss: 0.023956917226314545\n",
      "Epoch 200/200, Loss_1: 0.011978523805737495, Loss_2: 0.01178840920329094, Total Loss: 0.023766933009028435\n",
      "Epoch 20/200, Loss_1: 0.012082689441740513, Loss_2: 0.014124301262199879, Total Loss: 0.02620699070394039\n",
      "Epoch 40/200, Loss_1: 0.012181543745100498, Loss_2: 0.012137179262936115, Total Loss: 0.024318723008036613\n",
      "Epoch 60/200, Loss_1: 0.011344261467456818, Loss_2: 0.012099578976631165, Total Loss: 0.023443840444087982\n",
      "Epoch 80/200, Loss_1: 0.011515829712152481, Loss_2: 0.011702010408043861, Total Loss: 0.023217840120196342\n",
      "Epoch 100/200, Loss_1: 0.011489782482385635, Loss_2: 0.011645586229860783, Total Loss: 0.023135367780923843\n",
      "Epoch 120/200, Loss_1: 0.011476530693471432, Loss_2: 0.011607257649302483, Total Loss: 0.02308378741145134\n",
      "Epoch 140/200, Loss_1: 0.011465589515864849, Loss_2: 0.011581475846469402, Total Loss: 0.02304706536233425\n",
      "Epoch 160/200, Loss_1: 0.011461007408797741, Loss_2: 0.011558350175619125, Total Loss: 0.02301935851573944\n",
      "Epoch 180/200, Loss_1: 0.011455873027443886, Loss_2: 0.011541810818016529, Total Loss: 0.02299768477678299\n",
      "Epoch 200/200, Loss_1: 0.011453015729784966, Loss_2: 0.011527659371495247, Total Loss: 0.022980675101280212\n",
      "Epoch 20/200, Loss_1: 0.05317779257893562, Loss_2: 0.026214461773633957, Total Loss: 0.07939225435256958\n",
      "Epoch 40/200, Loss_1: 0.038427434861660004, Loss_2: 0.013436893001198769, Total Loss: 0.05186432600021362\n",
      "Epoch 60/200, Loss_1: 0.03363122045993805, Loss_2: 0.01048159971833229, Total Loss: 0.04411282017827034\n",
      "Epoch 80/200, Loss_1: 0.03065423108637333, Loss_2: 0.00852374266833067, Total Loss: 0.039177972823381424\n",
      "Epoch 100/200, Loss_1: 0.027292300015687943, Loss_2: 0.00826976727694273, Total Loss: 0.03556206822395325\n",
      "Epoch 120/200, Loss_1: 0.023738021031022072, Loss_2: 0.008816905319690704, Total Loss: 0.03255492448806763\n",
      "Epoch 140/200, Loss_1: 0.019957667216658592, Loss_2: 0.009765621274709702, Total Loss: 0.029723288491368294\n",
      "Epoch 160/200, Loss_1: 0.016762608662247658, Loss_2: 0.01068626344203949, Total Loss: 0.027448872104287148\n",
      "Epoch 180/200, Loss_1: 0.014323932118713856, Loss_2: 0.011561194434762001, Total Loss: 0.02588512748479843\n",
      "Epoch 200/200, Loss_1: 0.012773614376783371, Loss_2: 0.01215352676808834, Total Loss: 0.02492714114487171\n",
      "Epoch 20/200, Loss_1: 0.03799663484096527, Loss_2: 0.026350948959589005, Total Loss: 0.06434758007526398\n",
      "Epoch 40/200, Loss_1: 0.0201320368796587, Loss_2: 0.012802035547792912, Total Loss: 0.032934073358774185\n",
      "Epoch 60/200, Loss_1: 0.012239177711308002, Loss_2: 0.013875514268875122, Total Loss: 0.02611469104886055\n",
      "Epoch 80/200, Loss_1: 0.012545198202133179, Loss_2: 0.012104584835469723, Total Loss: 0.024649783968925476\n",
      "Epoch 100/200, Loss_1: 0.012166043743491173, Loss_2: 0.012015423737466335, Total Loss: 0.024181466549634933\n",
      "Epoch 120/200, Loss_1: 0.012085499241948128, Loss_2: 0.011850026436150074, Total Loss: 0.023935526609420776\n",
      "Epoch 140/200, Loss_1: 0.012071827426552773, Loss_2: 0.011701047420501709, Total Loss: 0.02377287484705448\n",
      "Epoch 160/200, Loss_1: 0.01200246810913086, Loss_2: 0.011649290099740028, Total Loss: 0.023651758208870888\n",
      "Epoch 180/200, Loss_1: 0.011957446113228798, Loss_2: 0.01159787829965353, Total Loss: 0.023555323481559753\n",
      "Epoch 200/200, Loss_1: 0.011906336061656475, Loss_2: 0.011569594033062458, Total Loss: 0.023475930094718933\n",
      "Epoch 20/200, Loss_1: 0.0377025306224823, Loss_2: 0.01075259130448103, Total Loss: 0.048455122858285904\n",
      "Epoch 40/200, Loss_1: 0.01689288392663002, Loss_2: 0.010266735218465328, Total Loss: 0.027159620076417923\n",
      "Epoch 60/200, Loss_1: 0.011355028487741947, Loss_2: 0.013590625487267971, Total Loss: 0.024945653975009918\n",
      "Epoch 80/200, Loss_1: 0.011035474948585033, Loss_2: 0.013142431154847145, Total Loss: 0.024177905172109604\n",
      "Epoch 100/200, Loss_1: 0.011023875325918198, Loss_2: 0.012760739773511887, Total Loss: 0.023784615099430084\n",
      "Epoch 120/200, Loss_1: 0.01120301429182291, Loss_2: 0.012342396192252636, Total Loss: 0.023545410484075546\n",
      "Epoch 140/200, Loss_1: 0.011342528276145458, Loss_2: 0.012050390243530273, Total Loss: 0.023392919450998306\n",
      "Epoch 160/200, Loss_1: 0.011398541741073132, Loss_2: 0.011897590011358261, Total Loss: 0.023296132683753967\n",
      "Epoch 180/200, Loss_1: 0.011437952518463135, Loss_2: 0.011794551275670528, Total Loss: 0.023232504725456238\n",
      "Epoch 200/200, Loss_1: 0.011444930918514729, Loss_2: 0.011742844246327877, Total Loss: 0.023187775164842606\n",
      "Epoch 20/200, Loss_1: 0.02137707732617855, Loss_2: 0.022394631057977676, Total Loss: 0.04377170652151108\n",
      "Epoch 40/200, Loss_1: 0.01393390353769064, Loss_2: 0.01600784808397293, Total Loss: 0.029941752552986145\n",
      "Epoch 60/200, Loss_1: 0.00971562135964632, Loss_2: 0.015272626653313637, Total Loss: 0.024988248944282532\n",
      "Epoch 80/200, Loss_1: 0.011953935958445072, Loss_2: 0.011865820735692978, Total Loss: 0.023819755762815475\n",
      "Epoch 100/200, Loss_1: 0.011452775448560715, Loss_2: 0.012026641517877579, Total Loss: 0.023479416966438293\n",
      "Epoch 120/200, Loss_1: 0.011266952380537987, Loss_2: 0.012036575935781002, Total Loss: 0.023303527384996414\n",
      "Epoch 140/200, Loss_1: 0.011408735066652298, Loss_2: 0.011800702661275864, Total Loss: 0.02320943772792816\n",
      "Epoch 160/200, Loss_1: 0.011416837573051453, Loss_2: 0.011723444797098637, Total Loss: 0.023140281438827515\n",
      "Epoch 180/200, Loss_1: 0.011427463963627815, Loss_2: 0.011662060394883156, Total Loss: 0.02308952435851097\n",
      "Epoch 200/200, Loss_1: 0.01144266314804554, Loss_2: 0.011606228537857533, Total Loss: 0.023048892617225647\n",
      "Epoch 20/200, Loss_1: 0.017666112631559372, Loss_2: 0.01843392848968506, Total Loss: 0.03610004112124443\n",
      "Epoch 40/200, Loss_1: 0.011912626214325428, Loss_2: 0.014780046418309212, Total Loss: 0.026692673563957214\n",
      "Epoch 60/200, Loss_1: 0.012095545418560505, Loss_2: 0.01277457270771265, Total Loss: 0.024870118126273155\n",
      "Epoch 80/200, Loss_1: 0.01197682972997427, Loss_2: 0.012197762727737427, Total Loss: 0.02417459338903427\n",
      "Epoch 100/200, Loss_1: 0.0116714583709836, Loss_2: 0.01216207817196846, Total Loss: 0.023833535611629486\n",
      "Epoch 120/200, Loss_1: 0.011563828215003014, Loss_2: 0.012075034901499748, Total Loss: 0.023638863116502762\n",
      "Epoch 140/200, Loss_1: 0.011591581627726555, Loss_2: 0.011882263235747814, Total Loss: 0.023473843932151794\n",
      "Epoch 160/200, Loss_1: 0.011565033346414566, Loss_2: 0.011791515164077282, Total Loss: 0.023356549441814423\n",
      "Epoch 180/200, Loss_1: 0.011589420028030872, Loss_2: 0.011691639199852943, Total Loss: 0.02328106015920639\n",
      "Epoch 200/200, Loss_1: 0.011570109985768795, Loss_2: 0.011662147007882595, Total Loss: 0.02323225699365139\n",
      "Epoch 20/200, Loss_1: 0.0211529228836298, Loss_2: 0.018495924770832062, Total Loss: 0.03964884579181671\n",
      "Epoch 40/200, Loss_1: 0.014181071892380714, Loss_2: 0.010874250903725624, Total Loss: 0.02505532279610634\n",
      "Epoch 60/200, Loss_1: 0.011459548957645893, Loss_2: 0.012320724315941334, Total Loss: 0.023780273273587227\n",
      "Epoch 80/200, Loss_1: 0.011611523106694221, Loss_2: 0.011744103394448757, Total Loss: 0.023355625569820404\n",
      "Epoch 100/200, Loss_1: 0.011596497148275375, Loss_2: 0.01161870826035738, Total Loss: 0.02321520447731018\n",
      "Epoch 120/200, Loss_1: 0.011568311601877213, Loss_2: 0.011584141291677952, Total Loss: 0.02315245196223259\n",
      "Epoch 140/200, Loss_1: 0.011552001349627972, Loss_2: 0.011563219130039215, Total Loss: 0.02311522141098976\n",
      "Epoch 160/200, Loss_1: 0.01153385080397129, Loss_2: 0.011555620469152927, Total Loss: 0.023089472204446793\n",
      "Epoch 180/200, Loss_1: 0.011521631851792336, Loss_2: 0.011548224836587906, Total Loss: 0.02306985668838024\n",
      "Epoch 200/200, Loss_1: 0.011510227806866169, Loss_2: 0.011542631313204765, Total Loss: 0.02305286005139351\n",
      "Epoch 20/200, Loss_1: 0.012674292549490929, Loss_2: 0.024186549708247185, Total Loss: 0.03686084225773811\n",
      "Epoch 40/200, Loss_1: 0.01772352308034897, Loss_2: 0.016756881028413773, Total Loss: 0.03448040410876274\n",
      "Epoch 60/200, Loss_1: 0.015583244152367115, Loss_2: 0.013527501374483109, Total Loss: 0.02911074459552765\n",
      "Epoch 80/200, Loss_1: 0.01544093620032072, Loss_2: 0.01197328232228756, Total Loss: 0.027414217591285706\n",
      "Epoch 100/200, Loss_1: 0.015177067369222641, Loss_2: 0.011158539913594723, Total Loss: 0.02633560821413994\n",
      "Epoch 120/200, Loss_1: 0.014430062845349312, Loss_2: 0.011132916435599327, Total Loss: 0.02556297928094864\n",
      "Epoch 140/200, Loss_1: 0.013552121818065643, Loss_2: 0.01140853576362133, Total Loss: 0.024960657581686974\n",
      "Epoch 160/200, Loss_1: 0.012874624691903591, Loss_2: 0.011635280214250088, Total Loss: 0.02450990490615368\n",
      "Epoch 180/200, Loss_1: 0.01244295947253704, Loss_2: 0.011745358817279339, Total Loss: 0.024188317358493805\n",
      "Epoch 200/200, Loss_1: 0.012176068499684334, Loss_2: 0.011788591742515564, Total Loss: 0.023964660242199898\n",
      "Epoch 20/200, Loss_1: 0.03732503950595856, Loss_2: 0.013561020605266094, Total Loss: 0.050886061042547226\n",
      "Epoch 40/200, Loss_1: 0.020997554063796997, Loss_2: 0.014208568260073662, Total Loss: 0.03520612418651581\n",
      "Epoch 60/200, Loss_1: 0.013565528206527233, Loss_2: 0.01326313428580761, Total Loss: 0.026828661561012268\n",
      "Epoch 80/200, Loss_1: 0.011753169819712639, Loss_2: 0.01308596134185791, Total Loss: 0.02483913116157055\n",
      "Epoch 100/200, Loss_1: 0.01232076808810234, Loss_2: 0.01191207580268383, Total Loss: 0.02423284389078617\n",
      "Epoch 120/200, Loss_1: 0.01215930376201868, Loss_2: 0.011744337156414986, Total Loss: 0.02390364184975624\n",
      "Epoch 140/200, Loss_1: 0.012051105499267578, Loss_2: 0.011651134118437767, Total Loss: 0.023702239617705345\n",
      "Epoch 160/200, Loss_1: 0.01199998240917921, Loss_2: 0.01156013272702694, Total Loss: 0.023560114204883575\n",
      "Epoch 180/200, Loss_1: 0.011879118159413338, Loss_2: 0.011574240401387215, Total Loss: 0.023453358560800552\n",
      "Epoch 200/200, Loss_1: 0.0118098771199584, Loss_2: 0.011562203988432884, Total Loss: 0.02337208017706871\n",
      "Epoch 20/200, Loss_1: 0.019370079040527344, Loss_2: 0.01649203710258007, Total Loss: 0.035862118005752563\n",
      "Epoch 40/200, Loss_1: 0.01088633295148611, Loss_2: 0.015330811962485313, Total Loss: 0.02621714398264885\n",
      "Epoch 60/200, Loss_1: 0.010858436115086079, Loss_2: 0.01380517054349184, Total Loss: 0.02466360665857792\n",
      "Epoch 80/200, Loss_1: 0.011073431000113487, Loss_2: 0.01274900883436203, Total Loss: 0.023822439834475517\n",
      "Epoch 100/200, Loss_1: 0.01119767501950264, Loss_2: 0.012213348411023617, Total Loss: 0.02341102436184883\n",
      "Epoch 120/200, Loss_1: 0.011556635610759258, Loss_2: 0.011707697995007038, Total Loss: 0.023264333605766296\n",
      "Epoch 140/200, Loss_1: 0.01168422494083643, Loss_2: 0.011526774615049362, Total Loss: 0.023210998624563217\n",
      "Epoch 160/200, Loss_1: 0.011665144003927708, Loss_2: 0.011510681360960007, Total Loss: 0.02317582443356514\n",
      "Epoch 180/200, Loss_1: 0.011637666262686253, Loss_2: 0.011509845964610577, Total Loss: 0.02314751222729683\n",
      "Epoch 200/200, Loss_1: 0.01162266917526722, Loss_2: 0.011500135064125061, Total Loss: 0.02312280423939228\n",
      "Epoch 20/200, Loss_1: 0.05577961727976799, Loss_2: 0.06596682965755463, Total Loss: 0.12174645066261292\n",
      "Epoch 40/200, Loss_1: 0.02155233547091484, Loss_2: 0.02594626694917679, Total Loss: 0.04749860242009163\n",
      "Epoch 60/200, Loss_1: 0.013348596170544624, Loss_2: 0.026085400953888893, Total Loss: 0.03943399712443352\n",
      "Epoch 80/200, Loss_1: 0.0106849055737257, Loss_2: 0.02523009106516838, Total Loss: 0.03591499477624893\n",
      "Epoch 100/200, Loss_1: 0.010261861607432365, Loss_2: 0.023652486503124237, Total Loss: 0.03391434997320175\n",
      "Epoch 120/200, Loss_1: 0.00943630188703537, Loss_2: 0.023380139842629433, Total Loss: 0.03281643986701965\n",
      "Epoch 140/200, Loss_1: 0.009025301784276962, Loss_2: 0.023142196238040924, Total Loss: 0.032167498022317886\n",
      "Epoch 160/200, Loss_1: 0.00892876647412777, Loss_2: 0.022768614813685417, Total Loss: 0.03169738128781319\n",
      "Epoch 180/200, Loss_1: 0.008966663852334023, Loss_2: 0.022289572283625603, Total Loss: 0.031256236135959625\n",
      "Epoch 200/200, Loss_1: 0.009147735312581062, Loss_2: 0.02157999388873577, Total Loss: 0.030727729201316833\n",
      "Epoch 20/200, Loss_1: 0.01897108554840088, Loss_2: 0.021494729444384575, Total Loss: 0.0404658168554306\n",
      "Epoch 40/200, Loss_1: 0.01065505389124155, Loss_2: 0.022623229771852493, Total Loss: 0.03327828273177147\n",
      "Epoch 60/200, Loss_1: 0.009233695454895496, Loss_2: 0.019931763410568237, Total Loss: 0.02916545793414116\n",
      "Epoch 80/200, Loss_1: 0.010018449276685715, Loss_2: 0.016940955072641373, Total Loss: 0.026959404349327087\n",
      "Epoch 100/200, Loss_1: 0.011020474135875702, Loss_2: 0.014531399123370647, Total Loss: 0.025551874190568924\n",
      "Epoch 120/200, Loss_1: 0.011612609028816223, Loss_2: 0.012964677065610886, Total Loss: 0.02457728609442711\n",
      "Epoch 140/200, Loss_1: 0.011844292283058167, Loss_2: 0.01211056113243103, Total Loss: 0.023954853415489197\n",
      "Epoch 160/200, Loss_1: 0.0118548683822155, Loss_2: 0.011750271543860435, Total Loss: 0.023605139926075935\n",
      "Epoch 180/200, Loss_1: 0.01176434475928545, Loss_2: 0.011648820713162422, Total Loss: 0.023413166403770447\n",
      "Epoch 200/200, Loss_1: 0.011690984480082989, Loss_2: 0.011607933789491653, Total Loss: 0.023298919200897217\n",
      "Epoch 20/200, Loss_1: 0.013080517761409283, Loss_2: 0.04042009264230728, Total Loss: 0.05350061133503914\n",
      "Epoch 40/200, Loss_1: 0.014092824421823025, Loss_2: 0.025163400918245316, Total Loss: 0.039256226271390915\n",
      "Epoch 60/200, Loss_1: 0.01363560650497675, Loss_2: 0.01921325922012329, Total Loss: 0.032848864793777466\n",
      "Epoch 80/200, Loss_1: 0.016614610329270363, Loss_2: 0.012567635625600815, Total Loss: 0.029182245954871178\n",
      "Epoch 100/200, Loss_1: 0.016375519335269928, Loss_2: 0.01102361362427473, Total Loss: 0.027399133890867233\n",
      "Epoch 120/200, Loss_1: 0.015418952330946922, Loss_2: 0.010889451950788498, Total Loss: 0.02630840428173542\n",
      "Epoch 140/200, Loss_1: 0.01463963370770216, Loss_2: 0.01085935439914465, Total Loss: 0.02549898810684681\n",
      "Epoch 160/200, Loss_1: 0.013929151929914951, Loss_2: 0.010950678959488869, Total Loss: 0.024879831820726395\n",
      "Epoch 180/200, Loss_1: 0.013201059773564339, Loss_2: 0.011205035261809826, Total Loss: 0.02440609410405159\n",
      "Epoch 200/200, Loss_1: 0.012621997855603695, Loss_2: 0.011430853046476841, Total Loss: 0.024052850902080536\n",
      "Epoch 20/200, Loss_1: 0.013281588442623615, Loss_2: 0.01927032694220543, Total Loss: 0.03255191445350647\n",
      "Epoch 40/200, Loss_1: 0.012333869002759457, Loss_2: 0.012205640785396099, Total Loss: 0.024539509788155556\n",
      "Epoch 60/200, Loss_1: 0.011286011897027493, Loss_2: 0.01241645310074091, Total Loss: 0.023702464997768402\n",
      "Epoch 80/200, Loss_1: 0.01167867612093687, Loss_2: 0.011708731763064861, Total Loss: 0.023387407884001732\n",
      "Epoch 100/200, Loss_1: 0.011538361199200153, Loss_2: 0.01168770156800747, Total Loss: 0.023226063698530197\n",
      "Epoch 120/200, Loss_1: 0.011532480828464031, Loss_2: 0.011602448299527168, Total Loss: 0.023134928196668625\n",
      "Epoch 140/200, Loss_1: 0.011511768214404583, Loss_2: 0.011567402631044388, Total Loss: 0.023079171776771545\n",
      "Epoch 160/200, Loss_1: 0.01149327028542757, Loss_2: 0.011549781076610088, Total Loss: 0.02304305136203766\n",
      "Epoch 180/200, Loss_1: 0.011483615264296532, Loss_2: 0.011534320190548897, Total Loss: 0.02301793545484543\n",
      "Epoch 200/200, Loss_1: 0.011473901569843292, Loss_2: 0.011525580659508705, Total Loss: 0.022999482229351997\n",
      "Epoch 20/200, Loss_1: 0.022638674825429916, Loss_2: 0.00974626000970602, Total Loss: 0.03238493576645851\n",
      "Epoch 40/200, Loss_1: 0.01356404460966587, Loss_2: 0.012831385247409344, Total Loss: 0.02639542892575264\n",
      "Epoch 60/200, Loss_1: 0.012499217875301838, Loss_2: 0.011911598034203053, Total Loss: 0.02441081590950489\n",
      "Epoch 80/200, Loss_1: 0.012261590920388699, Loss_2: 0.011635038070380688, Total Loss: 0.023896628990769386\n",
      "Epoch 100/200, Loss_1: 0.011871048249304295, Loss_2: 0.011746061034500599, Total Loss: 0.023617109283804893\n",
      "Epoch 120/200, Loss_1: 0.011858288198709488, Loss_2: 0.011562849394977093, Total Loss: 0.023421138525009155\n",
      "Epoch 140/200, Loss_1: 0.011769391596317291, Loss_2: 0.011447322554886341, Total Loss: 0.023216713219881058\n",
      "Epoch 160/200, Loss_1: 0.011651053093373775, Loss_2: 0.011478548869490623, Total Loss: 0.023129601031541824\n",
      "Epoch 180/200, Loss_1: 0.011616102419793606, Loss_2: 0.011459981091320515, Total Loss: 0.02307608351111412\n",
      "Epoch 200/200, Loss_1: 0.011582935228943825, Loss_2: 0.011455648578703403, Total Loss: 0.023038584738969803\n",
      "Epoch 20/200, Loss_1: 0.021863887086510658, Loss_2: 0.010479515418410301, Total Loss: 0.03234340250492096\n",
      "Epoch 40/200, Loss_1: 0.017070455476641655, Loss_2: 0.010574505664408207, Total Loss: 0.027644962072372437\n",
      "Epoch 60/200, Loss_1: 0.014178944751620293, Loss_2: 0.011249159462749958, Total Loss: 0.025428105145692825\n",
      "Epoch 80/200, Loss_1: 0.012466050684452057, Loss_2: 0.01170309353619814, Total Loss: 0.02416914328932762\n",
      "Epoch 100/200, Loss_1: 0.011892925947904587, Loss_2: 0.011758243665099144, Total Loss: 0.02365116961300373\n",
      "Epoch 120/200, Loss_1: 0.011711622588336468, Loss_2: 0.011712806299328804, Total Loss: 0.023424427956342697\n",
      "Epoch 140/200, Loss_1: 0.011629410088062286, Loss_2: 0.011671502143144608, Total Loss: 0.023300912231206894\n",
      "Epoch 160/200, Loss_1: 0.011607033200562, Loss_2: 0.01161480974406004, Total Loss: 0.02322184294462204\n",
      "Epoch 180/200, Loss_1: 0.011583668179810047, Loss_2: 0.011583668179810047, Total Loss: 0.023167336359620094\n",
      "Epoch 200/200, Loss_1: 0.011567438952624798, Loss_2: 0.011560099199414253, Total Loss: 0.023127537220716476\n",
      "Epoch 20/200, Loss_1: 0.01972118578851223, Loss_2: 0.03171519935131073, Total Loss: 0.05143638700246811\n",
      "Epoch 40/200, Loss_1: 0.016921013593673706, Loss_2: 0.022063953801989555, Total Loss: 0.03898496925830841\n",
      "Epoch 60/200, Loss_1: 0.013559257611632347, Loss_2: 0.018128084018826485, Total Loss: 0.03168734163045883\n",
      "Epoch 80/200, Loss_1: 0.012672433629631996, Loss_2: 0.016542816534638405, Total Loss: 0.0292152501642704\n",
      "Epoch 100/200, Loss_1: 0.012437472119927406, Loss_2: 0.014880417846143246, Total Loss: 0.027317889034748077\n",
      "Epoch 120/200, Loss_1: 0.012572702951729298, Loss_2: 0.013486928306519985, Total Loss: 0.026059631258249283\n",
      "Epoch 140/200, Loss_1: 0.01256201509386301, Loss_2: 0.012723587453365326, Total Loss: 0.02528560161590576\n",
      "Epoch 160/200, Loss_1: 0.012363160029053688, Loss_2: 0.012426340021193027, Total Loss: 0.02478950098156929\n",
      "Epoch 180/200, Loss_1: 0.012166021391749382, Loss_2: 0.012280793860554695, Total Loss: 0.024446815252304077\n",
      "Epoch 200/200, Loss_1: 0.01202853862196207, Loss_2: 0.012166142463684082, Total Loss: 0.024194680154323578\n",
      "Epoch 20/200, Loss_1: 0.023551568388938904, Loss_2: 0.016356725245714188, Total Loss: 0.03990829363465309\n",
      "Epoch 40/200, Loss_1: 0.014647184871137142, Loss_2: 0.012697484344244003, Total Loss: 0.02734467014670372\n",
      "Epoch 60/200, Loss_1: 0.012183037586510181, Loss_2: 0.012273754924535751, Total Loss: 0.024456791579723358\n",
      "Epoch 80/200, Loss_1: 0.011727339588105679, Loss_2: 0.012171618640422821, Total Loss: 0.023898959159851074\n",
      "Epoch 100/200, Loss_1: 0.011867241002619267, Loss_2: 0.011664669029414654, Total Loss: 0.02353191003203392\n",
      "Epoch 120/200, Loss_1: 0.011708446778357029, Loss_2: 0.011624656617641449, Total Loss: 0.023333102464675903\n",
      "Epoch 140/200, Loss_1: 0.011690091341733932, Loss_2: 0.01152715552598238, Total Loss: 0.023217245936393738\n",
      "Epoch 160/200, Loss_1: 0.01164058968424797, Loss_2: 0.011505703441798687, Total Loss: 0.023146294057369232\n",
      "Epoch 180/200, Loss_1: 0.01161104440689087, Loss_2: 0.011490008793771267, Total Loss: 0.02310105413198471\n",
      "Epoch 200/200, Loss_1: 0.0115895327180624, Loss_2: 0.011480635963380337, Total Loss: 0.023070167750120163\n",
      "Epoch 20/200, Loss_1: 0.025233982130885124, Loss_2: 0.0330626517534256, Total Loss: 0.05829663574695587\n",
      "Epoch 40/200, Loss_1: 0.01522779930382967, Loss_2: 0.0168454609811306, Total Loss: 0.032073259353637695\n",
      "Epoch 60/200, Loss_1: 0.013625556603074074, Loss_2: 0.014283980242908001, Total Loss: 0.0279095359146595\n",
      "Epoch 80/200, Loss_1: 0.013607841916382313, Loss_2: 0.012413174845278263, Total Loss: 0.026021016761660576\n",
      "Epoch 100/200, Loss_1: 0.013282456435263157, Loss_2: 0.011884883977472782, Total Loss: 0.02516734041273594\n",
      "Epoch 120/200, Loss_1: 0.012956364080309868, Loss_2: 0.011700408533215523, Total Loss: 0.02465677261352539\n",
      "Epoch 140/200, Loss_1: 0.01268763281404972, Loss_2: 0.011608376167714596, Total Loss: 0.024296008050441742\n",
      "Epoch 160/200, Loss_1: 0.012431795708835125, Loss_2: 0.01159715186804533, Total Loss: 0.024028947576880455\n",
      "Epoch 180/200, Loss_1: 0.012238150462508202, Loss_2: 0.011591012589633465, Total Loss: 0.023829162120819092\n",
      "Epoch 200/200, Loss_1: 0.012093430384993553, Loss_2: 0.01158362627029419, Total Loss: 0.023677056655287743\n",
      "Epoch 20/200, Loss_1: 0.01964547485113144, Loss_2: 0.02960394322872162, Total Loss: 0.04924941807985306\n",
      "Epoch 40/200, Loss_1: 0.016555603593587875, Loss_2: 0.02118646539747715, Total Loss: 0.037742070853710175\n",
      "Epoch 60/200, Loss_1: 0.013903940096497536, Loss_2: 0.019563009962439537, Total Loss: 0.03346695005893707\n",
      "Epoch 80/200, Loss_1: 0.011140831746160984, Loss_2: 0.0190565325319767, Total Loss: 0.03019736334681511\n",
      "Epoch 100/200, Loss_1: 0.010591230355203152, Loss_2: 0.01743609830737114, Total Loss: 0.028027329593896866\n",
      "Epoch 120/200, Loss_1: 0.0108363451436162, Loss_2: 0.015452300198376179, Total Loss: 0.026288645341992378\n",
      "Epoch 140/200, Loss_1: 0.01107768528163433, Loss_2: 0.014030642807483673, Total Loss: 0.025108328089118004\n",
      "Epoch 160/200, Loss_1: 0.011286607943475246, Loss_2: 0.013122565113008022, Total Loss: 0.02440917305648327\n",
      "Epoch 180/200, Loss_1: 0.011519797146320343, Loss_2: 0.012494362890720367, Total Loss: 0.02401416003704071\n",
      "Epoch 200/200, Loss_1: 0.011680621653795242, Loss_2: 0.012099385261535645, Total Loss: 0.023780006915330887\n",
      "Epoch 20/200, Loss_1: 0.028084278106689453, Loss_2: 0.02927454374730587, Total Loss: 0.05735882371664047\n",
      "Epoch 40/200, Loss_1: 0.02358444780111313, Loss_2: 0.02053110860288143, Total Loss: 0.04411555826663971\n",
      "Epoch 60/200, Loss_1: 0.020057443529367447, Loss_2: 0.016616953536868095, Total Loss: 0.03667439520359039\n",
      "Epoch 80/200, Loss_1: 0.01719973422586918, Loss_2: 0.014174715615808964, Total Loss: 0.03137445077300072\n",
      "Epoch 100/200, Loss_1: 0.015096955001354218, Loss_2: 0.012833493761718273, Total Loss: 0.027930449694395065\n",
      "Epoch 120/200, Loss_1: 0.013659484684467316, Loss_2: 0.012118009850382805, Total Loss: 0.02577749453485012\n",
      "Epoch 140/200, Loss_1: 0.012884136289358139, Loss_2: 0.011808831244707108, Total Loss: 0.024692967534065247\n",
      "Epoch 160/200, Loss_1: 0.012440096586942673, Loss_2: 0.011697573587298393, Total Loss: 0.024137670174241066\n",
      "Epoch 180/200, Loss_1: 0.012150825001299381, Loss_2: 0.01166264247149229, Total Loss: 0.023813467472791672\n",
      "Epoch 200/200, Loss_1: 0.011960899457335472, Loss_2: 0.011649941094219685, Total Loss: 0.02361084148287773\n",
      "Epoch 20/200, Loss_1: 0.03392334654927254, Loss_2: 0.03397740423679352, Total Loss: 0.06790074706077576\n",
      "Epoch 40/200, Loss_1: 0.01521744392812252, Loss_2: 0.02041529305279255, Total Loss: 0.03563273698091507\n",
      "Epoch 60/200, Loss_1: 0.00929937046021223, Loss_2: 0.021917587146162987, Total Loss: 0.031216956675052643\n",
      "Epoch 80/200, Loss_1: 0.00922449678182602, Loss_2: 0.020310863852500916, Total Loss: 0.029535360634326935\n",
      "Epoch 100/200, Loss_1: 0.0102878138422966, Loss_2: 0.017609430477023125, Total Loss: 0.027897244319319725\n",
      "Epoch 120/200, Loss_1: 0.010664805769920349, Loss_2: 0.015777306631207466, Total Loss: 0.026442112401127815\n",
      "Epoch 140/200, Loss_1: 0.010985808447003365, Loss_2: 0.014165349304676056, Total Loss: 0.02515115775167942\n",
      "Epoch 160/200, Loss_1: 0.011336253024637699, Loss_2: 0.01289887074381113, Total Loss: 0.02423512376844883\n",
      "Epoch 180/200, Loss_1: 0.011490088887512684, Loss_2: 0.012216798961162567, Total Loss: 0.023706886917352676\n",
      "Epoch 200/200, Loss_1: 0.011516633443534374, Loss_2: 0.01193730067461729, Total Loss: 0.023453934118151665\n",
      "Epoch 20/200, Loss_1: 0.03072596900165081, Loss_2: 0.01918879523873329, Total Loss: 0.04991476237773895\n",
      "Epoch 40/200, Loss_1: 0.014913534745573997, Loss_2: 0.015426629222929478, Total Loss: 0.03034016489982605\n",
      "Epoch 60/200, Loss_1: 0.012010120786726475, Loss_2: 0.014248961582779884, Total Loss: 0.026259083300828934\n",
      "Epoch 80/200, Loss_1: 0.0116554144769907, Loss_2: 0.012680213898420334, Total Loss: 0.024335628375411034\n",
      "Epoch 100/200, Loss_1: 0.011756411753594875, Loss_2: 0.01174913439899683, Total Loss: 0.023505546152591705\n",
      "Epoch 120/200, Loss_1: 0.011931037530303001, Loss_2: 0.011396219953894615, Total Loss: 0.023327257484197617\n",
      "Epoch 140/200, Loss_1: 0.011661910451948643, Loss_2: 0.011586956679821014, Total Loss: 0.023248866200447083\n",
      "Epoch 160/200, Loss_1: 0.011700846254825592, Loss_2: 0.01149708405137062, Total Loss: 0.023197930306196213\n",
      "Epoch 180/200, Loss_1: 0.01168110128492117, Loss_2: 0.011477693915367126, Total Loss: 0.02315879613161087\n",
      "Epoch 200/200, Loss_1: 0.011644192971289158, Loss_2: 0.011483044363558292, Total Loss: 0.02312723733484745\n",
      "Epoch 20/200, Loss_1: 0.03541610762476921, Loss_2: 0.02641790360212326, Total Loss: 0.06183401122689247\n",
      "Epoch 40/200, Loss_1: 0.01632518135011196, Loss_2: 0.0162503682076931, Total Loss: 0.03257554769515991\n",
      "Epoch 60/200, Loss_1: 0.01354935672134161, Loss_2: 0.013512548059225082, Total Loss: 0.027061905711889267\n",
      "Epoch 80/200, Loss_1: 0.011424361728131771, Loss_2: 0.014182215556502342, Total Loss: 0.02560657635331154\n",
      "Epoch 100/200, Loss_1: 0.011770540848374367, Loss_2: 0.013020817190408707, Total Loss: 0.024791358038783073\n",
      "Epoch 120/200, Loss_1: 0.011942056939005852, Loss_2: 0.012368644587695599, Total Loss: 0.024310700595378876\n",
      "Epoch 140/200, Loss_1: 0.012011741288006306, Loss_2: 0.012010645121335983, Total Loss: 0.024022385478019714\n",
      "Epoch 160/200, Loss_1: 0.012012223713099957, Loss_2: 0.011815844103693962, Total Loss: 0.023828066885471344\n",
      "Epoch 180/200, Loss_1: 0.011991472914814949, Loss_2: 0.0116919856518507, Total Loss: 0.02368345856666565\n",
      "Epoch 200/200, Loss_1: 0.011948669329285622, Loss_2: 0.011619506403803825, Total Loss: 0.023568175733089447\n",
      "Epoch 20/200, Loss_1: 0.03146696090698242, Loss_2: 0.01856471411883831, Total Loss: 0.05003167688846588\n",
      "Epoch 40/200, Loss_1: 0.019670238718390465, Loss_2: 0.020114928483963013, Total Loss: 0.03978516906499863\n",
      "Epoch 60/200, Loss_1: 0.016127368435263634, Loss_2: 0.014596616849303246, Total Loss: 0.03072398528456688\n",
      "Epoch 80/200, Loss_1: 0.01453049760311842, Loss_2: 0.013152021914720535, Total Loss: 0.02768252044916153\n",
      "Epoch 100/200, Loss_1: 0.012872811406850815, Loss_2: 0.013323555700480938, Total Loss: 0.026196368038654327\n",
      "Epoch 120/200, Loss_1: 0.011809119023382664, Loss_2: 0.013546532019972801, Total Loss: 0.02535565197467804\n",
      "Epoch 140/200, Loss_1: 0.01144891232252121, Loss_2: 0.013380559161305428, Total Loss: 0.024829471483826637\n",
      "Epoch 160/200, Loss_1: 0.011405101977288723, Loss_2: 0.013057488016784191, Total Loss: 0.024462589994072914\n",
      "Epoch 180/200, Loss_1: 0.011406595818698406, Loss_2: 0.012781210243701935, Total Loss: 0.024187806993722916\n",
      "Epoch 200/200, Loss_1: 0.011411999352276325, Loss_2: 0.01256288681179285, Total Loss: 0.023974886164069176\n",
      "Epoch 20/200, Loss_1: 0.031263843178749084, Loss_2: 0.02192402072250843, Total Loss: 0.053187862038612366\n",
      "Epoch 40/200, Loss_1: 0.017603982239961624, Loss_2: 0.013342518359422684, Total Loss: 0.030946500599384308\n",
      "Epoch 60/200, Loss_1: 0.013918910175561905, Loss_2: 0.01232400257140398, Total Loss: 0.02624291181564331\n",
      "Epoch 80/200, Loss_1: 0.012051789090037346, Loss_2: 0.012751933187246323, Total Loss: 0.02480372227728367\n",
      "Epoch 100/200, Loss_1: 0.011769413948059082, Loss_2: 0.01246897503733635, Total Loss: 0.02423838898539543\n",
      "Epoch 120/200, Loss_1: 0.011962296441197395, Loss_2: 0.011965028010308743, Total Loss: 0.023927323520183563\n",
      "Epoch 140/200, Loss_1: 0.011874259449541569, Loss_2: 0.011847259476780891, Total Loss: 0.023721519857645035\n",
      "Epoch 160/200, Loss_1: 0.011821024119853973, Loss_2: 0.011756985448300838, Total Loss: 0.023578010499477386\n",
      "Epoch 180/200, Loss_1: 0.011777219362556934, Loss_2: 0.0116916224360466, Total Loss: 0.02346884086728096\n",
      "Epoch 200/200, Loss_1: 0.011737112887203693, Loss_2: 0.011645568534731865, Total Loss: 0.023382682353258133\n",
      "Epoch 20/200, Loss_1: 0.021187426522374153, Loss_2: 0.030081208795309067, Total Loss: 0.05126863718032837\n",
      "Epoch 40/200, Loss_1: 0.015845082700252533, Loss_2: 0.020071614533662796, Total Loss: 0.03591669723391533\n",
      "Epoch 60/200, Loss_1: 0.013091382570564747, Loss_2: 0.016805224120616913, Total Loss: 0.029896605759859085\n",
      "Epoch 80/200, Loss_1: 0.01189301535487175, Loss_2: 0.015830332413315773, Total Loss: 0.027723347768187523\n",
      "Epoch 100/200, Loss_1: 0.011473910883069038, Loss_2: 0.014605569653213024, Total Loss: 0.026079479604959488\n",
      "Epoch 120/200, Loss_1: 0.01152708288282156, Loss_2: 0.013423187658190727, Total Loss: 0.024950269609689713\n",
      "Epoch 140/200, Loss_1: 0.011769689619541168, Loss_2: 0.012492295354604721, Total Loss: 0.02426198497414589\n",
      "Epoch 160/200, Loss_1: 0.012207277119159698, Loss_2: 0.011656719259917736, Total Loss: 0.02386399731040001\n",
      "Epoch 180/200, Loss_1: 0.012038683518767357, Loss_2: 0.011595215648412704, Total Loss: 0.02363389916718006\n",
      "Epoch 200/200, Loss_1: 0.011903258040547371, Loss_2: 0.011582065373659134, Total Loss: 0.023485323414206505\n",
      "Epoch 20/200, Loss_1: 0.0169488824903965, Loss_2: 0.012438256293535233, Total Loss: 0.029387138783931732\n",
      "Epoch 40/200, Loss_1: 0.012572146020829678, Loss_2: 0.011869900859892368, Total Loss: 0.024442046880722046\n",
      "Epoch 60/200, Loss_1: 0.0119628319516778, Loss_2: 0.011787401512265205, Total Loss: 0.02375023439526558\n",
      "Epoch 80/200, Loss_1: 0.011980501934885979, Loss_2: 0.011503621935844421, Total Loss: 0.0234841238707304\n",
      "Epoch 100/200, Loss_1: 0.011754011735320091, Loss_2: 0.011577366851270199, Total Loss: 0.023331377655267715\n",
      "Epoch 120/200, Loss_1: 0.011722791939973831, Loss_2: 0.011507712304592133, Total Loss: 0.023230504244565964\n",
      "Epoch 140/200, Loss_1: 0.011668426916003227, Loss_2: 0.011491368524730206, Total Loss: 0.023159794509410858\n",
      "Epoch 160/200, Loss_1: 0.011612621136009693, Loss_2: 0.011496420949697495, Total Loss: 0.023109041154384613\n",
      "Epoch 180/200, Loss_1: 0.011579379439353943, Loss_2: 0.011492209509015083, Total Loss: 0.023071588948369026\n",
      "Epoch 200/200, Loss_1: 0.011554822325706482, Loss_2: 0.011488150805234909, Total Loss: 0.02304297313094139\n",
      "Epoch 20/200, Loss_1: 0.04139284789562225, Loss_2: 0.02988290973007679, Total Loss: 0.0712757557630539\n",
      "Epoch 40/200, Loss_1: 0.017798008397221565, Loss_2: 0.018580425530672073, Total Loss: 0.03637843579053879\n",
      "Epoch 60/200, Loss_1: 0.011311094276607037, Loss_2: 0.01782374642789364, Total Loss: 0.0291348397731781\n",
      "Epoch 80/200, Loss_1: 0.0096697136759758, Loss_2: 0.017763573676347733, Total Loss: 0.027433287352323532\n",
      "Epoch 100/200, Loss_1: 0.010418027639389038, Loss_2: 0.01606825739145279, Total Loss: 0.026486285030841827\n",
      "Epoch 120/200, Loss_1: 0.01073926966637373, Loss_2: 0.014854307286441326, Total Loss: 0.025593576952815056\n",
      "Epoch 140/200, Loss_1: 0.01099174190312624, Loss_2: 0.013755972497165203, Total Loss: 0.024747714400291443\n",
      "Epoch 160/200, Loss_1: 0.01122407615184784, Loss_2: 0.012815148569643497, Total Loss: 0.024039223790168762\n",
      "Epoch 180/200, Loss_1: 0.011361168697476387, Loss_2: 0.012188722379505634, Total Loss: 0.023549892008304596\n",
      "Epoch 200/200, Loss_1: 0.011444286443293095, Loss_2: 0.011840330436825752, Total Loss: 0.02328461781144142\n",
      "Epoch 20/200, Loss_1: 0.025394653901457787, Loss_2: 0.033916305750608444, Total Loss: 0.05931095778942108\n",
      "Epoch 40/200, Loss_1: 0.017245067283511162, Loss_2: 0.01764424704015255, Total Loss: 0.03488931432366371\n",
      "Epoch 60/200, Loss_1: 0.013755838386714458, Loss_2: 0.017239714041352272, Total Loss: 0.030995551496744156\n",
      "Epoch 80/200, Loss_1: 0.012177081778645515, Loss_2: 0.017525359988212585, Total Loss: 0.0297024417668581\n",
      "Epoch 100/200, Loss_1: 0.01179586909711361, Loss_2: 0.01679636724293232, Total Loss: 0.02859223634004593\n",
      "Epoch 120/200, Loss_1: 0.011994179338216782, Loss_2: 0.01568707637488842, Total Loss: 0.0276812557131052\n",
      "Epoch 140/200, Loss_1: 0.012076468206942081, Loss_2: 0.014819424599409103, Total Loss: 0.02689589187502861\n",
      "Epoch 160/200, Loss_1: 0.012120702303946018, Loss_2: 0.014090009033679962, Total Loss: 0.026210710406303406\n",
      "Epoch 180/200, Loss_1: 0.012199264019727707, Loss_2: 0.013415968045592308, Total Loss: 0.025615232065320015\n",
      "Epoch 200/200, Loss_1: 0.012278481386601925, Loss_2: 0.012826922349631786, Total Loss: 0.02510540373623371\n",
      "Epoch 20/200, Loss_1: 0.01701168529689312, Loss_2: 0.03305203095078468, Total Loss: 0.050063714385032654\n",
      "Epoch 40/200, Loss_1: 0.013104613870382309, Loss_2: 0.027386393398046494, Total Loss: 0.0404910072684288\n",
      "Epoch 60/200, Loss_1: 0.012435637414455414, Loss_2: 0.024965012446045876, Total Loss: 0.03740064799785614\n",
      "Epoch 80/200, Loss_1: 0.011002467013895512, Loss_2: 0.023078233003616333, Total Loss: 0.03408069908618927\n",
      "Epoch 100/200, Loss_1: 0.012545966543257236, Loss_2: 0.017962845042347908, Total Loss: 0.03050881251692772\n",
      "Epoch 120/200, Loss_1: 0.014307781122624874, Loss_2: 0.012783120386302471, Total Loss: 0.027090901508927345\n",
      "Epoch 140/200, Loss_1: 0.014324672520160675, Loss_2: 0.010878125205636024, Total Loss: 0.0252027977257967\n",
      "Epoch 160/200, Loss_1: 0.01338804978877306, Loss_2: 0.010914608836174011, Total Loss: 0.024302657693624496\n",
      "Epoch 180/200, Loss_1: 0.012627126649022102, Loss_2: 0.011230232194066048, Total Loss: 0.02385735884308815\n",
      "Epoch 200/200, Loss_1: 0.01214941032230854, Loss_2: 0.011499091051518917, Total Loss: 0.023648500442504883\n",
      "Epoch 20/200, Loss_1: 0.023096881806850433, Loss_2: 0.01904834620654583, Total Loss: 0.04214522987604141\n",
      "Epoch 40/200, Loss_1: 0.015058601275086403, Loss_2: 0.012637851759791374, Total Loss: 0.027696453034877777\n",
      "Epoch 60/200, Loss_1: 0.011155338026583195, Loss_2: 0.013844705186784267, Total Loss: 0.025000043213367462\n",
      "Epoch 80/200, Loss_1: 0.012349585071206093, Loss_2: 0.011779011227190495, Total Loss: 0.024128597229719162\n",
      "Epoch 100/200, Loss_1: 0.012384929694235325, Loss_2: 0.011422140523791313, Total Loss: 0.023807071149349213\n",
      "Epoch 120/200, Loss_1: 0.012013040482997894, Loss_2: 0.011598578654229641, Total Loss: 0.02361162006855011\n",
      "Epoch 140/200, Loss_1: 0.011914417147636414, Loss_2: 0.011559114791452885, Total Loss: 0.023473531007766724\n",
      "Epoch 160/200, Loss_1: 0.011827647686004639, Loss_2: 0.011538800783455372, Total Loss: 0.023366447538137436\n",
      "Epoch 180/200, Loss_1: 0.011699470691382885, Loss_2: 0.011577784083783627, Total Loss: 0.02327725477516651\n",
      "Epoch 200/200, Loss_1: 0.011625006794929504, Loss_2: 0.011582920327782631, Total Loss: 0.023207927122712135\n",
      "Epoch 20/200, Loss_1: 0.028859764337539673, Loss_2: 0.0415915809571743, Total Loss: 0.07045134902000427\n",
      "Epoch 40/200, Loss_1: 0.01447014044970274, Loss_2: 0.01710047945380211, Total Loss: 0.03157062083482742\n",
      "Epoch 60/200, Loss_1: 0.014396723359823227, Loss_2: 0.013986965641379356, Total Loss: 0.028383689001202583\n",
      "Epoch 80/200, Loss_1: 0.014069567434489727, Loss_2: 0.012421725317835808, Total Loss: 0.02649129182100296\n",
      "Epoch 100/200, Loss_1: 0.013591362163424492, Loss_2: 0.012068179436028004, Total Loss: 0.02565954253077507\n",
      "Epoch 120/200, Loss_1: 0.013068633154034615, Loss_2: 0.012100690975785255, Total Loss: 0.02516932412981987\n",
      "Epoch 140/200, Loss_1: 0.012737727724015713, Loss_2: 0.012081151828169823, Total Loss: 0.02481887862086296\n",
      "Epoch 160/200, Loss_1: 0.012538825161755085, Loss_2: 0.012009267695248127, Total Loss: 0.024548092857003212\n",
      "Epoch 180/200, Loss_1: 0.012379058636724949, Loss_2: 0.011950449086725712, Total Loss: 0.02432950772345066\n",
      "Epoch 200/200, Loss_1: 0.012243056669831276, Loss_2: 0.011904405429959297, Total Loss: 0.024147462099790573\n",
      "Epoch 20/200, Loss_1: 0.016593191772699356, Loss_2: 0.012093464843928814, Total Loss: 0.028686657547950745\n",
      "Epoch 40/200, Loss_1: 0.012476403266191483, Loss_2: 0.01159204263240099, Total Loss: 0.024068444967269897\n",
      "Epoch 60/200, Loss_1: 0.011736765503883362, Loss_2: 0.011718378402292728, Total Loss: 0.023455142974853516\n",
      "Epoch 80/200, Loss_1: 0.011805695481598377, Loss_2: 0.01142652053385973, Total Loss: 0.023232216015458107\n",
      "Epoch 100/200, Loss_1: 0.011640944518148899, Loss_2: 0.011509913019835949, Total Loss: 0.023150857537984848\n",
      "Epoch 120/200, Loss_1: 0.011634954251348972, Loss_2: 0.011469919234514236, Total Loss: 0.023104872554540634\n",
      "Epoch 140/200, Loss_1: 0.011574761942029, Loss_2: 0.011497817933559418, Total Loss: 0.023072579875588417\n",
      "Epoch 160/200, Loss_1: 0.011551596224308014, Loss_2: 0.011495087295770645, Total Loss: 0.02304668352007866\n",
      "Epoch 180/200, Loss_1: 0.011530870571732521, Loss_2: 0.011494123376905918, Total Loss: 0.023024994879961014\n",
      "Epoch 200/200, Loss_1: 0.011515948921442032, Loss_2: 0.01149065513163805, Total Loss: 0.023006603121757507\n",
      "Epoch 20/200, Loss_1: 0.03215242177248001, Loss_2: 0.023214273154735565, Total Loss: 0.055366694927215576\n",
      "Epoch 40/200, Loss_1: 0.014090023003518581, Loss_2: 0.025306832045316696, Total Loss: 0.03939685598015785\n",
      "Epoch 60/200, Loss_1: 0.00896450225263834, Loss_2: 0.023030374199151993, Total Loss: 0.03199487552046776\n",
      "Epoch 80/200, Loss_1: 0.011391091160476208, Loss_2: 0.015538566745817661, Total Loss: 0.02692965790629387\n",
      "Epoch 100/200, Loss_1: 0.013908007182180882, Loss_2: 0.01116959098726511, Total Loss: 0.02507759816944599\n",
      "Epoch 120/200, Loss_1: 0.0129779614508152, Loss_2: 0.011288792826235294, Total Loss: 0.02426675334572792\n",
      "Epoch 140/200, Loss_1: 0.012531081214547157, Loss_2: 0.011337433941662312, Total Loss: 0.023868516087532043\n",
      "Epoch 160/200, Loss_1: 0.01247254479676485, Loss_2: 0.011196586303412914, Total Loss: 0.023669131100177765\n",
      "Epoch 180/200, Loss_1: 0.012253992259502411, Loss_2: 0.011301301419734955, Total Loss: 0.023555293679237366\n",
      "Epoch 200/200, Loss_1: 0.012135070748627186, Loss_2: 0.01133959274739027, Total Loss: 0.023474663496017456\n",
      "Epoch 20/200, Loss_1: 0.01661592721939087, Loss_2: 0.011401144787669182, Total Loss: 0.02801707200706005\n",
      "Epoch 40/200, Loss_1: 0.011783924885094166, Loss_2: 0.013529923744499683, Total Loss: 0.02531384862959385\n",
      "Epoch 60/200, Loss_1: 0.01287045981734991, Loss_2: 0.011286349035799503, Total Loss: 0.024156808853149414\n",
      "Epoch 80/200, Loss_1: 0.01187087967991829, Loss_2: 0.011853131465613842, Total Loss: 0.023724012076854706\n",
      "Epoch 100/200, Loss_1: 0.011924078688025475, Loss_2: 0.011554074473679066, Total Loss: 0.023478154093027115\n",
      "Epoch 120/200, Loss_1: 0.011721999384462833, Loss_2: 0.011599358171224594, Total Loss: 0.023321356624364853\n",
      "Epoch 140/200, Loss_1: 0.011681513860821724, Loss_2: 0.01153563242405653, Total Loss: 0.02321714535355568\n",
      "Epoch 160/200, Loss_1: 0.011624418199062347, Loss_2: 0.011522671207785606, Total Loss: 0.023147089406847954\n",
      "Epoch 180/200, Loss_1: 0.011585542932152748, Loss_2: 0.01151073258370161, Total Loss: 0.023096274584531784\n",
      "Epoch 200/200, Loss_1: 0.01155636366456747, Loss_2: 0.011502087116241455, Total Loss: 0.0230584517121315\n",
      "Epoch 20/200, Loss_1: 0.021297281607985497, Loss_2: 0.013519011437892914, Total Loss: 0.03481629490852356\n",
      "Epoch 40/200, Loss_1: 0.012162533588707447, Loss_2: 0.015611806884407997, Total Loss: 0.02777434140443802\n",
      "Epoch 60/200, Loss_1: 0.011576361022889614, Loss_2: 0.014492950402200222, Total Loss: 0.026069311425089836\n",
      "Epoch 80/200, Loss_1: 0.012354779988527298, Loss_2: 0.01247206050902605, Total Loss: 0.024826839566230774\n",
      "Epoch 100/200, Loss_1: 0.012334287166595459, Loss_2: 0.011929020285606384, Total Loss: 0.024263307452201843\n",
      "Epoch 120/200, Loss_1: 0.012283033691346645, Loss_2: 0.011676250025629997, Total Loss: 0.023959282785654068\n",
      "Epoch 140/200, Loss_1: 0.0121874138712883, Loss_2: 0.011578266508877277, Total Loss: 0.023765679448843002\n",
      "Epoch 160/200, Loss_1: 0.012105089612305164, Loss_2: 0.011518466286361217, Total Loss: 0.023623555898666382\n",
      "Epoch 180/200, Loss_1: 0.012011687271296978, Loss_2: 0.011501421220600605, Total Loss: 0.023513108491897583\n",
      "Epoch 200/200, Loss_1: 0.011939679272472858, Loss_2: 0.011484627611935139, Total Loss: 0.023424306884407997\n",
      "Epoch 20/200, Loss_1: 0.01902139000594616, Loss_2: 0.01720484159886837, Total Loss: 0.03622623160481453\n",
      "Epoch 40/200, Loss_1: 0.010127509944140911, Loss_2: 0.015303226187825203, Total Loss: 0.02543073520064354\n",
      "Epoch 60/200, Loss_1: 0.011557373218238354, Loss_2: 0.012312461622059345, Total Loss: 0.0238698348402977\n",
      "Epoch 80/200, Loss_1: 0.011736984364688396, Loss_2: 0.011698105372488499, Total Loss: 0.023435089737176895\n",
      "Epoch 100/200, Loss_1: 0.011379268020391464, Loss_2: 0.011867830529808998, Total Loss: 0.023247098550200462\n",
      "Epoch 120/200, Loss_1: 0.011542986147105694, Loss_2: 0.011605236679315567, Total Loss: 0.023148223757743835\n",
      "Epoch 140/200, Loss_1: 0.011501002125442028, Loss_2: 0.011592683382332325, Total Loss: 0.023093685507774353\n",
      "Epoch 160/200, Loss_1: 0.011512127704918385, Loss_2: 0.011549445800483227, Total Loss: 0.02306157350540161\n",
      "Epoch 180/200, Loss_1: 0.011500239372253418, Loss_2: 0.01154086273163557, Total Loss: 0.023041103035211563\n",
      "Epoch 200/200, Loss_1: 0.011498293839395046, Loss_2: 0.011528617702424526, Total Loss: 0.023026911541819572\n",
      "Epoch 20/200, Loss_1: 0.03501737490296364, Loss_2: 0.01464050356298685, Total Loss: 0.049657877534627914\n",
      "Epoch 40/200, Loss_1: 0.01920984499156475, Loss_2: 0.017262151464819908, Total Loss: 0.03647199645638466\n",
      "Epoch 60/200, Loss_1: 0.014083504676818848, Loss_2: 0.01525073777884245, Total Loss: 0.02933424338698387\n",
      "Epoch 80/200, Loss_1: 0.011538885533809662, Loss_2: 0.015191739425063133, Total Loss: 0.026730624958872795\n",
      "Epoch 100/200, Loss_1: 0.011275150813162327, Loss_2: 0.0140457171946764, Total Loss: 0.0253208689391613\n",
      "Epoch 120/200, Loss_1: 0.011243011802434921, Loss_2: 0.01333281397819519, Total Loss: 0.02457582578063011\n",
      "Epoch 140/200, Loss_1: 0.011288300156593323, Loss_2: 0.012834740802645683, Total Loss: 0.024123040959239006\n",
      "Epoch 160/200, Loss_1: 0.011304882355034351, Loss_2: 0.012529239058494568, Total Loss: 0.023834120482206345\n",
      "Epoch 180/200, Loss_1: 0.011355433613061905, Loss_2: 0.012283479794859886, Total Loss: 0.02363891340792179\n",
      "Epoch 200/200, Loss_1: 0.011405110359191895, Loss_2: 0.012091536074876785, Total Loss: 0.02349664643406868\n",
      "Epoch 20/200, Loss_1: 0.03135446459054947, Loss_2: 0.02139902673661709, Total Loss: 0.05275349318981171\n",
      "Epoch 40/200, Loss_1: 0.017513148486614227, Loss_2: 0.01989888772368431, Total Loss: 0.03741203621029854\n",
      "Epoch 60/200, Loss_1: 0.013214871287345886, Loss_2: 0.016572529450058937, Total Loss: 0.029787400737404823\n",
      "Epoch 80/200, Loss_1: 0.010202723555266857, Loss_2: 0.016708215698599815, Total Loss: 0.026910938322544098\n",
      "Epoch 100/200, Loss_1: 0.011165169067680836, Loss_2: 0.014493962749838829, Total Loss: 0.02565913274884224\n",
      "Epoch 120/200, Loss_1: 0.011527919210493565, Loss_2: 0.013368738815188408, Total Loss: 0.024896658957004547\n",
      "Epoch 140/200, Loss_1: 0.011341952718794346, Loss_2: 0.013034111820161343, Total Loss: 0.02437606453895569\n",
      "Epoch 160/200, Loss_1: 0.011449466459453106, Loss_2: 0.012564409524202347, Total Loss: 0.024013876914978027\n",
      "Epoch 180/200, Loss_1: 0.011424954980611801, Loss_2: 0.01233706995844841, Total Loss: 0.02376202493906021\n",
      "Epoch 200/200, Loss_1: 0.011442420072853565, Loss_2: 0.01214574184268713, Total Loss: 0.023588161915540695\n",
      "Epoch 20/200, Loss_1: 0.029063742607831955, Loss_2: 0.022224536165595055, Total Loss: 0.05128827691078186\n",
      "Epoch 40/200, Loss_1: 0.0189589224755764, Loss_2: 0.017117347568273544, Total Loss: 0.036076270043849945\n",
      "Epoch 60/200, Loss_1: 0.013401097618043423, Loss_2: 0.019061513245105743, Total Loss: 0.03246261179447174\n",
      "Epoch 80/200, Loss_1: 0.01282623503357172, Loss_2: 0.016740882769227028, Total Loss: 0.029567118734121323\n",
      "Epoch 100/200, Loss_1: 0.012842567637562752, Loss_2: 0.014761759899556637, Total Loss: 0.027604326605796814\n",
      "Epoch 120/200, Loss_1: 0.012399217113852501, Loss_2: 0.013585454784333706, Total Loss: 0.025984670966863632\n",
      "Epoch 140/200, Loss_1: 0.012314294464886189, Loss_2: 0.012462479062378407, Total Loss: 0.024776773527264595\n",
      "Epoch 160/200, Loss_1: 0.012140702456235886, Loss_2: 0.011878900229930878, Total Loss: 0.024019602686166763\n",
      "Epoch 180/200, Loss_1: 0.011894152499735355, Loss_2: 0.011759025976061821, Total Loss: 0.02365317940711975\n",
      "Epoch 200/200, Loss_1: 0.011782650835812092, Loss_2: 0.011692407540977001, Total Loss: 0.023475058376789093\n",
      "Epoch 20/200, Loss_1: 0.011460911482572556, Loss_2: 0.018726345151662827, Total Loss: 0.030187256634235382\n",
      "Epoch 40/200, Loss_1: 0.01210322231054306, Loss_2: 0.012583624571561813, Total Loss: 0.024686846882104874\n",
      "Epoch 60/200, Loss_1: 0.012017708271741867, Loss_2: 0.011494884267449379, Total Loss: 0.023512592539191246\n",
      "Epoch 80/200, Loss_1: 0.011625864543020725, Loss_2: 0.011603310704231262, Total Loss: 0.023229174315929413\n",
      "Epoch 100/200, Loss_1: 0.011545076966285706, Loss_2: 0.011581513099372387, Total Loss: 0.023126590996980667\n",
      "Epoch 120/200, Loss_1: 0.01157276052981615, Loss_2: 0.011502151377499104, Total Loss: 0.023074911907315254\n",
      "Epoch 140/200, Loss_1: 0.01153226476162672, Loss_2: 0.011510085314512253, Total Loss: 0.023042351007461548\n",
      "Epoch 160/200, Loss_1: 0.011522553861141205, Loss_2: 0.011495205573737621, Total Loss: 0.0230177603662014\n",
      "Epoch 180/200, Loss_1: 0.01150678750127554, Loss_2: 0.011491665616631508, Total Loss: 0.022998452186584473\n",
      "Epoch 200/200, Loss_1: 0.011495375074446201, Loss_2: 0.011487653478980064, Total Loss: 0.02298302948474884\n",
      "Epoch 20/200, Loss_1: 0.02373640239238739, Loss_2: 0.01613275520503521, Total Loss: 0.03986915946006775\n",
      "Epoch 40/200, Loss_1: 0.015364517457783222, Loss_2: 0.011192044243216515, Total Loss: 0.02655656263232231\n",
      "Epoch 60/200, Loss_1: 0.012872516177594662, Loss_2: 0.011502481065690517, Total Loss: 0.02437499724328518\n",
      "Epoch 80/200, Loss_1: 0.011765135452151299, Loss_2: 0.01182838249951601, Total Loss: 0.023593518882989883\n",
      "Epoch 100/200, Loss_1: 0.011944182217121124, Loss_2: 0.011365234851837158, Total Loss: 0.023309417068958282\n",
      "Epoch 120/200, Loss_1: 0.011669808998703957, Loss_2: 0.011520433239638805, Total Loss: 0.023190241307020187\n",
      "Epoch 140/200, Loss_1: 0.011604594066739082, Loss_2: 0.011529427953064442, Total Loss: 0.0231340229511261\n",
      "Epoch 160/200, Loss_1: 0.011586928740143776, Loss_2: 0.011514075100421906, Total Loss: 0.02310100384056568\n",
      "Epoch 180/200, Loss_1: 0.011573068797588348, Loss_2: 0.01150334533303976, Total Loss: 0.023076415061950684\n",
      "Epoch 200/200, Loss_1: 0.011564677581191063, Loss_2: 0.011491780169308186, Total Loss: 0.023056458681821823\n",
      "Epoch 20/200, Loss_1: 0.023814868181943893, Loss_2: 0.013030505739152431, Total Loss: 0.0368453748524189\n",
      "Epoch 40/200, Loss_1: 0.0133082689717412, Loss_2: 0.016571929678320885, Total Loss: 0.02988019958138466\n",
      "Epoch 60/200, Loss_1: 0.014353027567267418, Loss_2: 0.013140182010829449, Total Loss: 0.027493208646774292\n",
      "Epoch 80/200, Loss_1: 0.013339229859411716, Loss_2: 0.01289154589176178, Total Loss: 0.02623077481985092\n",
      "Epoch 100/200, Loss_1: 0.012682298198342323, Loss_2: 0.012965227477252483, Total Loss: 0.025647524744272232\n",
      "Epoch 120/200, Loss_1: 0.012632390484213829, Loss_2: 0.012615346349775791, Total Loss: 0.025247737765312195\n",
      "Epoch 140/200, Loss_1: 0.012495731003582478, Loss_2: 0.01242159679532051, Total Loss: 0.024917326867580414\n",
      "Epoch 160/200, Loss_1: 0.012363774701952934, Loss_2: 0.012267133221030235, Total Loss: 0.02463090792298317\n",
      "Epoch 180/200, Loss_1: 0.012244015000760555, Loss_2: 0.012136166915297508, Total Loss: 0.02438018098473549\n",
      "Epoch 200/200, Loss_1: 0.012129898183047771, Loss_2: 0.012029243633151054, Total Loss: 0.02415914088487625\n",
      "Epoch 20/200, Loss_1: 0.03220883756875992, Loss_2: 0.008073901757597923, Total Loss: 0.04028274118900299\n",
      "Epoch 40/200, Loss_1: 0.026730023324489594, Loss_2: 0.010316789150238037, Total Loss: 0.03704681247472763\n",
      "Epoch 60/200, Loss_1: 0.019439393654465675, Loss_2: 0.009332330897450447, Total Loss: 0.028771724551916122\n",
      "Epoch 80/200, Loss_1: 0.012958740815520287, Loss_2: 0.012897437438368797, Total Loss: 0.025856178253889084\n",
      "Epoch 100/200, Loss_1: 0.01232344750314951, Loss_2: 0.01232124213129282, Total Loss: 0.02464468963444233\n",
      "Epoch 120/200, Loss_1: 0.012059273198246956, Loss_2: 0.012046849355101585, Total Loss: 0.02410612255334854\n",
      "Epoch 140/200, Loss_1: 0.01190721895545721, Loss_2: 0.011873587965965271, Total Loss: 0.023780807852745056\n",
      "Epoch 160/200, Loss_1: 0.011812394484877586, Loss_2: 0.011759519577026367, Total Loss: 0.023571914061903954\n",
      "Epoch 180/200, Loss_1: 0.01178072951734066, Loss_2: 0.011650137603282928, Total Loss: 0.02343086712062359\n",
      "Epoch 200/200, Loss_1: 0.011733205989003181, Loss_2: 0.011597058735787868, Total Loss: 0.023330263793468475\n",
      "Epoch 20/200, Loss_1: 0.03196468949317932, Loss_2: 0.008452310226857662, Total Loss: 0.04041700065135956\n",
      "Epoch 40/200, Loss_1: 0.01491496991366148, Loss_2: 0.011670869775116444, Total Loss: 0.026585839688777924\n",
      "Epoch 60/200, Loss_1: 0.011925233528017998, Loss_2: 0.013000953011214733, Total Loss: 0.024926185607910156\n",
      "Epoch 80/200, Loss_1: 0.012417461723089218, Loss_2: 0.011757960543036461, Total Loss: 0.02417542226612568\n",
      "Epoch 100/200, Loss_1: 0.012187148444354534, Loss_2: 0.01157000008970499, Total Loss: 0.023757148534059525\n",
      "Epoch 120/200, Loss_1: 0.012065732851624489, Loss_2: 0.01146360021084547, Total Loss: 0.023529332131147385\n",
      "Epoch 140/200, Loss_1: 0.011867580935359001, Loss_2: 0.011525661684572697, Total Loss: 0.023393243551254272\n",
      "Epoch 160/200, Loss_1: 0.011782048270106316, Loss_2: 0.011524291709065437, Total Loss: 0.023306339979171753\n",
      "Epoch 180/200, Loss_1: 0.01171418372541666, Loss_2: 0.011530688963830471, Total Loss: 0.02324487268924713\n",
      "Epoch 200/200, Loss_1: 0.01166890375316143, Loss_2: 0.011530909687280655, Total Loss: 0.023199813440442085\n",
      "Epoch 20/200, Loss_1: 0.024288447573781013, Loss_2: 0.008375761099159718, Total Loss: 0.032664209604263306\n",
      "Epoch 40/200, Loss_1: 0.010910635814070702, Loss_2: 0.01422142144292593, Total Loss: 0.025132056325674057\n",
      "Epoch 60/200, Loss_1: 0.01231800951063633, Loss_2: 0.011431485414505005, Total Loss: 0.023749494925141335\n",
      "Epoch 80/200, Loss_1: 0.0116417296230793, Loss_2: 0.011645423248410225, Total Loss: 0.023287152871489525\n",
      "Epoch 100/200, Loss_1: 0.011646837927401066, Loss_2: 0.011490916833281517, Total Loss: 0.023137755692005157\n",
      "Epoch 120/200, Loss_1: 0.011611668393015862, Loss_2: 0.011456912383437157, Total Loss: 0.023068580776453018\n",
      "Epoch 140/200, Loss_1: 0.011548193171620369, Loss_2: 0.01148002129048109, Total Loss: 0.023028213530778885\n",
      "Epoch 160/200, Loss_1: 0.011522484011948109, Loss_2: 0.011478285305202007, Total Loss: 0.023000769317150116\n",
      "Epoch 180/200, Loss_1: 0.011511620134115219, Loss_2: 0.011469359509646893, Total Loss: 0.022980980575084686\n",
      "Epoch 200/200, Loss_1: 0.01150142028927803, Loss_2: 0.011464950628578663, Total Loss: 0.02296636998653412\n",
      "Epoch 20/200, Loss_1: 0.03063252754509449, Loss_2: 0.01621035672724247, Total Loss: 0.04684288427233696\n",
      "Epoch 40/200, Loss_1: 0.02793584018945694, Loss_2: 0.013341083191335201, Total Loss: 0.041276924312114716\n",
      "Epoch 60/200, Loss_1: 0.017128055915236473, Loss_2: 0.014140906743705273, Total Loss: 0.03126896172761917\n",
      "Epoch 80/200, Loss_1: 0.009620552882552147, Loss_2: 0.017952701076865196, Total Loss: 0.027573253959417343\n",
      "Epoch 100/200, Loss_1: 0.010054216720163822, Loss_2: 0.016235921531915665, Total Loss: 0.026290137320756912\n",
      "Epoch 120/200, Loss_1: 0.010449513792991638, Loss_2: 0.01464800164103508, Total Loss: 0.025097515434026718\n",
      "Epoch 140/200, Loss_1: 0.011004564352333546, Loss_2: 0.013089855201542377, Total Loss: 0.024094419553875923\n",
      "Epoch 160/200, Loss_1: 0.011510017327964306, Loss_2: 0.011983058415353298, Total Loss: 0.023493075743317604\n",
      "Epoch 180/200, Loss_1: 0.011517882347106934, Loss_2: 0.011676306836307049, Total Loss: 0.023194190114736557\n",
      "Epoch 200/200, Loss_1: 0.011501769535243511, Loss_2: 0.01156606711447239, Total Loss: 0.023067835718393326\n",
      "Epoch 20/200, Loss_1: 0.06244245544075966, Loss_2: 0.05516417324542999, Total Loss: 0.11760662496089935\n",
      "Epoch 40/200, Loss_1: 0.029215924441814423, Loss_2: 0.017907772213220596, Total Loss: 0.04712369665503502\n",
      "Epoch 60/200, Loss_1: 0.028195660561323166, Loss_2: 0.013484167866408825, Total Loss: 0.041679829359054565\n",
      "Epoch 80/200, Loss_1: 0.028425388038158417, Loss_2: 0.009356279857456684, Total Loss: 0.037781666964292526\n",
      "Epoch 100/200, Loss_1: 0.02870895154774189, Loss_2: 0.007666423451155424, Total Loss: 0.03637537360191345\n",
      "Epoch 120/200, Loss_1: 0.02848687954246998, Loss_2: 0.007068774197250605, Total Loss: 0.035555653274059296\n",
      "Epoch 140/200, Loss_1: 0.027719775214791298, Loss_2: 0.007075021043419838, Total Loss: 0.034794796258211136\n",
      "Epoch 160/200, Loss_1: 0.026356741786003113, Loss_2: 0.007486992981284857, Total Loss: 0.03384373337030411\n",
      "Epoch 180/200, Loss_1: 0.024347679689526558, Loss_2: 0.008210250176489353, Total Loss: 0.032557930797338486\n",
      "Epoch 200/200, Loss_1: 0.021683719009160995, Loss_2: 0.009180597960948944, Total Loss: 0.03086431697010994\n",
      "Epoch 20/200, Loss_1: 0.02455681562423706, Loss_2: 0.01725653186440468, Total Loss: 0.04181334748864174\n",
      "Epoch 40/200, Loss_1: 0.024726610630750656, Loss_2: 0.00821681134402752, Total Loss: 0.032943420112133026\n",
      "Epoch 60/200, Loss_1: 0.017438985407352448, Loss_2: 0.011375091038644314, Total Loss: 0.028814077377319336\n",
      "Epoch 80/200, Loss_1: 0.01338791474699974, Loss_2: 0.013826709240674973, Total Loss: 0.027214623987674713\n",
      "Epoch 100/200, Loss_1: 0.013001831248402596, Loss_2: 0.013302300125360489, Total Loss: 0.026304131373763084\n",
      "Epoch 120/200, Loss_1: 0.012791073881089687, Loss_2: 0.012892764061689377, Total Loss: 0.02568383887410164\n",
      "Epoch 140/200, Loss_1: 0.012359743937849998, Loss_2: 0.012850474566221237, Total Loss: 0.025210218504071236\n",
      "Epoch 160/200, Loss_1: 0.012141896411776543, Loss_2: 0.012697196565568447, Total Loss: 0.024839092046022415\n",
      "Epoch 180/200, Loss_1: 0.012032890692353249, Loss_2: 0.012505779042840004, Total Loss: 0.024538669735193253\n",
      "Epoch 200/200, Loss_1: 0.011937558650970459, Loss_2: 0.012354087084531784, Total Loss: 0.024291645735502243\n",
      "Epoch 20/200, Loss_1: 0.019614404067397118, Loss_2: 0.019032971933484077, Total Loss: 0.038647376000881195\n",
      "Epoch 40/200, Loss_1: 0.021686259657144547, Loss_2: 0.011550845578312874, Total Loss: 0.03323710709810257\n",
      "Epoch 60/200, Loss_1: 0.015496427193284035, Loss_2: 0.012208640575408936, Total Loss: 0.02770506776869297\n",
      "Epoch 80/200, Loss_1: 0.012997126206755638, Loss_2: 0.013210722245275974, Total Loss: 0.026207849383354187\n",
      "Epoch 100/200, Loss_1: 0.011927038431167603, Loss_2: 0.013421738520264626, Total Loss: 0.025348776951432228\n",
      "Epoch 120/200, Loss_1: 0.011770735494792461, Loss_2: 0.013016649521887302, Total Loss: 0.024787385016679764\n",
      "Epoch 140/200, Loss_1: 0.011868362314999104, Loss_2: 0.012512409128248692, Total Loss: 0.024380771443247795\n",
      "Epoch 160/200, Loss_1: 0.011892067268490791, Loss_2: 0.012188366614282131, Total Loss: 0.024080432951450348\n",
      "Epoch 180/200, Loss_1: 0.011830431409180164, Loss_2: 0.01202496699988842, Total Loss: 0.02385539934039116\n",
      "Epoch 200/200, Loss_1: 0.011756575666368008, Loss_2: 0.011928877793252468, Total Loss: 0.023685453459620476\n",
      "Epoch 20/200, Loss_1: 0.021879861131310463, Loss_2: 0.0288042351603508, Total Loss: 0.05068409442901611\n",
      "Epoch 40/200, Loss_1: 0.014064808376133442, Loss_2: 0.018716255202889442, Total Loss: 0.03278106451034546\n",
      "Epoch 60/200, Loss_1: 0.012366712093353271, Loss_2: 0.01425119023770094, Total Loss: 0.026617903262376785\n",
      "Epoch 80/200, Loss_1: 0.011908390559256077, Loss_2: 0.01304575428366661, Total Loss: 0.024954143911600113\n",
      "Epoch 100/200, Loss_1: 0.011494508013129234, Loss_2: 0.012830132618546486, Total Loss: 0.02432464063167572\n",
      "Epoch 120/200, Loss_1: 0.011617237702012062, Loss_2: 0.012362607754766941, Total Loss: 0.023979846388101578\n",
      "Epoch 140/200, Loss_1: 0.011568592861294746, Loss_2: 0.01217258907854557, Total Loss: 0.023741181939840317\n",
      "Epoch 160/200, Loss_1: 0.011579896323382854, Loss_2: 0.011985603719949722, Total Loss: 0.02356550097465515\n",
      "Epoch 180/200, Loss_1: 0.011582487262785435, Loss_2: 0.011853975243866444, Total Loss: 0.02343646250665188\n",
      "Epoch 200/200, Loss_1: 0.011594841256737709, Loss_2: 0.01174645870923996, Total Loss: 0.02334129996597767\n",
      "Epoch 20/200, Loss_1: 0.019406255334615707, Loss_2: 0.03402986750006676, Total Loss: 0.053436122834682465\n",
      "Epoch 40/200, Loss_1: 0.011751866899430752, Loss_2: 0.027374694123864174, Total Loss: 0.03912656009197235\n",
      "Epoch 60/200, Loss_1: 0.010115857236087322, Loss_2: 0.025461262091994286, Total Loss: 0.03557711839675903\n",
      "Epoch 80/200, Loss_1: 0.008197660557925701, Loss_2: 0.02454131655395031, Total Loss: 0.032738976180553436\n",
      "Epoch 100/200, Loss_1: 0.0076127019710838795, Loss_2: 0.02445845678448677, Total Loss: 0.03207115828990936\n",
      "Epoch 120/200, Loss_1: 0.007527525536715984, Loss_2: 0.024170001968741417, Total Loss: 0.03169752657413483\n",
      "Epoch 140/200, Loss_1: 0.007624125573784113, Loss_2: 0.023699268698692322, Total Loss: 0.0313233956694603\n",
      "Epoch 160/200, Loss_1: 0.007960627786815166, Loss_2: 0.022864598780870438, Total Loss: 0.03082522749900818\n",
      "Epoch 180/200, Loss_1: 0.008576077409088612, Loss_2: 0.021503709256649017, Total Loss: 0.030079785734415054\n",
      "Epoch 200/200, Loss_1: 0.00947626493871212, Loss_2: 0.019457871094346046, Total Loss: 0.028934136033058167\n",
      "Epoch 20/200, Loss_1: 0.03198247030377388, Loss_2: 0.027018655091524124, Total Loss: 0.059001125395298004\n",
      "Epoch 40/200, Loss_1: 0.011203395202755928, Loss_2: 0.01787201687693596, Total Loss: 0.029075412079691887\n",
      "Epoch 60/200, Loss_1: 0.012534131295979023, Loss_2: 0.011775648221373558, Total Loss: 0.024309780448675156\n",
      "Epoch 80/200, Loss_1: 0.011399664916098118, Loss_2: 0.012215543538331985, Total Loss: 0.02361520752310753\n",
      "Epoch 100/200, Loss_1: 0.011791207827627659, Loss_2: 0.011542768217623234, Total Loss: 0.023333976045250893\n",
      "Epoch 120/200, Loss_1: 0.011645208112895489, Loss_2: 0.01157228834927082, Total Loss: 0.023217495530843735\n",
      "Epoch 140/200, Loss_1: 0.011650540865957737, Loss_2: 0.011513047851622105, Total Loss: 0.02316358871757984\n",
      "Epoch 160/200, Loss_1: 0.01161077618598938, Loss_2: 0.011521079577505589, Total Loss: 0.023131854832172394\n",
      "Epoch 180/200, Loss_1: 0.011594191193580627, Loss_2: 0.011514139361679554, Total Loss: 0.023108329623937607\n",
      "Epoch 200/200, Loss_1: 0.011583381332457066, Loss_2: 0.01150513719767332, Total Loss: 0.023088518530130386\n",
      "Epoch 20/200, Loss_1: 0.03798362612724304, Loss_2: 0.015343248844146729, Total Loss: 0.05332687497138977\n",
      "Epoch 40/200, Loss_1: 0.024555476382374763, Loss_2: 0.008636966347694397, Total Loss: 0.03319244086742401\n",
      "Epoch 60/200, Loss_1: 0.012710788287222385, Loss_2: 0.012323262169957161, Total Loss: 0.02503405138850212\n",
      "Epoch 80/200, Loss_1: 0.01119720283895731, Loss_2: 0.012578297406435013, Total Loss: 0.023775499314069748\n",
      "Epoch 100/200, Loss_1: 0.011250505223870277, Loss_2: 0.012210598215460777, Total Loss: 0.023461103439331055\n",
      "Epoch 120/200, Loss_1: 0.011389847844839096, Loss_2: 0.011881861835718155, Total Loss: 0.02327170968055725\n",
      "Epoch 140/200, Loss_1: 0.011449534446001053, Loss_2: 0.01172022707760334, Total Loss: 0.023169761523604393\n",
      "Epoch 160/200, Loss_1: 0.01151489932090044, Loss_2: 0.011591078713536263, Total Loss: 0.023105978965759277\n",
      "Epoch 180/200, Loss_1: 0.011508870869874954, Loss_2: 0.011553953401744366, Total Loss: 0.023062825202941895\n",
      "Epoch 200/200, Loss_1: 0.011512177996337414, Loss_2: 0.011520118452608585, Total Loss: 0.023032296448946\n",
      "Epoch 20/200, Loss_1: 0.052655890583992004, Loss_2: 0.030128462240099907, Total Loss: 0.08278435468673706\n",
      "Epoch 40/200, Loss_1: 0.021131984889507294, Loss_2: 0.01156094204634428, Total Loss: 0.03269292786717415\n",
      "Epoch 60/200, Loss_1: 0.01317110937088728, Loss_2: 0.013516179285943508, Total Loss: 0.026687288656830788\n",
      "Epoch 80/200, Loss_1: 0.01165014412254095, Loss_2: 0.014060077257454395, Total Loss: 0.025710221379995346\n",
      "Epoch 100/200, Loss_1: 0.011749165132641792, Loss_2: 0.01319396123290062, Total Loss: 0.024943126365542412\n",
      "Epoch 120/200, Loss_1: 0.011745627038180828, Loss_2: 0.012766264379024506, Total Loss: 0.02451189234852791\n",
      "Epoch 140/200, Loss_1: 0.011686451733112335, Loss_2: 0.012517874129116535, Total Loss: 0.024204324930906296\n",
      "Epoch 160/200, Loss_1: 0.011704192496836185, Loss_2: 0.012281901203095913, Total Loss: 0.0239860936999321\n",
      "Epoch 180/200, Loss_1: 0.011703887023031712, Loss_2: 0.01212315820157528, Total Loss: 0.023827046155929565\n",
      "Epoch 200/200, Loss_1: 0.011690055951476097, Loss_2: 0.01201684307307005, Total Loss: 0.023706898093223572\n",
      "Epoch 20/200, Loss_1: 0.02795557864010334, Loss_2: 0.005462048575282097, Total Loss: 0.03341762721538544\n",
      "Epoch 40/200, Loss_1: 0.012988530099391937, Loss_2: 0.011515023186802864, Total Loss: 0.0245035532861948\n",
      "Epoch 60/200, Loss_1: 0.010829420760273933, Loss_2: 0.01300992164760828, Total Loss: 0.023839343339204788\n",
      "Epoch 80/200, Loss_1: 0.011971610598266125, Loss_2: 0.01155779417604208, Total Loss: 0.023529404774308205\n",
      "Epoch 100/200, Loss_1: 0.011688937433063984, Loss_2: 0.011646059341728687, Total Loss: 0.02333499677479267\n",
      "Epoch 120/200, Loss_1: 0.011588279157876968, Loss_2: 0.011611586436629295, Total Loss: 0.023199865594506264\n",
      "Epoch 140/200, Loss_1: 0.011571313254535198, Loss_2: 0.011544041335582733, Total Loss: 0.023115355521440506\n",
      "Epoch 160/200, Loss_1: 0.011526316404342651, Loss_2: 0.011533256620168686, Total Loss: 0.023059573024511337\n",
      "Epoch 180/200, Loss_1: 0.011506038717925549, Loss_2: 0.011517019011080265, Total Loss: 0.023023057729005814\n",
      "Epoch 200/200, Loss_1: 0.011495739221572876, Loss_2: 0.011503667570650578, Total Loss: 0.02299940586090088\n",
      "Best decay coefficient: 1.2000000000000002, MSE: 0.08786604451143855\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:12:40.006372Z",
     "start_time": "2024-07-30T04:11:13.089749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# Generate station locations\n",
    "np.random.seed(42)\n",
    "num_stations = 10\n",
    "station_coords = np.random.rand(num_stations, 2)\n",
    "\n",
    "# Temperature data for one year (one data point per hour, 24 hours * 365 days)\n",
    "time_steps = 24 * 365\n",
    "temperature_data = np.random.rand(num_stations, time_steps) * 30  # Temperature range 0 to 30 degrees\n",
    "\n",
    "# Min-Max normalization for each station's temperature series\n",
    "min_temp = np.min(temperature_data, axis=1).reshape(-1, 1)\n",
    "max_temp = np.max(temperature_data, axis=1).reshape(-1, 1)\n",
    "temperature_data_normalized = (temperature_data - min_temp) / (max_temp - min_temp)\n",
    "\n",
    "# Generate interpolation point location and true temperature values\n",
    "interpolation_point = np.random.rand(1, 2)\n",
    "true_interpolation_temp = np.random.rand(time_steps) * 30  # Assume true temperature range is also 0 to 30 degrees\n",
    "\n",
    "# Normalize true_interpolation_temp\n",
    "true_min_temp = np.min(true_interpolation_temp)\n",
    "true_max_temp = np.max(true_interpolation_temp)\n",
    "true_interpolation_temp_normalized = (true_interpolation_temp - true_min_temp) / (true_max_temp - true_min_temp)\n",
    "\n",
    "# Define two subgraphs\n",
    "subgraph_1 = [0, 1, 2, 3, 4]\n",
    "subgraph_2 = [5, 6, 7, 8, 9]\n",
    "\n",
    "# Inverse Distance Weighting (IDW) interpolation\n",
    "def idw_interpolation(station_coords, temperatures, target_point, power=2):\n",
    "    distances = np.linalg.norm(station_coords - target_point, axis=1)\n",
    "    weights = 1 / (distances ** power)\n",
    "    weights /= weights.sum()\n",
    "    interpolated_value = np.dot(weights, temperatures)\n",
    "    return interpolated_value\n",
    "\n",
    "# Apply IDW interpolation to the two subgraphs\n",
    "idw_estimate_1 = np.array([idw_interpolation(station_coords[subgraph_1], temperature_data_normalized[subgraph_1, t], interpolation_point) for t in range(time_steps)])\n",
    "idw_estimate_2 = np.array([idw_interpolation(station_coords[subgraph_2], temperature_data_normalized[subgraph_2, t], interpolation_point) for t in range(time_steps)])\n",
    "\n",
    "# Define GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, adj):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def calculate_inverse_distance_adj(station_coords, decay):\n",
    "    num_nodes = station_coords.shape[0]\n",
    "    adj = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                distance = np.linalg.norm(station_coords[i] - station_coords[j])\n",
    "                adj[i, j] = np.exp(-decay * distance)\n",
    "    return torch.tensor(adj, dtype=torch.float)\n",
    "\n",
    "def prepare_data(subgraph, temperature_data, idw_estimate, decay):\n",
    "    edge_index = torch.tensor([[i, j] for i in range(len(subgraph)) for j in range(len(subgraph))], dtype=torch.long).t().contiguous()\n",
    "    adj = calculate_inverse_distance_adj(station_coords[subgraph], decay)\n",
    "    x = torch.tensor(temperature_data[subgraph], dtype=torch.float).t()\n",
    "    y = torch.tensor(idw_estimate, dtype=torch.float).t()\n",
    "    data = Data(x=x, edge_index=edge_index, y=y, adj=adj)\n",
    "    return data\n",
    "\n",
    "# Initialize models\n",
    "def initialize_models(hidden_dim):\n",
    "    model_1 = GCNModel(num_features=len(subgraph_1), hidden_dim=hidden_dim, output_dim=1)\n",
    "    model_2 = GCNModel(num_features=len(subgraph_2), hidden_dim=hidden_dim, output_dim=1)\n",
    "    return model_1, model_2\n",
    "\n",
    "# Define MoE model\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self, gcn1, gcn2, hidden_dim):\n",
    "        super(MoEModel, self).__init__()\n",
    "        self.gcn1 = gcn1\n",
    "        self.gcn2 = gcn2\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, edge_index1, adj1, x2, edge_index2, adj2):\n",
    "        out1 = self.gcn1(x1, edge_index1, adj1).view(-1, 1)\n",
    "        out2 = self.gcn2(x2, edge_index2, adj2).view(-1, 1)\n",
    "        gate_input = torch.cat([out1, out2], dim=1)\n",
    "        gate_output = self.gate(gate_input)\n",
    "        out = gate_output[:, 0].unsqueeze(1) * out1 + gate_output[:, 1].unsqueeze(1) * out2\n",
    "        return out\n",
    "\n",
    "# Train MoE model\n",
    "def train_model(moe_model, data_1, data_2, optimizer, criterion, num_epochs=200):\n",
    "    epoch_times = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        moe_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = moe_model(data_1.x, data_1.edge_index, data_1.adj, data_2.x, data_2.edge_index, data_2.adj)\n",
    "        \n",
    "        loss_1 = criterion(out.squeeze(), data_1.y)\n",
    "        loss_2 = criterion(out.squeeze(), data_2.y)\n",
    "        \n",
    "        total_loss = loss_1 + loss_2\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss_1: {loss_1.item()}, Loss_2: {loss_2.item()}, Total Loss: {total_loss.item()}, Epoch Time: {epoch_time:.2f} seconds')\n",
    "    \n",
    "    return epoch_times\n",
    "\n",
    "# Predict temperature for the interpolation point\n",
    "def predict(moe_model, data_1, data_2):\n",
    "    moe_model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_temp = moe_model(data_1.x, data_1.edge_index, data_1.adj, data_2.x, data_2.edge_index, data_2.adj)\n",
    "    return predicted_temp.squeeze().numpy()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# MCMC for evaluating decay coefficients\n",
    "def mcmc_decay_selection(decay_coefficients, num_samples=100):\n",
    "    samples = []\n",
    "    current_decay = np.random.choice(decay_coefficients)\n",
    "    current_mse, _ = evaluate_decay(current_decay)\n",
    "    samples.append((current_decay, current_mse))\n",
    "    optimization_times = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        start_time = time.time()\n",
    "        proposed_decay = np.random.choice(decay_coefficients)\n",
    "        proposed_mse, _ = evaluate_decay(proposed_decay)\n",
    "\n",
    "        acceptance_prob = min(1, np.exp(current_mse - proposed_mse))\n",
    "        if np.random.rand() < acceptance_prob:\n",
    "            current_decay = proposed_decay\n",
    "            current_mse = proposed_mse\n",
    "        \n",
    "        samples.append((current_decay, current_mse))\n",
    "        end_time = time.time()\n",
    "        optimization_time = end_time - start_time\n",
    "        optimization_times.append(optimization_time)\n",
    "    \n",
    "    return samples, optimization_times\n",
    "\n",
    "def evaluate_decay(decay):\n",
    "    hidden_dim = 16  # Define hidden_dim here\n",
    "    data_1 = prepare_data(subgraph_1, temperature_data_normalized, idw_estimate_1, decay)\n",
    "    data_2 = prepare_data(subgraph_2, temperature_data_normalized, idw_estimate_2, decay)\n",
    "    model_1, model_2 = initialize_models(hidden_dim)\n",
    "    moe_model = MoEModel(model_1, model_2, hidden_dim)\n",
    "    optimizer = optim.Adam(moe_model.parameters(), lr=0.01)\n",
    "    \n",
    "    epoch_times = train_model(moe_model, data_1, data_2, optimizer, criterion)\n",
    "    predicted_temp_normalized = predict(moe_model, data_1, data_2)\n",
    "    mse = mean_squared_error(true_interpolation_temp_normalized, predicted_temp_normalized)\n",
    "    \n",
    "    return mse, epoch_times\n",
    "\n",
    "# Evaluate different decay coefficients using MCMC\n",
    "decay_coefficients = np.arange(0, 1.6, 0.1)\n",
    "samples, optimization_times = mcmc_decay_selection(decay_coefficients)\n",
    "best_sample = min(samples, key=lambda x: x[1])\n",
    "best_decay = best_sample[0]\n",
    "best_mse = best_sample[1]\n",
    "\n",
    "print(f'Best decay coefficient: {best_decay}, MSE: {best_mse}')\n",
    "\n",
    "# Print the training time per epoch for the best model\n",
    "best_mse, epoch_times = evaluate_decay(best_decay)\n",
    "print(f'Training times per epoch for best decay coefficient ({best_decay}):')\n",
    "for epoch, time_taken in enumerate(epoch_times):\n",
    "    print(f'Epoch {epoch + 1}: {time_taken:.2f} seconds')\n",
    "\n",
    "# Print the total optimization time by MCMC\n",
    "total_optimization_time = sum(optimization_times)\n",
    "print(f'Total optimization time by MCMC: {total_optimization_time:.2f} seconds')\n",
    "\n"
   ],
   "id": "db48c4373a67d5ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss_1: 0.11969754844903946, Loss_2: 0.07645069807767868, Total Loss: 0.19614824652671814, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.05265704542398453, Loss_2: 0.024850834161043167, Total Loss: 0.077507883310318, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.04001958668231964, Loss_2: 0.013977598398923874, Total Loss: 0.053997185081243515, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.034054722636938095, Loss_2: 0.01148733589798212, Total Loss: 0.04554205760359764, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.031161565333604813, Loss_2: 0.010981419123709202, Total Loss: 0.04214298352599144, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.02987779676914215, Loss_2: 0.010533077642321587, Total Loss: 0.04041087627410889, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.028770051896572113, Loss_2: 0.009956393390893936, Total Loss: 0.03872644528746605, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.026229750365018845, Loss_2: 0.00969184935092926, Total Loss: 0.035921599715948105, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.021552208811044693, Loss_2: 0.010254920460283756, Total Loss: 0.031807128340005875, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.016987543553113937, Loss_2: 0.010790650732815266, Total Loss: 0.02777819335460663, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.023569513112306595, Loss_2: 0.023771891370415688, Total Loss: 0.04734140634536743, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01628071442246437, Loss_2: 0.013745129108428955, Total Loss: 0.030025843530893326, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013320722617208958, Loss_2: 0.012898904271423817, Total Loss: 0.026219626888632774, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012594745494425297, Loss_2: 0.01218102965503931, Total Loss: 0.024775775149464607, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012524234130978584, Loss_2: 0.01162149477750063, Total Loss: 0.02414572983980179, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012346852570772171, Loss_2: 0.011492835357785225, Total Loss: 0.023839687928557396, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01210736483335495, Loss_2: 0.011551068164408207, Total Loss: 0.023658432066440582, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011967115104198456, Loss_2: 0.011570552363991737, Total Loss: 0.023537667468190193, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011896338313817978, Loss_2: 0.011553073301911354, Total Loss: 0.023449411615729332, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011834983713924885, Loss_2: 0.011545689776539803, Total Loss: 0.023380674421787262, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.019026614725589752, Loss_2: 0.03154631331562996, Total Loss: 0.05057292804121971, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.021120529621839523, Loss_2: 0.01818506233394146, Total Loss: 0.039305590093135834, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.014231979846954346, Loss_2: 0.0172109417617321, Total Loss: 0.03144292160868645, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012271953746676445, Loss_2: 0.01715100184082985, Total Loss: 0.029422955587506294, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011556047014892101, Loss_2: 0.01654285192489624, Total Loss: 0.028098899871110916, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011510485783219337, Loss_2: 0.015720341354608536, Total Loss: 0.027230827137827873, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011645510792732239, Loss_2: 0.014864124357700348, Total Loss: 0.026509635150432587, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011765198782086372, Loss_2: 0.014085027389228344, Total Loss: 0.02585022523999214, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011847734451293945, Loss_2: 0.01340707391500473, Total Loss: 0.025254808366298676, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011911089532077312, Loss_2: 0.012829873710870743, Total Loss: 0.02474096417427063, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.020567724481225014, Loss_2: 0.021246736869215965, Total Loss: 0.04181446135044098, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01442305464297533, Loss_2: 0.01334927324205637, Total Loss: 0.0277723278850317, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01295132003724575, Loss_2: 0.012127542868256569, Total Loss: 0.02507886290550232, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011567414738237858, Loss_2: 0.012338194064795971, Total Loss: 0.02390560880303383, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011659986339509487, Loss_2: 0.011860457248985767, Total Loss: 0.023520443588495255, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011625087819993496, Loss_2: 0.011672674678266048, Total Loss: 0.023297762498259544, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011609167791903019, Loss_2: 0.01157789584249258, Total Loss: 0.0231870636343956, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011558933183550835, Loss_2: 0.011567622423171997, Total Loss: 0.02312655560672283, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011526848189532757, Loss_2: 0.011563047766685486, Total Loss: 0.023089896887540817, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011499626561999321, Loss_2: 0.01156484242528677, Total Loss: 0.023064468055963516, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.0311521477997303, Loss_2: 0.025825098156929016, Total Loss: 0.05697724595665932, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02988852933049202, Loss_2: 0.012650752440094948, Total Loss: 0.04253928363323212, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.025610843673348427, Loss_2: 0.009388502687215805, Total Loss: 0.03499934822320938, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.023046167567372322, Loss_2: 0.008584878407418728, Total Loss: 0.031631045043468475, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.020821567624807358, Loss_2: 0.008669829927384853, Total Loss: 0.029491398483514786, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.018438907340168953, Loss_2: 0.00930096860975027, Total Loss: 0.02773987501859665, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.016192017123103142, Loss_2: 0.010115896351635456, Total Loss: 0.026307914406061172, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.014505812898278236, Loss_2: 0.010717296972870827, Total Loss: 0.025223109871149063, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.013385738246142864, Loss_2: 0.011114685796201229, Total Loss: 0.024500424042344093, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012598919682204723, Loss_2: 0.011433882638812065, Total Loss: 0.024032801389694214, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.013784029521048069, Loss_2: 0.013058009557425976, Total Loss: 0.026842039078474045, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.013606831431388855, Loss_2: 0.010866750031709671, Total Loss: 0.024473581463098526, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011698199436068535, Loss_2: 0.012213683687150478, Total Loss: 0.02391188219189644, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01174029428511858, Loss_2: 0.011886411346495152, Total Loss: 0.02362670563161373, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01178681943565607, Loss_2: 0.011668885126709938, Total Loss: 0.023455705493688583, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011683440767228603, Loss_2: 0.01166018471121788, Total Loss: 0.023343626409769058, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011649922467768192, Loss_2: 0.011614437215030193, Total Loss: 0.023264359682798386, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011626862920820713, Loss_2: 0.011576811783015728, Total Loss: 0.02320367470383644, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011603021994233131, Loss_2: 0.011552386917173862, Total Loss: 0.02315540984272957, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011586855165660381, Loss_2: 0.011529471725225449, Total Loss: 0.023116327822208405, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.040832508355379105, Loss_2: 0.020850786939263344, Total Loss: 0.0616832971572876, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01877838559448719, Loss_2: 0.010978794656693935, Total Loss: 0.02975717931985855, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.010409722104668617, Loss_2: 0.015680935233831406, Total Loss: 0.026090657338500023, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012058696709573269, Loss_2: 0.013303540647029877, Total Loss: 0.02536223828792572, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01179629098623991, Loss_2: 0.01310541108250618, Total Loss: 0.024901703000068665, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011563993990421295, Loss_2: 0.013007232919335365, Total Loss: 0.02457122690975666, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011667333543300629, Loss_2: 0.012640691362321377, Total Loss: 0.02430802583694458, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011635997332632542, Loss_2: 0.012457210570573807, Total Loss: 0.024093206971883774, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011626223102211952, Loss_2: 0.012291657738387585, Total Loss: 0.023917879909276962, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011617949232459068, Loss_2: 0.012156669050455093, Total Loss: 0.02377461828291416, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.026584576815366745, Loss_2: 0.010146908462047577, Total Loss: 0.03673148527741432, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.011377837508916855, Loss_2: 0.014671876095235348, Total Loss: 0.026049714535474777, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012638687156140804, Loss_2: 0.011583263985812664, Total Loss: 0.02422195114195347, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011687234044075012, Loss_2: 0.011987664736807346, Total Loss: 0.023674897849559784, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011784828267991543, Loss_2: 0.011608163826167583, Total Loss: 0.023392992094159126, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01169316191226244, Loss_2: 0.011552675627171993, Total Loss: 0.023245837539434433, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01163526251912117, Loss_2: 0.011521704494953156, Total Loss: 0.023156967014074326, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01160871796309948, Loss_2: 0.011490806937217712, Total Loss: 0.023099524900317192, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011580109596252441, Loss_2: 0.011479716747999191, Total Loss: 0.023059826344251633, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011622464284300804, Loss_2: 0.011405952274799347, Total Loss: 0.02302841655910015, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.033581431955099106, Loss_2: 0.018611464649438858, Total Loss: 0.052192896604537964, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.017252106219530106, Loss_2: 0.012958504259586334, Total Loss: 0.03021061047911644, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01150632556527853, Loss_2: 0.015010962262749672, Total Loss: 0.026517286896705627, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012091725133359432, Loss_2: 0.013322393409907818, Total Loss: 0.02541411854326725, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011736067943274975, Loss_2: 0.012926657684147358, Total Loss: 0.024662725627422333, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011801234446465969, Loss_2: 0.012341868132352829, Total Loss: 0.024143103510141373, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.0117855966091156, Loss_2: 0.012010563164949417, Total Loss: 0.023796159774065018, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01182371936738491, Loss_2: 0.011750749312341213, Total Loss: 0.02357446774840355, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011746440082788467, Loss_2: 0.011691453866660595, Total Loss: 0.023437894880771637, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01163632795214653, Loss_2: 0.011709525249898434, Total Loss: 0.02334585413336754, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.0312797985970974, Loss_2: 0.014086965471506119, Total Loss: 0.045366764068603516, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.017364542931318283, Loss_2: 0.012194545939564705, Total Loss: 0.029559088870882988, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.012417054735124111, Loss_2: 0.013639040291309357, Total Loss: 0.026056095957756042, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011896072886884212, Loss_2: 0.012009233236312866, Total Loss: 0.023905307054519653, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01180068589746952, Loss_2: 0.011576339602470398, Total Loss: 0.02337702549993992, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011545784771442413, Loss_2: 0.01170300506055355, Total Loss: 0.023248789831995964, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011528225615620613, Loss_2: 0.011653034016489983, Total Loss: 0.023181259632110596, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011544655077159405, Loss_2: 0.011594961397349834, Total Loss: 0.02313961647450924, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011508609168231487, Loss_2: 0.011601089499890804, Total Loss: 0.02310969866812229, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01151076890528202, Loss_2: 0.01157520990818739, Total Loss: 0.023085977882146835, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.04064895212650299, Loss_2: 0.009794823825359344, Total Loss: 0.050443775951862335, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.040570102632045746, Loss_2: 0.005141762550920248, Total Loss: 0.04571186378598213, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.032102495431900024, Loss_2: 0.004860122222453356, Total Loss: 0.03696261718869209, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.017477354034781456, Loss_2: 0.009998105466365814, Total Loss: 0.02747545950114727, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011012139730155468, Loss_2: 0.013802669942378998, Total Loss: 0.02481481060385704, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011298099532723427, Loss_2: 0.012804844416677952, Total Loss: 0.024102944880723953, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011518659070134163, Loss_2: 0.01225750520825386, Total Loss: 0.023776164278388023, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01164011936634779, Loss_2: 0.011932971887290478, Total Loss: 0.023573091253638268, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01162988692522049, Loss_2: 0.011801854707300663, Total Loss: 0.023431740701198578, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011604094877839088, Loss_2: 0.0117301344871521, Total Loss: 0.023334229364991188, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.016978954896330833, Loss_2: 0.025966649875044823, Total Loss: 0.042945604771375656, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.011825290508568287, Loss_2: 0.014821035787463188, Total Loss: 0.02664632722735405, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.012564368546009064, Loss_2: 0.011964760720729828, Total Loss: 0.02452912926673889, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012481811456382275, Loss_2: 0.011374245397746563, Total Loss: 0.023856056854128838, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011992874555289745, Loss_2: 0.011607114225625992, Total Loss: 0.023599989712238312, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011794446036219597, Loss_2: 0.01165942195802927, Total Loss: 0.02345386892557144, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011756502091884613, Loss_2: 0.01159500703215599, Total Loss: 0.023351509124040604, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011707749217748642, Loss_2: 0.011571028269827366, Total Loss: 0.023278776556253433, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011675761081278324, Loss_2: 0.011547812260687351, Total Loss: 0.023223573341965675, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.0116550512611866, Loss_2: 0.011525429785251617, Total Loss: 0.023180481046438217, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03552640974521637, Loss_2: 0.025518611073493958, Total Loss: 0.06104502081871033, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012726633809506893, Loss_2: 0.01564471237361431, Total Loss: 0.02837134525179863, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011513693258166313, Loss_2: 0.014424201101064682, Total Loss: 0.025937894359230995, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01175676565617323, Loss_2: 0.013154194690287113, Total Loss: 0.024910960346460342, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01181848719716072, Loss_2: 0.012480762787163258, Total Loss: 0.024299249053001404, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01178971491754055, Loss_2: 0.012155861593782902, Total Loss: 0.023945577442646027, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011724374257028103, Loss_2: 0.011985463090240955, Total Loss: 0.023709837347269058, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011668672785162926, Loss_2: 0.011878454126417637, Total Loss: 0.023547127842903137, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011624905280768871, Loss_2: 0.011805330403149128, Total Loss: 0.023430235683918, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011597774922847748, Loss_2: 0.011747222393751144, Total Loss: 0.023344997316598892, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.01283663883805275, Loss_2: 0.023947203531861305, Total Loss: 0.036783844232559204, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.014266029000282288, Loss_2: 0.015914887189865112, Total Loss: 0.0301809161901474, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.013417702168226242, Loss_2: 0.011534340679645538, Total Loss: 0.02495204284787178, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011814975179731846, Loss_2: 0.012268489226698875, Total Loss: 0.024083465337753296, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011721554212272167, Loss_2: 0.012032396160066128, Total Loss: 0.023753950372338295, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011622577905654907, Loss_2: 0.011935961432754993, Total Loss: 0.023558538407087326, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011626534163951874, Loss_2: 0.011807368136942387, Total Loss: 0.023433901369571686, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011557714082300663, Loss_2: 0.011791651137173176, Total Loss: 0.02334936521947384, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011556904762983322, Loss_2: 0.011727339588105679, Total Loss: 0.023284245282411575, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011539343744516373, Loss_2: 0.011692028492689133, Total Loss: 0.023231372237205505, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.013307171873748302, Loss_2: 0.012189076282083988, Total Loss: 0.02549624815583229, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012675636447966099, Loss_2: 0.011200334876775742, Total Loss: 0.023875970393419266, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011817152611911297, Loss_2: 0.011575254611670971, Total Loss: 0.023392407223582268, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011669582687318325, Loss_2: 0.011550409719347954, Total Loss: 0.023219991475343704, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011633471585810184, Loss_2: 0.011500103399157524, Total Loss: 0.023133575916290283, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011579656973481178, Loss_2: 0.011501881293952465, Total Loss: 0.02308153733611107, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01155097410082817, Loss_2: 0.011494857259094715, Total Loss: 0.02304583042860031, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011533680371940136, Loss_2: 0.011486269533634186, Total Loss: 0.023019950836896896, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011519020423293114, Loss_2: 0.011481224559247494, Total Loss: 0.023000244051218033, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011506934650242329, Loss_2: 0.011477823369204998, Total Loss: 0.022984758019447327, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.038367606699466705, Loss_2: 0.0257116686552763, Total Loss: 0.06407927721738815, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.03182468190789223, Loss_2: 0.016219183802604675, Total Loss: 0.0480438657104969, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.024609623476862907, Loss_2: 0.008685258217155933, Total Loss: 0.033294882625341415, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.013021173886954784, Loss_2: 0.013468126766383648, Total Loss: 0.026489300653338432, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012382078915834427, Loss_2: 0.012166418135166168, Total Loss: 0.024548497051000595, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011633990332484245, Loss_2: 0.012356537394225597, Total Loss: 0.023990526795387268, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011769379489123821, Loss_2: 0.011904901824891567, Total Loss: 0.02367428131401539, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011608241125941277, Loss_2: 0.011895623058080673, Total Loss: 0.02350386418402195, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011590879410505295, Loss_2: 0.011811884120106697, Total Loss: 0.023402763530611992, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011582269333302975, Loss_2: 0.01175567228347063, Total Loss: 0.023337941616773605, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03663165494799614, Loss_2: 0.017612168565392494, Total Loss: 0.05424382537603378, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.02879859134554863, Loss_2: 0.008527885191142559, Total Loss: 0.03732647746801376, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.024680964648723602, Loss_2: 0.008500785566866398, Total Loss: 0.033181749284267426, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.021298067644238472, Loss_2: 0.009199782274663448, Total Loss: 0.030497848987579346, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01731875352561474, Loss_2: 0.010414405725896358, Total Loss: 0.027733158320188522, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.01389117632061243, Loss_2: 0.011578123085200787, Total Loss: 0.025469299405813217, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.012318948283791542, Loss_2: 0.011928385123610497, Total Loss: 0.02424733340740204, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011822333559393883, Loss_2: 0.011909505352377892, Total Loss: 0.023731838911771774, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011673140339553356, Loss_2: 0.011849002912640572, Total Loss: 0.023522142320871353, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011654923669993877, Loss_2: 0.011764070950448513, Total Loss: 0.02341899462044239, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.0345182940363884, Loss_2: 0.03253493085503578, Total Loss: 0.06705322861671448, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012100099585950375, Loss_2: 0.018747512251138687, Total Loss: 0.030847612768411636, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.00923183560371399, Loss_2: 0.018939947709441185, Total Loss: 0.028171783313155174, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.010234073735773563, Loss_2: 0.0162514541298151, Total Loss: 0.02648552879691124, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011300628073513508, Loss_2: 0.013853097334504128, Total Loss: 0.02515372633934021, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01173805445432663, Loss_2: 0.012521662749350071, Total Loss: 0.024259716272354126, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011823197826743126, Loss_2: 0.01191570796072483, Total Loss: 0.023738905787467957, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011913037858903408, Loss_2: 0.011538345366716385, Total Loss: 0.023451384156942368, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011643779464066029, Loss_2: 0.011684115044772625, Total Loss: 0.023327894508838654, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011543500237166882, Loss_2: 0.011721093207597733, Total Loss: 0.02326459437608719, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02017379365861416, Loss_2: 0.02858668379485607, Total Loss: 0.04876047745347023, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.025751635432243347, Loss_2: 0.01255088485777378, Total Loss: 0.03830251842737198, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.02118304930627346, Loss_2: 0.010359380394220352, Total Loss: 0.03154242783784866, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.019600437954068184, Loss_2: 0.010017731226980686, Total Loss: 0.029618170112371445, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.018621673807501793, Loss_2: 0.009980125352740288, Total Loss: 0.02860179916024208, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.017405467107892036, Loss_2: 0.01031099259853363, Total Loss: 0.027716459706425667, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.016331888735294342, Loss_2: 0.010553707368671894, Total Loss: 0.02688559517264366, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.015328197740018368, Loss_2: 0.010785634629428387, Total Loss: 0.026113832369446754, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.014395971782505512, Loss_2: 0.011024149134755135, Total Loss: 0.02542012184858322, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.013619237579405308, Loss_2: 0.011201647110283375, Total Loss: 0.024820884689688683, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.018431641161441803, Loss_2: 0.014775129035115242, Total Loss: 0.033206768333911896, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012885472737252712, Loss_2: 0.01249745674431324, Total Loss: 0.025382928550243378, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.012563762255012989, Loss_2: 0.0118269557133317, Total Loss: 0.02439071796834469, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012171566486358643, Loss_2: 0.011744724586606026, Total Loss: 0.02391629107296467, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011871264316141605, Loss_2: 0.011750896461308002, Total Loss: 0.023622160777449608, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011655504815280437, Loss_2: 0.011799176223576069, Total Loss: 0.023454681038856506, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011565829627215862, Loss_2: 0.011793343350291252, Total Loss: 0.02335917204618454, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011532984673976898, Loss_2: 0.011763028800487518, Total Loss: 0.023296013474464417, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011520232073962688, Loss_2: 0.01172658707946539, Total Loss: 0.023246819153428078, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011508065275847912, Loss_2: 0.011697831563651562, Total Loss: 0.023205896839499474, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.026018396019935608, Loss_2: 0.019352087751030922, Total Loss: 0.04537048190832138, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.022403588518500328, Loss_2: 0.016185523942112923, Total Loss: 0.03858911246061325, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.0160610843449831, Loss_2: 0.016069427132606506, Total Loss: 0.03213050961494446, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.013785499148070812, Loss_2: 0.0162680484354496, Total Loss: 0.030053548514842987, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012699638493359089, Loss_2: 0.016028128564357758, Total Loss: 0.028727766126394272, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012146718800067902, Loss_2: 0.015609108842909336, Total Loss: 0.027755826711654663, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01181066408753395, Loss_2: 0.015166543424129486, Total Loss: 0.026977207511663437, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01161227747797966, Loss_2: 0.014718695543706417, Total Loss: 0.02633097395300865, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011507268995046616, Loss_2: 0.014269349165260792, Total Loss: 0.025776617228984833, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011466200463473797, Loss_2: 0.01382850855588913, Total Loss: 0.0252947099506855, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.017359569668769836, Loss_2: 0.014990133233368397, Total Loss: 0.03234970197081566, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.011667740531265736, Loss_2: 0.015089709311723709, Total Loss: 0.02675744891166687, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011635704897344112, Loss_2: 0.013523135334253311, Total Loss: 0.025158841162919998, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012345505878329277, Loss_2: 0.011955825611948967, Total Loss: 0.024301331490278244, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011898278258740902, Loss_2: 0.011882045306265354, Total Loss: 0.023780323565006256, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011769119650125504, Loss_2: 0.011710304766893387, Total Loss: 0.02347942441701889, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011680735275149345, Loss_2: 0.011629634536802769, Total Loss: 0.02331037074327469, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01160096749663353, Loss_2: 0.01161961629986763, Total Loss: 0.02322058379650116, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011590683832764626, Loss_2: 0.011574183590710163, Total Loss: 0.023164868354797363, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011573996394872665, Loss_2: 0.011551872827112675, Total Loss: 0.023125868290662766, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.01704050786793232, Loss_2: 0.012088573537766933, Total Loss: 0.02912908047437668, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.011458631604909897, Loss_2: 0.012895610183477402, Total Loss: 0.0243542417883873, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011653050780296326, Loss_2: 0.012115544639527798, Total Loss: 0.023768596351146698, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011331025511026382, Loss_2: 0.0120810866355896, Total Loss: 0.023412112146615982, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011486985720694065, Loss_2: 0.011751685291528702, Total Loss: 0.023238670080900192, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011477275751531124, Loss_2: 0.011672886088490486, Total Loss: 0.023150160908699036, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011492593213915825, Loss_2: 0.011599717661738396, Total Loss: 0.02309231087565422, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011489148251712322, Loss_2: 0.01156163215637207, Total Loss: 0.023050781339406967, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011484907940030098, Loss_2: 0.011535406112670898, Total Loss: 0.023020314052700996, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011479953303933144, Loss_2: 0.01151624321937561, Total Loss: 0.022996196523308754, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.023259060457348824, Loss_2: 0.024026457220315933, Total Loss: 0.047285519540309906, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.021142004057765007, Loss_2: 0.01632421649992466, Total Loss: 0.03746622055768967, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01710459217429161, Loss_2: 0.013618526048958302, Total Loss: 0.030723117291927338, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01444709300994873, Loss_2: 0.012928683310747147, Total Loss: 0.027375776320695877, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012994983233511448, Loss_2: 0.012672674842178822, Total Loss: 0.02566765807569027, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012301473878324032, Loss_2: 0.012337408028542995, Total Loss: 0.024638881906867027, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012090392410755157, Loss_2: 0.011988461017608643, Total Loss: 0.0240788534283638, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011860189959406853, Loss_2: 0.011896969750523567, Total Loss: 0.02375715970993042, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011757818050682545, Loss_2: 0.011814285069704056, Total Loss: 0.023572102189064026, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011726733297109604, Loss_2: 0.01172912772744894, Total Loss: 0.02345586195588112, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02983270213007927, Loss_2: 0.025934474542737007, Total Loss: 0.055767178535461426, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.019259465858340263, Loss_2: 0.024347055703401566, Total Loss: 0.04360651969909668, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.015461431816220284, Loss_2: 0.020381296053528786, Total Loss: 0.03584272786974907, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011661465279757977, Loss_2: 0.01967492327094078, Total Loss: 0.03133638948202133, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.010850872844457626, Loss_2: 0.018878759816288948, Total Loss: 0.029729632660746574, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.010732542723417282, Loss_2: 0.01817987859249115, Total Loss: 0.028912421315908432, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.010716511867940426, Loss_2: 0.01752578280866146, Total Loss: 0.028242293745279312, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.010763444937765598, Loss_2: 0.016841763630509377, Total Loss: 0.02760520949959755, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.010829727165400982, Loss_2: 0.01614866778254509, Total Loss: 0.026978395879268646, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.010949992574751377, Loss_2: 0.015414620749652386, Total Loss: 0.026364613324403763, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.011481530033051968, Loss_2: 0.025299277156591415, Total Loss: 0.03678080812096596, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.010923385620117188, Loss_2: 0.01742846518754959, Total Loss: 0.02835185080766678, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011397730559110641, Loss_2: 0.013386521488428116, Total Loss: 0.024784252047538757, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011535653844475746, Loss_2: 0.012266731821000576, Total Loss: 0.023802384734153748, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011718635447323322, Loss_2: 0.011813599616289139, Total Loss: 0.023532234132289886, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011658797971904278, Loss_2: 0.011722086928784847, Total Loss: 0.023380884900689125, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01159961149096489, Loss_2: 0.011683513410389423, Total Loss: 0.02328312397003174, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011592253111302853, Loss_2: 0.01162403542548418, Total Loss: 0.023216288536787033, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01157508697360754, Loss_2: 0.011593305505812168, Total Loss: 0.023168392479419708, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011570308357477188, Loss_2: 0.011561628431081772, Total Loss: 0.02313193678855896, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.014661160297691822, Loss_2: 0.022044988349080086, Total Loss: 0.03670614957809448, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.010055487044155598, Loss_2: 0.014947802759706974, Total Loss: 0.02500328980386257, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01212993822991848, Loss_2: 0.012148475274443626, Total Loss: 0.024278413504362106, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011264992877840996, Loss_2: 0.012431166134774685, Total Loss: 0.023696158081293106, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011327031068503857, Loss_2: 0.012130046263337135, Total Loss: 0.023457076400518417, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011397170834243298, Loss_2: 0.011922019533813, Total Loss: 0.023319190368056297, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011400865390896797, Loss_2: 0.011832093819975853, Total Loss: 0.02323295921087265, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01143298577517271, Loss_2: 0.011743828654289246, Total Loss: 0.02317681536078453, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011443967930972576, Loss_2: 0.011694321408867836, Total Loss: 0.023138288408517838, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011457026936113834, Loss_2: 0.01165270246565342, Total Loss: 0.02310973033308983, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03729340434074402, Loss_2: 0.02327554114162922, Total Loss: 0.06056894361972809, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.02829381451010704, Loss_2: 0.008183536119759083, Total Loss: 0.03647734969854355, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.023088084533810616, Loss_2: 0.008203597739338875, Total Loss: 0.03129168227314949, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.018047666177153587, Loss_2: 0.010267036035656929, Total Loss: 0.028314702212810516, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.013814203441143036, Loss_2: 0.012164431624114513, Total Loss: 0.025978635996580124, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012138398364186287, Loss_2: 0.012465105392038822, Total Loss: 0.024603504687547684, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01158691942691803, Loss_2: 0.012309358455240726, Total Loss: 0.02389627695083618, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011469041928648949, Loss_2: 0.012070219963788986, Total Loss: 0.023539261892437935, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011506804265081882, Loss_2: 0.011852461844682693, Total Loss: 0.023359265178442, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01153754536062479, Loss_2: 0.011720143258571625, Total Loss: 0.02325768768787384, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02653055265545845, Loss_2: 0.014262965880334377, Total Loss: 0.0407935194671154, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.016436278820037842, Loss_2: 0.016428640112280846, Total Loss: 0.03286492079496384, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.013646373525261879, Loss_2: 0.014280200004577637, Total Loss: 0.027926573529839516, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011972200125455856, Loss_2: 0.01392187550663948, Total Loss: 0.025894075632095337, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01154547929763794, Loss_2: 0.013483348302543163, Total Loss: 0.025028828531503677, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011644004844129086, Loss_2: 0.012943369336426258, Total Loss: 0.024587374180555344, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011606568470597267, Loss_2: 0.012655960395932198, Total Loss: 0.024262528866529465, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011603371240198612, Loss_2: 0.012415382079780102, Total Loss: 0.024018753319978714, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011571303009986877, Loss_2: 0.012259943410754204, Total Loss: 0.02383124642074108, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01155577227473259, Loss_2: 0.012129498645663261, Total Loss: 0.02368527092039585, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02428923361003399, Loss_2: 0.025196271017193794, Total Loss: 0.04948550462722778, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.015088350512087345, Loss_2: 0.014421172440052032, Total Loss: 0.029509522020816803, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01265348307788372, Loss_2: 0.012188955210149288, Total Loss: 0.024842437356710434, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012813699431717396, Loss_2: 0.011007907800376415, Total Loss: 0.02382160723209381, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012136269360780716, Loss_2: 0.011329657398164272, Total Loss: 0.023465927690267563, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.01184694655239582, Loss_2: 0.011469254270195961, Total Loss: 0.02331620082259178, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011730327270925045, Loss_2: 0.01148637942969799, Total Loss: 0.02321670576930046, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01165247056633234, Loss_2: 0.011507739312946796, Total Loss: 0.023160209879279137, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01165261585265398, Loss_2: 0.011469104327261448, Total Loss: 0.023121720179915428, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011624607257544994, Loss_2: 0.011467182077467442, Total Loss: 0.023091789335012436, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.035832688212394714, Loss_2: 0.028552304953336716, Total Loss: 0.06438499689102173, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.028333023190498352, Loss_2: 0.01670803688466549, Total Loss: 0.04504106193780899, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.02473263069987297, Loss_2: 0.013716276735067368, Total Loss: 0.03844890743494034, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.021902598440647125, Loss_2: 0.012125709094107151, Total Loss: 0.0340283066034317, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.019453998655080795, Loss_2: 0.01163517963141203, Total Loss: 0.0310891792178154, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.017409082502126694, Loss_2: 0.011555387638509274, Total Loss: 0.028964471071958542, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.015721868723630905, Loss_2: 0.011646446771919727, Total Loss: 0.027368314564228058, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01444708276540041, Loss_2: 0.011756133288145065, Total Loss: 0.0262032151222229, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.013559469021856785, Loss_2: 0.011812649667263031, Total Loss: 0.02537211775779724, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012980147264897823, Loss_2: 0.011809942312538624, Total Loss: 0.024790089577436447, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.040290217846632004, Loss_2: 0.0417170450091362, Total Loss: 0.0820072591304779, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.02120087295770645, Loss_2: 0.017567651346325874, Total Loss: 0.038768522441387177, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.019967079162597656, Loss_2: 0.013373621739447117, Total Loss: 0.0333406999707222, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.018621718510985374, Loss_2: 0.011285950429737568, Total Loss: 0.029907669872045517, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.016929220408201218, Loss_2: 0.010846060700714588, Total Loss: 0.02777528017759323, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.015086665749549866, Loss_2: 0.011106525547802448, Total Loss: 0.02619319036602974, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.013663526624441147, Loss_2: 0.011484453454613686, Total Loss: 0.025147980079054832, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.012803496792912483, Loss_2: 0.011737356893718243, Total Loss: 0.02454085275530815, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.012392912991344929, Loss_2: 0.011793491430580616, Total Loss: 0.024186404421925545, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012466399930417538, Loss_2: 0.011463047936558723, Total Loss: 0.023929446935653687, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.01776551641523838, Loss_2: 0.017899781465530396, Total Loss: 0.03566529601812363, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012553730048239231, Loss_2: 0.014442069455981255, Total Loss: 0.02699580043554306, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012147374451160431, Loss_2: 0.01246059499680996, Total Loss: 0.02460796944797039, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011935140006244183, Loss_2: 0.011710659600794315, Total Loss: 0.023645799607038498, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011572261340916157, Loss_2: 0.011750662699341774, Total Loss: 0.023322924971580505, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.01156150083988905, Loss_2: 0.011654859408736229, Total Loss: 0.023216359317302704, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011501242406666279, Loss_2: 0.011669125407934189, Total Loss: 0.023170366883277893, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01150050014257431, Loss_2: 0.011638727970421314, Total Loss: 0.02313922718167305, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011490807868540287, Loss_2: 0.011623173952102661, Total Loss: 0.023113980889320374, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011484361253678799, Loss_2: 0.011608371511101723, Total Loss: 0.023092731833457947, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.01559841725975275, Loss_2: 0.03459612652659416, Total Loss: 0.05019454285502434, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01139487512409687, Loss_2: 0.019366975873708725, Total Loss: 0.030761850997805595, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.012671155855059624, Loss_2: 0.013667833060026169, Total Loss: 0.026338988915085793, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01296576950699091, Loss_2: 0.011784815229475498, Total Loss: 0.024750584736466408, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012442751787602901, Loss_2: 0.011706157587468624, Total Loss: 0.024148909375071526, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011974744498729706, Loss_2: 0.011815260164439678, Total Loss: 0.02379000559449196, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011816129088401794, Loss_2: 0.011745480820536613, Total Loss: 0.023561609908938408, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011708160862326622, Loss_2: 0.011703353375196457, Total Loss: 0.02341151423752308, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011631675995886326, Loss_2: 0.011677974835038185, Total Loss: 0.023309651762247086, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011586231179535389, Loss_2: 0.011651720851659775, Total Loss: 0.02323795109987259, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.012227650731801987, Loss_2: 0.014394271187484264, Total Loss: 0.026621922850608826, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012512710876762867, Loss_2: 0.011772911995649338, Total Loss: 0.02428562194108963, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011633781716227531, Loss_2: 0.012087211944162846, Total Loss: 0.02372099459171295, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011597424745559692, Loss_2: 0.011943136341869831, Total Loss: 0.02354056015610695, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01157775241881609, Loss_2: 0.011849706061184406, Total Loss: 0.023427458480000496, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011588766239583492, Loss_2: 0.01176021434366703, Total Loss: 0.023348979651927948, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011545172892510891, Loss_2: 0.011742649599909782, Total Loss: 0.0232878215610981, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01153868343681097, Loss_2: 0.011697684414684772, Total Loss: 0.023236367851495743, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011525539681315422, Loss_2: 0.011667084880173206, Total Loss: 0.023192625492811203, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011512636207044125, Loss_2: 0.01164192147552967, Total Loss: 0.02315455675125122, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.045558176934719086, Loss_2: 0.0204060897231102, Total Loss: 0.06596426665782928, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.03556329384446144, Loss_2: 0.016153201460838318, Total Loss: 0.05171649530529976, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.026616867631673813, Loss_2: 0.010283916257321835, Total Loss: 0.03690078482031822, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01644374057650566, Loss_2: 0.011115961708128452, Total Loss: 0.02755970135331154, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.010469540022313595, Loss_2: 0.014267160557210445, Total Loss: 0.02473670057952404, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.010591152124106884, Loss_2: 0.013455372303724289, Total Loss: 0.024046525359153748, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011370508000254631, Loss_2: 0.01210732664912939, Total Loss: 0.023477833718061447, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011808889918029308, Loss_2: 0.01147680077701807, Total Loss: 0.02328569069504738, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011793067678809166, Loss_2: 0.011419860646128654, Total Loss: 0.02321292832493782, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011682543903589249, Loss_2: 0.01148166786879301, Total Loss: 0.023164212703704834, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.025221023708581924, Loss_2: 0.017559794709086418, Total Loss: 0.04278081655502319, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.015330635942518711, Loss_2: 0.013515311293303967, Total Loss: 0.028845947235822678, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011586673557758331, Loss_2: 0.014035942032933235, Total Loss: 0.025622615590691566, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012293217703700066, Loss_2: 0.012293629348278046, Total Loss: 0.02458684705197811, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012250479310750961, Loss_2: 0.011703591793775558, Total Loss: 0.02395407110452652, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011783990077674389, Loss_2: 0.011807669885456562, Total Loss: 0.02359165996313095, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011732164770364761, Loss_2: 0.011655997484922409, Total Loss: 0.02338816225528717, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011608535423874855, Loss_2: 0.011662972159683704, Total Loss: 0.023271508514881134, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01157095655798912, Loss_2: 0.011629007756710052, Total Loss: 0.023199964314699173, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.01153344102203846, Loss_2: 0.011617718264460564, Total Loss: 0.023151159286499023, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.013776054605841637, Loss_2: 0.010975760407745838, Total Loss: 0.02475181594491005, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012478843331336975, Loss_2: 0.011102982796728611, Total Loss: 0.02358182519674301, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011225705966353416, Loss_2: 0.011960272677242756, Total Loss: 0.023185979574918747, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011481007561087608, Loss_2: 0.011559206992387772, Total Loss: 0.02304021455347538, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011572171933948994, Loss_2: 0.011416039429605007, Total Loss: 0.022988211363554, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011516382917761803, Loss_2: 0.011448183096945286, Total Loss: 0.022964566946029663, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011490965262055397, Loss_2: 0.01145988143980503, Total Loss: 0.022950846701860428, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011483040638267994, Loss_2: 0.011458351276814938, Total Loss: 0.02294139191508293, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011475839652121067, Loss_2: 0.0114584444090724, Total Loss: 0.022934284061193466, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011470543220639229, Loss_2: 0.011458187364041805, Total Loss: 0.02292872965335846, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.03022134117782116, Loss_2: 0.009318317286670208, Total Loss: 0.03953965753316879, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01923941634595394, Loss_2: 0.008983288891613483, Total Loss: 0.02822270616889, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012412098236382008, Loss_2: 0.01239935215562582, Total Loss: 0.024811450392007828, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012391345575451851, Loss_2: 0.011740203015506268, Total Loss: 0.024131547659635544, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01173306442797184, Loss_2: 0.012044355273246765, Total Loss: 0.023777419701218605, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011841215193271637, Loss_2: 0.011733479797840118, Total Loss: 0.023574694991111755, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011701765470206738, Loss_2: 0.011737511493265629, Total Loss: 0.023439276963472366, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011673185974359512, Loss_2: 0.011667273007333279, Total Loss: 0.023340459913015366, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011625152081251144, Loss_2: 0.011639580130577087, Total Loss: 0.023264732211828232, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011588571593165398, Loss_2: 0.011616451665759087, Total Loss: 0.023205023258924484, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.013827289454638958, Loss_2: 0.012303211726248264, Total Loss: 0.026130501180887222, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.010576576925814152, Loss_2: 0.013089179061353207, Total Loss: 0.02366575598716736, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011612807400524616, Loss_2: 0.011658485047519207, Total Loss: 0.023271292448043823, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011506001465022564, Loss_2: 0.011608903296291828, Total Loss: 0.023114904761314392, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011515825055539608, Loss_2: 0.011548427864909172, Total Loss: 0.023064251989126205, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011519643478095531, Loss_2: 0.01151394471526146, Total Loss: 0.023033589124679565, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011500979773700237, Loss_2: 0.01150980032980442, Total Loss: 0.023010779172182083, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011492044664919376, Loss_2: 0.011500849388539791, Total Loss: 0.022992894053459167, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011485425755381584, Loss_2: 0.011493032798171043, Total Loss: 0.022978458553552628, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011359844356775284, Loss_2: 0.011606012471020222, Total Loss: 0.02296585589647293, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.013352601788938046, Loss_2: 0.011790338903665543, Total Loss: 0.025142941623926163, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012306690216064453, Loss_2: 0.011088463477790356, Total Loss: 0.023395154625177383, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011820673942565918, Loss_2: 0.011348450556397438, Total Loss: 0.023169124498963356, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011634363792836666, Loss_2: 0.011439219117164612, Total Loss: 0.023073583841323853, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011553500778973103, Loss_2: 0.011473341844975948, Total Loss: 0.02302684262394905, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011535575613379478, Loss_2: 0.01146070845425129, Total Loss: 0.022996284067630768, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011509431526064873, Loss_2: 0.011464596726000309, Total Loss: 0.022974029183387756, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01150467712432146, Loss_2: 0.011452676728367805, Total Loss: 0.02295735478401184, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011484244838356972, Loss_2: 0.011461124755442142, Total Loss: 0.02294537052512169, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011492477729916573, Loss_2: 0.011444678530097008, Total Loss: 0.02293715626001358, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.018662652000784874, Loss_2: 0.01962984912097454, Total Loss: 0.038292501121759415, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.010466828010976315, Loss_2: 0.017879247665405273, Total Loss: 0.028346076607704163, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011702116578817368, Loss_2: 0.012674952857196331, Total Loss: 0.024377070367336273, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011691583320498466, Loss_2: 0.011934774927794933, Total Loss: 0.023626357316970825, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011533918790519238, Loss_2: 0.011855682358145714, Total Loss: 0.023389600217342377, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011476580053567886, Loss_2: 0.011825607158243656, Total Loss: 0.023302186280488968, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011454558931291103, Loss_2: 0.011788529343903065, Total Loss: 0.023243088275194168, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011460915207862854, Loss_2: 0.011738702654838562, Total Loss: 0.023199617862701416, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011458340100944042, Loss_2: 0.011706559918820858, Total Loss: 0.0231649000197649, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011455322615802288, Loss_2: 0.011680199764668941, Total Loss: 0.02313552238047123, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.013281580060720444, Loss_2: 0.030371755361557007, Total Loss: 0.04365333542227745, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.015416022390127182, Loss_2: 0.018932657316327095, Total Loss: 0.034348681569099426, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01456814631819725, Loss_2: 0.018029097467660904, Total Loss: 0.032597243785858154, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01306307315826416, Loss_2: 0.01650303788483143, Total Loss: 0.02956611104309559, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012370774522423744, Loss_2: 0.015567014925181866, Total Loss: 0.027937788516283035, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012168580666184425, Loss_2: 0.01465602871030569, Total Loss: 0.02682460844516754, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012236018665134907, Loss_2: 0.013798193074762821, Total Loss: 0.026034211739897728, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.012347857467830181, Loss_2: 0.013116389513015747, Total Loss: 0.025464247912168503, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.012377463281154633, Loss_2: 0.012666681781411171, Total Loss: 0.025044145062565804, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.012514798901975155, Loss_2: 0.012172864750027657, Total Loss: 0.024687662720680237, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02899932488799095, Loss_2: 0.019514447078108788, Total Loss: 0.04851377010345459, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01648780144751072, Loss_2: 0.012752724811434746, Total Loss: 0.029240526258945465, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013741262257099152, Loss_2: 0.011980962008237839, Total Loss: 0.02572222426533699, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.0119015509262681, Loss_2: 0.012815666384994984, Total Loss: 0.024717217311263084, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012196384370326996, Loss_2: 0.011998926289379597, Total Loss: 0.024195309728384018, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011921216733753681, Loss_2: 0.011933951638638973, Total Loss: 0.023855168372392654, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011802979744970798, Loss_2: 0.011815778911113739, Total Loss: 0.023618757724761963, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011744534596800804, Loss_2: 0.011706034652888775, Total Loss: 0.023450568318367004, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011677068658173084, Loss_2: 0.011653130874037743, Total Loss: 0.0233302004635334, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011636955663561821, Loss_2: 0.011605732142925262, Total Loss: 0.023242687806487083, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.011610705405473709, Loss_2: 0.013377576135098934, Total Loss: 0.024988282471895218, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.011854281648993492, Loss_2: 0.011915472336113453, Total Loss: 0.02376975491642952, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01178903691470623, Loss_2: 0.011434206739068031, Total Loss: 0.02322324365377426, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011618213728070259, Loss_2: 0.011441804468631744, Total Loss: 0.023060018196702003, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.0114964060485363, Loss_2: 0.01150396466255188, Total Loss: 0.02300037071108818, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011472431942820549, Loss_2: 0.011499376967549324, Total Loss: 0.022971808910369873, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011478657834231853, Loss_2: 0.011475765146315098, Total Loss: 0.02295442298054695, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01147607434540987, Loss_2: 0.011466986499726772, Total Loss: 0.022943060845136642, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01146694179624319, Loss_2: 0.011468208394944668, Total Loss: 0.02293515019118786, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011462435126304626, Loss_2: 0.011467045173048973, Total Loss: 0.0229294802993536, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.027624761685729027, Loss_2: 0.0159477386623621, Total Loss: 0.043572500348091125, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012353863567113876, Loss_2: 0.01627642661333084, Total Loss: 0.028630290180444717, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01282693911343813, Loss_2: 0.01149873249232769, Total Loss: 0.024325672537088394, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012236615642905235, Loss_2: 0.01155504398047924, Total Loss: 0.023791659623384476, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011949600651860237, Loss_2: 0.011564008891582489, Total Loss: 0.023513609543442726, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011841755360364914, Loss_2: 0.011514930054545403, Total Loss: 0.023356685414910316, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011749401688575745, Loss_2: 0.011502661742269993, Total Loss: 0.023252062499523163, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011688049882650375, Loss_2: 0.011491281911730766, Total Loss: 0.02317933179438114, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011645051650702953, Loss_2: 0.011482445523142815, Total Loss: 0.023127496242523193, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011605125851929188, Loss_2: 0.011484881862998009, Total Loss: 0.02309000864624977, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.01954755000770092, Loss_2: 0.03451114147901535, Total Loss: 0.05405869334936142, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012111452408134937, Loss_2: 0.018491776660084724, Total Loss: 0.030603229999542236, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01155959814786911, Loss_2: 0.014546525664627552, Total Loss: 0.026106122881174088, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011665103025734425, Loss_2: 0.01316434983164072, Total Loss: 0.024829452857375145, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011862999759614468, Loss_2: 0.0124210175126791, Total Loss: 0.024284016340970993, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011759696528315544, Loss_2: 0.012162948027253151, Total Loss: 0.023922644555568695, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011771650984883308, Loss_2: 0.011920318007469177, Total Loss: 0.023691968992352486, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01173437386751175, Loss_2: 0.01180290151387453, Total Loss: 0.023537274450063705, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011609919369220734, Loss_2: 0.011810963973402977, Total Loss: 0.02342088334262371, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011608239263296127, Loss_2: 0.011729742400348186, Total Loss: 0.02333798259496689, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.017410926520824432, Loss_2: 0.02860341966152191, Total Loss: 0.046014346182346344, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.013686149381101131, Loss_2: 0.014230017550289631, Total Loss: 0.027916166931390762, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.013694686815142632, Loss_2: 0.011730496771633625, Total Loss: 0.02542518451809883, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012642423622310162, Loss_2: 0.011495962738990784, Total Loss: 0.02413838729262352, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011767162010073662, Loss_2: 0.011853192001581192, Total Loss: 0.023620354011654854, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.01167495921254158, Loss_2: 0.011719667352735996, Total Loss: 0.023394625633955002, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011716354638338089, Loss_2: 0.011568382382392883, Total Loss: 0.023284737020730972, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011661076918244362, Loss_2: 0.011553839780390263, Total Loss: 0.0232149176299572, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011623461730778217, Loss_2: 0.011542728170752525, Total Loss: 0.023166190832853317, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011592243798077106, Loss_2: 0.01153901033103466, Total Loss: 0.02313125506043434, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03306596726179123, Loss_2: 0.014755639247596264, Total Loss: 0.04782160744071007, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.02341429516673088, Loss_2: 0.012261521071195602, Total Loss: 0.03567581623792648, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.014530607499182224, Loss_2: 0.013502765446901321, Total Loss: 0.02803337201476097, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01181752234697342, Loss_2: 0.01410585455596447, Total Loss: 0.02592337690293789, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012001574039459229, Loss_2: 0.012849290855228901, Total Loss: 0.024850863963365555, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011924654245376587, Loss_2: 0.012355852872133255, Total Loss: 0.024280507117509842, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011670178733766079, Loss_2: 0.012263108044862747, Total Loss: 0.0239332877099514, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011651641689240932, Loss_2: 0.012066982686519623, Total Loss: 0.02371862530708313, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011620109900832176, Loss_2: 0.011958633549511433, Total Loss: 0.023578744381666183, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011606454849243164, Loss_2: 0.01187143661081791, Total Loss: 0.023477891460061073, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.041849248111248016, Loss_2: 0.018893824890255928, Total Loss: 0.060743071138858795, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.031532157212495804, Loss_2: 0.016036497429013252, Total Loss: 0.047568656504154205, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.021794810891151428, Loss_2: 0.01109867263585329, Total Loss: 0.032893482595682144, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01505247876048088, Loss_2: 0.011839611455798149, Total Loss: 0.02689209021627903, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.010648269206285477, Loss_2: 0.013968274928629398, Total Loss: 0.0246165432035923, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011337530799210072, Loss_2: 0.012694314122200012, Total Loss: 0.02403184399008751, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011477084830403328, Loss_2: 0.012282958254218102, Total Loss: 0.02376004308462143, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011562608182430267, Loss_2: 0.012044564820826054, Total Loss: 0.023607172071933746, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011585243046283722, Loss_2: 0.011913829483091831, Total Loss: 0.02349907159805298, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011575710028409958, Loss_2: 0.011838093400001526, Total Loss: 0.023413803428411484, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.022547759115695953, Loss_2: 0.0236566923558712, Total Loss: 0.046204451471567154, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012123903259634972, Loss_2: 0.01563354954123497, Total Loss: 0.02775745280086994, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011561155319213867, Loss_2: 0.013515104539692402, Total Loss: 0.025076258927583694, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011911269277334213, Loss_2: 0.012327456846833229, Total Loss: 0.024238726124167442, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011721629649400711, Loss_2: 0.01216618437319994, Total Loss: 0.023887813091278076, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01156620029360056, Loss_2: 0.012071372009813786, Total Loss: 0.023637572303414345, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011534836143255234, Loss_2: 0.011927693150937557, Total Loss: 0.023462530225515366, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011502934619784355, Loss_2: 0.011840449646115303, Total Loss: 0.023343384265899658, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011487947776913643, Loss_2: 0.0117721538990736, Total Loss: 0.023260101675987244, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01147504523396492, Loss_2: 0.011724898591637611, Total Loss: 0.02319994382560253, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.01894531026482582, Loss_2: 0.013747857883572578, Total Loss: 0.03269317001104355, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.010519507341086864, Loss_2: 0.015679290518164635, Total Loss: 0.026198796927928925, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.010708825662732124, Loss_2: 0.01370560098439455, Total Loss: 0.02441442757844925, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01197925116866827, Loss_2: 0.011967504397034645, Total Loss: 0.02394675463438034, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012007498182356358, Loss_2: 0.011659707874059677, Total Loss: 0.02366720512509346, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011739845387637615, Loss_2: 0.011756251566112041, Total Loss: 0.023496096953749657, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011707535944879055, Loss_2: 0.011670649982988834, Total Loss: 0.02337818592786789, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011641963385045528, Loss_2: 0.01164967380464077, Total Loss: 0.023291636258363724, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011591501533985138, Loss_2: 0.011634357273578644, Total Loss: 0.023225858807563782, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011559096165001392, Loss_2: 0.011616319417953491, Total Loss: 0.02317541465163231, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.028908459469676018, Loss_2: 0.0293057169765234, Total Loss: 0.05821417644619942, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.014644844457507133, Loss_2: 0.016412505879998207, Total Loss: 0.03105735033750534, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011576492339372635, Loss_2: 0.014248550869524479, Total Loss: 0.02582504227757454, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012651313096284866, Loss_2: 0.011654427275061607, Total Loss: 0.024305740371346474, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012025263160467148, Loss_2: 0.01195297110825777, Total Loss: 0.023978233337402344, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011740408837795258, Loss_2: 0.01200134214013815, Total Loss: 0.02374175190925598, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011760941706597805, Loss_2: 0.011805488727986813, Total Loss: 0.023566430434584618, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011638687923550606, Loss_2: 0.011799563653767109, Total Loss: 0.02343825250864029, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011601708829402924, Loss_2: 0.011744646355509758, Total Loss: 0.02334635518491268, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011583806946873665, Loss_2: 0.011693993583321571, Total Loss: 0.023277800530195236, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03740868717432022, Loss_2: 0.018468961119651794, Total Loss: 0.055877648293972015, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01863194815814495, Loss_2: 0.010611513629555702, Total Loss: 0.029243461787700653, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01228056289255619, Loss_2: 0.01223310362547636, Total Loss: 0.024513665586709976, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011556005105376244, Loss_2: 0.011994482018053532, Total Loss: 0.02355048805475235, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011626554653048515, Loss_2: 0.011705946177244186, Total Loss: 0.0233325008302927, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011606638319790363, Loss_2: 0.011631510220468044, Total Loss: 0.023238148540258408, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011632791720330715, Loss_2: 0.011550226248800755, Total Loss: 0.02318301796913147, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011637553572654724, Loss_2: 0.011508598923683167, Total Loss: 0.02314615249633789, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01162806712090969, Loss_2: 0.011488989926874638, Total Loss: 0.023117057979106903, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011612399481236935, Loss_2: 0.011479480192065239, Total Loss: 0.0230918787419796, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03377397730946541, Loss_2: 0.029869507998228073, Total Loss: 0.06364348530769348, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.011201406829059124, Loss_2: 0.015748409554362297, Total Loss: 0.026949815452098846, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011283714324235916, Loss_2: 0.012958154082298279, Total Loss: 0.024241868406534195, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012644479051232338, Loss_2: 0.010932440869510174, Total Loss: 0.023576918989419937, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01170405838638544, Loss_2: 0.011618005111813545, Total Loss: 0.02332206442952156, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011745456606149673, Loss_2: 0.011491073295474052, Total Loss: 0.023236529901623726, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011655941605567932, Loss_2: 0.011532148346304893, Total Loss: 0.023188089951872826, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011638429015874863, Loss_2: 0.011512253433465958, Total Loss: 0.02315068244934082, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.0116184763610363, Loss_2: 0.01150214672088623, Total Loss: 0.02312062308192253, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011600125581026077, Loss_2: 0.011495204642415047, Total Loss: 0.023095330223441124, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.041706230491399765, Loss_2: 0.01174496952444315, Total Loss: 0.05345119908452034, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02448928728699684, Loss_2: 0.006984848529100418, Total Loss: 0.03147413581609726, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013165531679987907, Loss_2: 0.012567330151796341, Total Loss: 0.02573286183178425, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011228294111788273, Loss_2: 0.013406977988779545, Total Loss: 0.024635272100567818, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012098497711122036, Loss_2: 0.012028658762574196, Total Loss: 0.024127155542373657, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011961820535361767, Loss_2: 0.011899761855602264, Total Loss: 0.023861583322286606, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011896010488271713, Loss_2: 0.011787079274654388, Total Loss: 0.0236830897629261, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011818903498351574, Loss_2: 0.011726787313818932, Total Loss: 0.02354568988084793, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011756312102079391, Loss_2: 0.011681185103952885, Total Loss: 0.0234374962747097, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011718334630131721, Loss_2: 0.011635001748800278, Total Loss: 0.023353336378932, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02661585621535778, Loss_2: 0.011124001815915108, Total Loss: 0.03773985803127289, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02072651870548725, Loss_2: 0.010468028485774994, Total Loss: 0.031194547191262245, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01664860174059868, Loss_2: 0.010144279338419437, Total Loss: 0.02679288014769554, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01433839276432991, Loss_2: 0.011048617772758007, Total Loss: 0.025387011468410492, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012677964754402637, Loss_2: 0.011761254630982876, Total Loss: 0.024439219385385513, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011854532174766064, Loss_2: 0.012095248326659203, Total Loss: 0.02394977957010269, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011679616756737232, Loss_2: 0.012014192529022694, Total Loss: 0.023693809285759926, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011706769466400146, Loss_2: 0.011810244992375374, Total Loss: 0.02351701445877552, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011688615195453167, Loss_2: 0.011701894924044609, Total Loss: 0.0233905091881752, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011646727100014687, Loss_2: 0.011651130393147469, Total Loss: 0.023297857493162155, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.024214422330260277, Loss_2: 0.034572165459394455, Total Loss: 0.05878658592700958, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.014465347863733768, Loss_2: 0.01753239519894123, Total Loss: 0.031997743993997574, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01321140956133604, Loss_2: 0.014575011096894741, Total Loss: 0.02778642065823078, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01254584826529026, Loss_2: 0.012803591787815094, Total Loss: 0.025349440053105354, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012454447336494923, Loss_2: 0.011942372657358646, Total Loss: 0.02439681999385357, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012337255291640759, Loss_2: 0.01161543931812048, Total Loss: 0.023952694609761238, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01214890368282795, Loss_2: 0.011538506485521793, Total Loss: 0.023687411099672318, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011960415169596672, Loss_2: 0.011551662348210812, Total Loss: 0.02351207658648491, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011833877302706242, Loss_2: 0.011557528749108315, Total Loss: 0.02339140698313713, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011751364916563034, Loss_2: 0.011554687283933163, Total Loss: 0.02330605313181877, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02465052157640457, Loss_2: 0.019087472930550575, Total Loss: 0.04373799264431, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.013160797767341137, Loss_2: 0.013236181810498238, Total Loss: 0.0263969786465168, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01204244326800108, Loss_2: 0.012291889637708664, Total Loss: 0.024334333837032318, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011543615721166134, Loss_2: 0.012198961339890957, Total Loss: 0.02374257706105709, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011545843444764614, Loss_2: 0.012011418119072914, Total Loss: 0.023557260632514954, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011459304951131344, Loss_2: 0.011960205622017384, Total Loss: 0.023419510573148727, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011493748053908348, Loss_2: 0.011817536316812038, Total Loss: 0.023311283439397812, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011490977369248867, Loss_2: 0.011736294254660606, Total Loss: 0.0232272706925869, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011490638367831707, Loss_2: 0.011673355475068092, Total Loss: 0.023163992911577225, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011485506780445576, Loss_2: 0.011630762368440628, Total Loss: 0.02311626821756363, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.08991692960262299, Loss_2: 0.08484356105327606, Total Loss: 0.17476049065589905, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.03190790116786957, Loss_2: 0.023277219384908676, Total Loss: 0.055185120552778244, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.024910928681492805, Loss_2: 0.016324585303664207, Total Loss: 0.04123551398515701, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.021989695727825165, Loss_2: 0.014956817962229252, Total Loss: 0.03694651275873184, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01971481740474701, Loss_2: 0.01433524675667286, Total Loss: 0.03405006229877472, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.017321810126304626, Loss_2: 0.014320637099444866, Total Loss: 0.03164244815707207, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.015317312441766262, Loss_2: 0.014331797137856483, Total Loss: 0.02964910864830017, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.013660424388945103, Loss_2: 0.01437586359679699, Total Loss: 0.028036288917064667, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.012652291916310787, Loss_2: 0.014131247065961361, Total Loss: 0.026783538982272148, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011777523905038834, Loss_2: 0.014044002629816532, Total Loss: 0.02582152560353279, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.008655967190861702, Loss_2: 0.021449429914355278, Total Loss: 0.03010539710521698, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012187786400318146, Loss_2: 0.013468564487993717, Total Loss: 0.02565634995698929, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011668979190289974, Loss_2: 0.012553971260786057, Total Loss: 0.024222951382398605, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011548180133104324, Loss_2: 0.012124266475439072, Total Loss: 0.023672446608543396, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011573364026844501, Loss_2: 0.01183948665857315, Total Loss: 0.023412849754095078, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011582606472074986, Loss_2: 0.011681159026920795, Total Loss: 0.02326376549899578, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011560006067156792, Loss_2: 0.011608784087002277, Total Loss: 0.023168791085481644, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011541605927050114, Loss_2: 0.011562749743461609, Total Loss: 0.023104354739189148, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01153547689318657, Loss_2: 0.011524130590260029, Total Loss: 0.023059606552124023, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011524914763867855, Loss_2: 0.011502567678689957, Total Loss: 0.023027483373880386, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.028898730874061584, Loss_2: 0.014210998080670834, Total Loss: 0.04310972988605499, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.0217639971524477, Loss_2: 0.011356737464666367, Total Loss: 0.033120736479759216, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01722964271903038, Loss_2: 0.01224167924374342, Total Loss: 0.029471322894096375, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.014185287989675999, Loss_2: 0.012832642532885075, Total Loss: 0.027017930522561073, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.013180251233279705, Loss_2: 0.012662271969020367, Total Loss: 0.02584252320230007, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012570110149681568, Loss_2: 0.012465719133615494, Total Loss: 0.025035828351974487, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012164735235273838, Loss_2: 0.012327481992542744, Total Loss: 0.02449221722781658, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01197708398103714, Loss_2: 0.012136203236877918, Total Loss: 0.024113286286592484, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011840236373245716, Loss_2: 0.012002682313323021, Total Loss: 0.02384291961789131, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011744196526706219, Loss_2: 0.011902634985744953, Total Loss: 0.023646831512451172, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.007299390621483326, Loss_2: 0.021473785862326622, Total Loss: 0.028773177415132523, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01232798583805561, Loss_2: 0.01191262248903513, Total Loss: 0.024240609258413315, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012040862813591957, Loss_2: 0.011389568448066711, Total Loss: 0.02343043126165867, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011276171542704105, Loss_2: 0.011966129764914513, Total Loss: 0.023242302238941193, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011511368677020073, Loss_2: 0.011630675755441189, Total Loss: 0.023142043501138687, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011441025882959366, Loss_2: 0.01164685282856226, Total Loss: 0.02308787778019905, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011469381861388683, Loss_2: 0.011583859100937843, Total Loss: 0.023053240031003952, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011459114030003548, Loss_2: 0.011569480411708355, Total Loss: 0.023028593510389328, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011458749882876873, Loss_2: 0.011551235802471638, Total Loss: 0.02300998568534851, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011458530090749264, Loss_2: 0.011537089012563229, Total Loss: 0.022995619103312492, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.03879215940833092, Loss_2: 0.022608594968914986, Total Loss: 0.06140075623989105, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.0226032305508852, Loss_2: 0.013033564202487469, Total Loss: 0.035636793822050095, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.0179660115391016, Loss_2: 0.010510952211916447, Total Loss: 0.028476964682340622, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.013574179261922836, Loss_2: 0.011543328873813152, Total Loss: 0.025117509067058563, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.010889901779592037, Loss_2: 0.013190451078116894, Total Loss: 0.02408035285770893, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011221184395253658, Loss_2: 0.0125271650031209, Total Loss: 0.023748349398374557, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01163114421069622, Loss_2: 0.011995172128081322, Total Loss: 0.023626316338777542, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011649729683995247, Loss_2: 0.011916765943169594, Total Loss: 0.02356649562716484, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011601092293858528, Loss_2: 0.011920765973627567, Total Loss: 0.02352185919880867, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011560148559510708, Loss_2: 0.011920293793082237, Total Loss: 0.02348044142127037, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.028167443349957466, Loss_2: 0.04031815379858017, Total Loss: 0.06848559528589249, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.019994819536805153, Loss_2: 0.02053498476743698, Total Loss: 0.040529802441596985, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.014037428423762321, Loss_2: 0.0156398955732584, Total Loss: 0.02967732399702072, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012180985882878304, Loss_2: 0.013781317509710789, Total Loss: 0.025962304323911667, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012273739092051983, Loss_2: 0.012448816560208797, Total Loss: 0.02472255565226078, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012131177820265293, Loss_2: 0.012128160335123539, Total Loss: 0.024259338155388832, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011952965520322323, Loss_2: 0.012039621360599995, Total Loss: 0.023992586880922318, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011919083073735237, Loss_2: 0.011884894222021103, Total Loss: 0.02380397729575634, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011877221055328846, Loss_2: 0.011796669103205204, Total Loss: 0.02367389015853405, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011825618334114552, Loss_2: 0.01176407653838396, Total Loss: 0.023589694872498512, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.03095628134906292, Loss_2: 0.02908420003950596, Total Loss: 0.06004048138856888, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.0215089563280344, Loss_2: 0.012216263450682163, Total Loss: 0.03372522071003914, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.017491620033979416, Loss_2: 0.011330942623317242, Total Loss: 0.028822563588619232, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.014355408027768135, Loss_2: 0.011754296720027924, Total Loss: 0.02610970474779606, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01298236008733511, Loss_2: 0.011768577620387077, Total Loss: 0.024750936776399612, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012345933355391026, Loss_2: 0.011829680763185024, Total Loss: 0.02417561411857605, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012186592444777489, Loss_2: 0.011676670052111149, Total Loss: 0.023863263428211212, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.012029009871184826, Loss_2: 0.011621704325079918, Total Loss: 0.02365071326494217, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011891953647136688, Loss_2: 0.011606032960116863, Total Loss: 0.023497987538576126, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011802945286035538, Loss_2: 0.01158776506781578, Total Loss: 0.02339071035385132, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02680400386452675, Loss_2: 0.024775125086307526, Total Loss: 0.051579128950834274, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01634257845580578, Loss_2: 0.011953369714319706, Total Loss: 0.02829594910144806, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013764414936304092, Loss_2: 0.012434057891368866, Total Loss: 0.02619847282767296, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012229178100824356, Loss_2: 0.012514031492173672, Total Loss: 0.024743210524320602, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011820482090115547, Loss_2: 0.012352154590189457, Total Loss: 0.02417263761162758, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011768939904868603, Loss_2: 0.012122093699872494, Total Loss: 0.023891033604741096, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011758937500417233, Loss_2: 0.011969611048698425, Total Loss: 0.023728549480438232, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01173589751124382, Loss_2: 0.011876133270561695, Total Loss: 0.02361202985048294, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011713292449712753, Loss_2: 0.011803894303739071, Total Loss: 0.0235171876847744, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011689556762576103, Loss_2: 0.011747380718588829, Total Loss: 0.023436937481164932, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.031619638204574585, Loss_2: 0.016669804230332375, Total Loss: 0.04828944057226181, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.018092773854732513, Loss_2: 0.010990853421390057, Total Loss: 0.029083628207445145, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013584191910922527, Loss_2: 0.0126517154276371, Total Loss: 0.026235908269882202, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012375923804938793, Loss_2: 0.012464873492717743, Total Loss: 0.02484079822897911, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012311914935708046, Loss_2: 0.011866609565913677, Total Loss: 0.02417852357029915, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012116584926843643, Loss_2: 0.011706103570759296, Total Loss: 0.023822687566280365, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011938611045479774, Loss_2: 0.011665917001664639, Total Loss: 0.02360452711582184, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011809106916189194, Loss_2: 0.011650861240923405, Total Loss: 0.023459967225790024, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011723521165549755, Loss_2: 0.011637476272881031, Total Loss: 0.023360997438430786, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011663483455777168, Loss_2: 0.011627537198364735, Total Loss: 0.023291021585464478, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.04620056226849556, Loss_2: 0.012896088883280754, Total Loss: 0.059096649289131165, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02947099320590496, Loss_2: 0.012621404603123665, Total Loss: 0.042092397809028625, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.0234985314309597, Loss_2: 0.011399156413972378, Total Loss: 0.034897688776254654, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.017761850729584694, Loss_2: 0.011834242381155491, Total Loss: 0.02959609404206276, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01206457894295454, Loss_2: 0.013754402287304401, Total Loss: 0.02581898123025894, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012357397004961967, Loss_2: 0.011887154541909695, Total Loss: 0.024244550615549088, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.012493077665567398, Loss_2: 0.011230257339775562, Total Loss: 0.023723334074020386, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01228871289640665, Loss_2: 0.011248375289142132, Total Loss: 0.023537088185548782, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.012078932486474514, Loss_2: 0.011330577544867992, Total Loss: 0.023409510031342506, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011965842917561531, Loss_2: 0.011356635019183159, Total Loss: 0.02332247793674469, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.04509367421269417, Loss_2: 0.01835472136735916, Total Loss: 0.06344839930534363, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.03438490256667137, Loss_2: 0.012053399346768856, Total Loss: 0.0464383028447628, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.03177522495388985, Loss_2: 0.010508700273931026, Total Loss: 0.04228392615914345, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.029362397268414497, Loss_2: 0.0090631740167737, Total Loss: 0.03842557221651077, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.02729109674692154, Loss_2: 0.008670179173350334, Total Loss: 0.03596127778291702, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.025100694969296455, Loss_2: 0.008775189518928528, Total Loss: 0.033875882625579834, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.02264459617435932, Loss_2: 0.009274802170693874, Total Loss: 0.03191939741373062, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01991114765405655, Loss_2: 0.010024000890552998, Total Loss: 0.029935147613286972, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.017092851921916008, Loss_2: 0.010865275748074055, Total Loss: 0.027958128601312637, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.014656336978077888, Loss_2: 0.011490996927022934, Total Loss: 0.026147333905100822, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.0148536441847682, Loss_2: 0.030609872192144394, Total Loss: 0.04546351730823517, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.010011435486376286, Loss_2: 0.020110169425606728, Total Loss: 0.030121605843305588, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012409025803208351, Loss_2: 0.012666663154959679, Total Loss: 0.02507568895816803, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012242297641932964, Loss_2: 0.011814452707767487, Total Loss: 0.024056751281023026, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012208188883960247, Loss_2: 0.011477758176624775, Total Loss: 0.023685947060585022, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011998265981674194, Loss_2: 0.011476540938019753, Total Loss: 0.023474806919693947, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011849863454699516, Loss_2: 0.011477620340883732, Total Loss: 0.023327484726905823, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011758142150938511, Loss_2: 0.011466889642179012, Total Loss: 0.023225031793117523, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01168829295784235, Loss_2: 0.011466511525213718, Total Loss: 0.02315480448305607, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011641713790595531, Loss_2: 0.011462302878499031, Total Loss: 0.023104015737771988, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.017024662345647812, Loss_2: 0.02424885891377926, Total Loss: 0.04127351939678192, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.010004117153584957, Loss_2: 0.019115380942821503, Total Loss: 0.029119499027729034, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01115258689969778, Loss_2: 0.014622229151427746, Total Loss: 0.025774816051125526, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011801873333752155, Loss_2: 0.013090047053992748, Total Loss: 0.024891920387744904, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011361072771251202, Loss_2: 0.01309173833578825, Total Loss: 0.02445281110703945, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011413711123168468, Loss_2: 0.012740815989673138, Total Loss: 0.024154527112841606, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011423989199101925, Loss_2: 0.012508906424045563, Total Loss: 0.023932896554470062, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01148197427392006, Loss_2: 0.012285060249269009, Total Loss: 0.023767035454511642, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011493529193103313, Loss_2: 0.012145237997174263, Total Loss: 0.023638766258955002, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011484797112643719, Loss_2: 0.012052064761519432, Total Loss: 0.023536860942840576, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.018330950289964676, Loss_2: 0.027761580422520638, Total Loss: 0.04609253257513046, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.010403580032289028, Loss_2: 0.01761113665997982, Total Loss: 0.028014715760946274, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011758708395063877, Loss_2: 0.014163600280880928, Total Loss: 0.02592230960726738, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011708610691130161, Loss_2: 0.01329923328012228, Total Loss: 0.02500784397125244, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.01184927299618721, Loss_2: 0.012587100267410278, Total Loss: 0.02443637326359749, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011815212666988373, Loss_2: 0.012250321917235851, Total Loss: 0.0240655355155468, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011757142841815948, Loss_2: 0.012055585160851479, Total Loss: 0.023812728002667427, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011715433560311794, Loss_2: 0.011921068653464317, Total Loss: 0.023636501282453537, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01166660338640213, Loss_2: 0.01184098795056343, Total Loss: 0.02350759133696556, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011627488769590855, Loss_2: 0.011785012669861317, Total Loss: 0.02341250143945217, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.021378889679908752, Loss_2: 0.011979215778410435, Total Loss: 0.03335810452699661, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01339486800134182, Loss_2: 0.01754799485206604, Total Loss: 0.03094286285340786, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01377103477716446, Loss_2: 0.013521920889616013, Total Loss: 0.027292955666780472, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.0125278290361166, Loss_2: 0.01322253979742527, Total Loss: 0.02575036883354187, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011564384214580059, Loss_2: 0.01323662418872118, Total Loss: 0.02480100840330124, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.01163881178945303, Loss_2: 0.012520668096840382, Total Loss: 0.02415947988629341, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011386835016310215, Loss_2: 0.012367361225187778, Total Loss: 0.023754196241497993, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01181316003203392, Loss_2: 0.011705528944730759, Total Loss: 0.02351868897676468, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011771022342145443, Loss_2: 0.011606712825596333, Total Loss: 0.023377735167741776, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01171270664781332, Loss_2: 0.011567859910428524, Total Loss: 0.023280566558241844, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.019348036497831345, Loss_2: 0.032048989087343216, Total Loss: 0.05139702558517456, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01583811454474926, Loss_2: 0.026630161330103874, Total Loss: 0.042468275874853134, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011965726502239704, Loss_2: 0.02034122310578823, Total Loss: 0.03230695053935051, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012191199697554111, Loss_2: 0.01655690371990204, Total Loss: 0.028748102486133575, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.013236528262495995, Loss_2: 0.013333617709577084, Total Loss: 0.026570145040750504, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.013759752735495567, Loss_2: 0.011747057549655437, Total Loss: 0.02550680935382843, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01344410888850689, Loss_2: 0.01140652783215046, Total Loss: 0.02485063672065735, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01292890589684248, Loss_2: 0.011466062627732754, Total Loss: 0.024394968524575233, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01252709049731493, Loss_2: 0.011548290960490704, Total Loss: 0.024075381457805634, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012206275947391987, Loss_2: 0.011642095632851124, Total Loss: 0.02384837158024311, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.040863972157239914, Loss_2: 0.008192943409085274, Total Loss: 0.04905691742897034, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.029245194047689438, Loss_2: 0.00951323565095663, Total Loss: 0.03875843062996864, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.02548612840473652, Loss_2: 0.009318654425442219, Total Loss: 0.03480478376150131, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01977730356156826, Loss_2: 0.010165073908865452, Total Loss: 0.029942378401756287, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.015447222627699375, Loss_2: 0.011506245471537113, Total Loss: 0.02695346809923649, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012624457478523254, Loss_2: 0.012697594240307808, Total Loss: 0.025322051718831062, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011463629081845284, Loss_2: 0.013114402070641518, Total Loss: 0.0245780311524868, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011174331419169903, Loss_2: 0.013047090731561184, Total Loss: 0.024221422150731087, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01121025625616312, Loss_2: 0.01278225239366293, Total Loss: 0.02399250864982605, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011270084418356419, Loss_2: 0.012553189881145954, Total Loss: 0.023823274299502373, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03217388316988945, Loss_2: 0.013405871577560902, Total Loss: 0.04557975381612778, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02256224863231182, Loss_2: 0.014648445881903172, Total Loss: 0.03721069544553757, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01968260109424591, Loss_2: 0.012852017767727375, Total Loss: 0.03253461793065071, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01672370545566082, Loss_2: 0.012338039465248585, Total Loss: 0.02906174585223198, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.014926782809197903, Loss_2: 0.012383917346596718, Total Loss: 0.027310699224472046, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.013621661812067032, Loss_2: 0.012434965930879116, Total Loss: 0.026056628674268723, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.012741495855152607, Loss_2: 0.012456897646188736, Total Loss: 0.02519839257001877, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.012242544442415237, Loss_2: 0.012302055954933167, Total Loss: 0.024544600397348404, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.012126910500228405, Loss_2: 0.011876184493303299, Total Loss: 0.02400309592485428, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011855938471853733, Loss_2: 0.011905927211046219, Total Loss: 0.023761864751577377, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.016288938000798225, Loss_2: 0.02584107778966427, Total Loss: 0.042130015790462494, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.013741896487772465, Loss_2: 0.023657873272895813, Total Loss: 0.0373997688293457, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01157557126134634, Loss_2: 0.02100139483809471, Total Loss: 0.032576967030763626, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.009673968888819218, Loss_2: 0.02082037925720215, Total Loss: 0.03049434721469879, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.009275101125240326, Loss_2: 0.02006465010344982, Total Loss: 0.029339751228690147, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.009644892066717148, Loss_2: 0.018563270568847656, Total Loss: 0.028208162635564804, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.010339081287384033, Loss_2: 0.01671389862895012, Total Loss: 0.027052979916334152, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.01094513013958931, Loss_2: 0.015066209249198437, Total Loss: 0.02601134032011032, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011188906617462635, Loss_2: 0.013978369534015656, Total Loss: 0.025167275220155716, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011302786879241467, Loss_2: 0.013235755264759064, Total Loss: 0.024538543075323105, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.009782945737242699, Loss_2: 0.014746114611625671, Total Loss: 0.02452906034886837, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.011533677577972412, Loss_2: 0.011840487830340862, Total Loss: 0.02337416633963585, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011765889823436737, Loss_2: 0.011386306956410408, Total Loss: 0.023152196779847145, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01147877424955368, Loss_2: 0.011584841646254063, Total Loss: 0.02306361496448517, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011459057219326496, Loss_2: 0.011559750884771347, Total Loss: 0.02301880717277527, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011480403132736683, Loss_2: 0.011508231051266193, Total Loss: 0.022988634184002876, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011482798494398594, Loss_2: 0.011484730057418346, Total Loss: 0.02296752855181694, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011478584259748459, Loss_2: 0.011473634280264378, Total Loss: 0.022952217608690262, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011474072933197021, Loss_2: 0.011466781608760357, Total Loss: 0.022940855473279953, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011470298282802105, Loss_2: 0.011462213471531868, Total Loss: 0.0229325108230114, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03040534257888794, Loss_2: 0.010620246641337872, Total Loss: 0.041025590151548386, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.027040915563702583, Loss_2: 0.010525848716497421, Total Loss: 0.037566766142845154, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.022688431665301323, Loss_2: 0.00961083173751831, Total Loss: 0.03229926526546478, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01907307095825672, Loss_2: 0.010037094354629517, Total Loss: 0.029110165312886238, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.015480492264032364, Loss_2: 0.011239983141422272, Total Loss: 0.026720475405454636, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012956997379660606, Loss_2: 0.012473586946725845, Total Loss: 0.02543058432638645, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011930206790566444, Loss_2: 0.012846598401665688, Total Loss: 0.024776805192232132, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011761133559048176, Loss_2: 0.012577868066728115, Total Loss: 0.02433900162577629, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011737613938748837, Loss_2: 0.012292523868381977, Total Loss: 0.024030137807130814, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011688766069710255, Loss_2: 0.012109803035855293, Total Loss: 0.023798570036888123, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.025432223454117775, Loss_2: 0.021159878000617027, Total Loss: 0.0465921014547348, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.023147063329815865, Loss_2: 0.01682911068201065, Total Loss: 0.039976172149181366, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01241549476981163, Loss_2: 0.01779051683843136, Total Loss: 0.03020601160824299, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012638339772820473, Loss_2: 0.014745860360562801, Total Loss: 0.0273841992020607, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011964738368988037, Loss_2: 0.013732879422605038, Total Loss: 0.02569761872291565, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012135790660977364, Loss_2: 0.012439239770174026, Total Loss: 0.02457503043115139, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.0119282566010952, Loss_2: 0.011986764147877693, Total Loss: 0.023915020748972893, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011775574646890163, Loss_2: 0.011852848343551159, Total Loss: 0.023628422990441322, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011709257960319519, Loss_2: 0.011777309700846672, Total Loss: 0.02348656766116619, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011633766815066338, Loss_2: 0.011762973852455616, Total Loss: 0.023396741598844528, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.026432739570736885, Loss_2: 0.012594723142683506, Total Loss: 0.039027463644742966, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.01196221448481083, Loss_2: 0.013595469295978546, Total Loss: 0.025557683780789375, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013207345269620419, Loss_2: 0.01149868592619896, Total Loss: 0.024706032127141953, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012282092124223709, Loss_2: 0.011906378902494907, Total Loss: 0.024188470095396042, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012196207419037819, Loss_2: 0.011708790436387062, Total Loss: 0.02390499785542488, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012129868380725384, Loss_2: 0.011584571562707424, Total Loss: 0.023714439943432808, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01197882741689682, Loss_2: 0.011592906899750233, Total Loss: 0.023571733385324478, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01191366370767355, Loss_2: 0.011547144502401352, Total Loss: 0.023460809141397476, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01184851210564375, Loss_2: 0.011520760133862495, Total Loss: 0.02336927130818367, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011797890067100525, Loss_2: 0.01149753574281931, Total Loss: 0.02329542487859726, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.019010212272405624, Loss_2: 0.016440244391560555, Total Loss: 0.03545045852661133, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.015570977702736855, Loss_2: 0.010716171003878117, Total Loss: 0.026287149637937546, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012159444391727448, Loss_2: 0.01220318116247654, Total Loss: 0.024362625554203987, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011672408320009708, Loss_2: 0.012181228958070278, Total Loss: 0.023853637278079987, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011617458425462246, Loss_2: 0.011990160681307316, Total Loss: 0.023607619106769562, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011562741361558437, Loss_2: 0.011902163736522198, Total Loss: 0.023464905098080635, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011534747667610645, Loss_2: 0.011834324337542057, Total Loss: 0.023369072005152702, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011524556204676628, Loss_2: 0.011777257546782494, Total Loss: 0.02330181375145912, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011511721648275852, Loss_2: 0.011739685200154781, Total Loss: 0.023251406848430634, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011504972353577614, Loss_2: 0.011705925688147545, Total Loss: 0.02321089804172516, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.03945181146264076, Loss_2: 0.0207151398062706, Total Loss: 0.06016695126891136, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02113432064652443, Loss_2: 0.015755318105220795, Total Loss: 0.036889638751745224, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.014606962911784649, Loss_2: 0.012969095259904861, Total Loss: 0.027576059103012085, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012819122523069382, Loss_2: 0.012931104749441147, Total Loss: 0.02575022727251053, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012227775529026985, Loss_2: 0.012682251632213593, Total Loss: 0.024910027161240578, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01204458437860012, Loss_2: 0.012328141368925571, Total Loss: 0.024372726678848267, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011987519450485706, Loss_2: 0.012033307924866676, Total Loss: 0.024020828306674957, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011941201984882355, Loss_2: 0.011839941143989563, Total Loss: 0.023781143128871918, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011891430243849754, Loss_2: 0.011723482050001621, Total Loss: 0.02361491322517395, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011851439252495766, Loss_2: 0.01164670754224062, Total Loss: 0.02349814772605896, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.015987226739525795, Loss_2: 0.01680593751370907, Total Loss: 0.03279316425323486, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.019454780966043472, Loss_2: 0.01414560154080391, Total Loss: 0.03360038250684738, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.015331684611737728, Loss_2: 0.013205722905695438, Total Loss: 0.028537407517433167, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.013348896987736225, Loss_2: 0.01373600959777832, Total Loss: 0.02708490565419197, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.012617439962923527, Loss_2: 0.013360184617340565, Total Loss: 0.02597762458026409, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012559964321553707, Loss_2: 0.012609844096004963, Total Loss: 0.02516980841755867, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012471909634768963, Loss_2: 0.01211641076952219, Total Loss: 0.024588320404291153, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.012296635657548904, Loss_2: 0.01186593808233738, Total Loss: 0.024162573739886284, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.012108134105801582, Loss_2: 0.01173887774348259, Total Loss: 0.023847011849284172, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011944337747991085, Loss_2: 0.011669546365737915, Total Loss: 0.023613885045051575, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.02826828882098198, Loss_2: 0.006754829082638025, Total Loss: 0.03502311930060387, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.017482783645391464, Loss_2: 0.008310342207551003, Total Loss: 0.025793125852942467, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011652419343590736, Loss_2: 0.012281255796551704, Total Loss: 0.02393367514014244, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011374464258551598, Loss_2: 0.012120144441723824, Total Loss: 0.02349460870027542, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011458838358521461, Loss_2: 0.01183921005576849, Total Loss: 0.023298047482967377, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011534235440194607, Loss_2: 0.011651966720819473, Total Loss: 0.023186203092336655, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011514624580740929, Loss_2: 0.011603039689362049, Total Loss: 0.023117665201425552, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011506353504955769, Loss_2: 0.011568045243620872, Total Loss: 0.023074399679899216, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01150351483374834, Loss_2: 0.011541488580405712, Total Loss: 0.023045003414154053, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011497946456074715, Loss_2: 0.011525509878993034, Total Loss: 0.02302345633506775, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.031029528006911278, Loss_2: 0.017489217221736908, Total Loss: 0.048518747091293335, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.018830228596925735, Loss_2: 0.010610200464725494, Total Loss: 0.02944042906165123, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.017196258530020714, Loss_2: 0.010720489546656609, Total Loss: 0.027916748076677322, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.015633437782526016, Loss_2: 0.01073757465928793, Total Loss: 0.02637101337313652, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.014180288650095463, Loss_2: 0.011122439987957478, Total Loss: 0.02530272863805294, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.013014905154705048, Loss_2: 0.011493031866848469, Total Loss: 0.024507936090230942, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012293470092117786, Loss_2: 0.01167008001357317, Total Loss: 0.023963550105690956, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011914219707250595, Loss_2: 0.011706866323947906, Total Loss: 0.0236210860311985, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011716675013303757, Loss_2: 0.011701376177370548, Total Loss: 0.02341805025935173, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011611784808337688, Loss_2: 0.011688108555972576, Total Loss: 0.023299893364310265, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.017631305381655693, Loss_2: 0.012096964754164219, Total Loss: 0.029728271067142487, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.010785560123622417, Loss_2: 0.013874840922653675, Total Loss: 0.024660401046276093, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.011902260594069958, Loss_2: 0.011829458177089691, Total Loss: 0.023731719702482224, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.01184774748980999, Loss_2: 0.011457152664661407, Total Loss: 0.023304900154471397, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011493343859910965, Loss_2: 0.011667138896882534, Total Loss: 0.023160483688116074, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011568344198167324, Loss_2: 0.011524534784257412, Total Loss: 0.023092878982424736, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011555654928088188, Loss_2: 0.011498077772557735, Total Loss: 0.02305373176932335, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011540701612830162, Loss_2: 0.01148604229092598, Total Loss: 0.02302674390375614, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011530651710927486, Loss_2: 0.011476069688796997, Total Loss: 0.023006722331047058, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011521182022988796, Loss_2: 0.011469822376966476, Total Loss: 0.022991005331277847, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02527451515197754, Loss_2: 0.009575034491717815, Total Loss: 0.03484955057501793, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.016903463751077652, Loss_2: 0.010898681357502937, Total Loss: 0.02780214510858059, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012718664482235909, Loss_2: 0.012141438201069832, Total Loss: 0.02486010268330574, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011739570647478104, Loss_2: 0.01210849080234766, Total Loss: 0.02384806051850319, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011403669603168964, Loss_2: 0.012145429849624634, Total Loss: 0.023549098521471024, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011588804423809052, Loss_2: 0.011830092407763004, Total Loss: 0.02341889590024948, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01158860046416521, Loss_2: 0.011739544570446014, Total Loss: 0.02332814410328865, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011576673947274685, Loss_2: 0.011681151576340199, Total Loss: 0.023257825523614883, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.0115660410374403, Loss_2: 0.01163602713495493, Total Loss: 0.023202069103717804, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011556671932339668, Loss_2: 0.01159990206360817, Total Loss: 0.023156573995947838, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.026942702010273933, Loss_2: 0.007842451333999634, Total Loss: 0.03478515148162842, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.022580869495868683, Loss_2: 0.011206600815057755, Total Loss: 0.03378747031092644, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.016404611989855766, Loss_2: 0.010887651704251766, Total Loss: 0.027292262762784958, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.013623381033539772, Loss_2: 0.012374124489724636, Total Loss: 0.025997504591941833, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012640319764614105, Loss_2: 0.012573972344398499, Total Loss: 0.025214292109012604, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012516820803284645, Loss_2: 0.012192383408546448, Total Loss: 0.024709204211831093, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.012377896346151829, Loss_2: 0.01196321565657854, Total Loss: 0.02434111200273037, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.012199752032756805, Loss_2: 0.011865577660501003, Total Loss: 0.024065330624580383, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.01208964642137289, Loss_2: 0.011767197400331497, Total Loss: 0.023856844753026962, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012009802274405956, Loss_2: 0.01168663427233696, Total Loss: 0.02369643747806549, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.027711637318134308, Loss_2: 0.025796640664339066, Total Loss: 0.05350827798247337, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.026350848376750946, Loss_2: 0.015236089006066322, Total Loss: 0.04158693552017212, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.02431509457528591, Loss_2: 0.013305716216564178, Total Loss: 0.03762081265449524, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.021564844995737076, Loss_2: 0.012708127498626709, Total Loss: 0.034272972494363785, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.018765199929475784, Loss_2: 0.012653275392949581, Total Loss: 0.03141847625374794, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.016391994431614876, Loss_2: 0.01272545475512743, Total Loss: 0.02911745011806488, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.014425835572183132, Loss_2: 0.012808417901396751, Total Loss: 0.02723425254225731, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.012915626168251038, Loss_2: 0.012875031679868698, Total Loss: 0.025790657848119736, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.012211774475872517, Loss_2: 0.012750954367220402, Total Loss: 0.02496272884309292, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.012159643694758415, Loss_2: 0.012344243004918098, Total Loss: 0.024503886699676514, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.027698077261447906, Loss_2: 0.019727712497115135, Total Loss: 0.04742579162120819, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01619393192231655, Loss_2: 0.013770464807748795, Total Loss: 0.029964396730065346, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.013259297236800194, Loss_2: 0.013275651261210442, Total Loss: 0.026534948498010635, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01167723536491394, Loss_2: 0.013177569955587387, Total Loss: 0.024854805320501328, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011720662005245686, Loss_2: 0.012502944096922874, Total Loss: 0.024223607033491135, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011789544485509396, Loss_2: 0.012072504498064518, Total Loss: 0.023862048983573914, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011693517677485943, Loss_2: 0.011944694444537163, Total Loss: 0.02363821119070053, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011695804074406624, Loss_2: 0.01179015263915062, Total Loss: 0.023485956713557243, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011675198562443256, Loss_2: 0.01169813983142376, Total Loss: 0.02337333932518959, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011645668186247349, Loss_2: 0.01164038386195898, Total Loss: 0.02328605204820633, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.013179158791899681, Loss_2: 0.013797217048704624, Total Loss: 0.02697637677192688, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012065079994499683, Loss_2: 0.012272854335606098, Total Loss: 0.02433793433010578, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01178090088069439, Loss_2: 0.011864996515214443, Total Loss: 0.023645896464586258, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01172726135700941, Loss_2: 0.01165745873004198, Total Loss: 0.02338472008705139, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011665288358926773, Loss_2: 0.011600385420024395, Total Loss: 0.023265674710273743, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011650956235826015, Loss_2: 0.011544191278517246, Total Loss: 0.02319514751434326, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.01161446887999773, Loss_2: 0.011531978845596313, Total Loss: 0.02314644679427147, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011586354114115238, Loss_2: 0.011521689593791962, Total Loss: 0.023108042776584625, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011567138135433197, Loss_2: 0.011510081589221954, Total Loss: 0.02307721972465515, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011548510752618313, Loss_2: 0.011503757908940315, Total Loss: 0.023052267730236053, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.03913059085607529, Loss_2: 0.019120439887046814, Total Loss: 0.0582510307431221, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.024441128596663475, Loss_2: 0.009751974605023861, Total Loss: 0.03419310227036476, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.01960000768303871, Loss_2: 0.009697360917925835, Total Loss: 0.029297368600964546, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.014502228237688541, Loss_2: 0.011621701531112194, Total Loss: 0.026123929768800735, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012048320844769478, Loss_2: 0.012744544073939323, Total Loss: 0.0247928649187088, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011708737351000309, Loss_2: 0.012598990462720394, Total Loss: 0.024307727813720703, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011806209571659565, Loss_2: 0.012261804193258286, Total Loss: 0.024068012833595276, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011783930473029613, Loss_2: 0.012112497352063656, Total Loss: 0.02389642782509327, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011777078732848167, Loss_2: 0.011982472613453865, Total Loss: 0.023759551346302032, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011763863265514374, Loss_2: 0.011883783154189587, Total Loss: 0.023647647351026535, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.015260444022715092, Loss_2: 0.010345966555178165, Total Loss: 0.025606410577893257, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.012466727755963802, Loss_2: 0.011307785287499428, Total Loss: 0.023774512112140656, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.011277989484369755, Loss_2: 0.012106084264814854, Total Loss: 0.02338407374918461, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.011513501405715942, Loss_2: 0.011705013923346996, Total Loss: 0.023218516260385513, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.011578590609133244, Loss_2: 0.011554071679711342, Total Loss: 0.02313266322016716, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.011569310910999775, Loss_2: 0.011512244120240211, Total Loss: 0.02308155596256256, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011559459380805492, Loss_2: 0.011488987132906914, Total Loss: 0.02304844558238983, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011546509340405464, Loss_2: 0.011478481814265251, Total Loss: 0.023024991154670715, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011536219157278538, Loss_2: 0.011470909230411053, Total Loss: 0.02300712838768959, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.01152507308870554, Loss_2: 0.011467539705336094, Total Loss: 0.022992612794041634, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02646755799651146, Loss_2: 0.02631618268787861, Total Loss: 0.05278374254703522, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.018262896686792374, Loss_2: 0.01292047556489706, Total Loss: 0.03118337318301201, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.014264523051679134, Loss_2: 0.012044074013829231, Total Loss: 0.02630859613418579, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.01230742409825325, Loss_2: 0.012660914100706577, Total Loss: 0.024968337267637253, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012079250998795033, Loss_2: 0.012213042005896568, Total Loss: 0.024292293936014175, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.012202178128063679, Loss_2: 0.011675198562443256, Total Loss: 0.023877376690506935, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.012017589062452316, Loss_2: 0.011591312475502491, Total Loss: 0.023608900606632233, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011876861564815044, Loss_2: 0.011550511233508587, Total Loss: 0.02342737279832363, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011797764338552952, Loss_2: 0.011505627073347569, Total Loss: 0.02330339141190052, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011723523028194904, Loss_2: 0.01149536669254303, Total Loss: 0.02321888878941536, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.02262859232723713, Loss_2: 0.018275538459420204, Total Loss: 0.04090413078665733, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.01539682038128376, Loss_2: 0.012836879119277, Total Loss: 0.02823369950056076, Epoch Time: 0.00 seconds\n",
      "Epoch 60/200, Loss_1: 0.014249850995838642, Loss_2: 0.011104021221399307, Total Loss: 0.025353871285915375, Epoch Time: 0.00 seconds\n",
      "Epoch 80/200, Loss_1: 0.012766370549798012, Loss_2: 0.011741235852241516, Total Loss: 0.024507606402039528, Epoch Time: 0.00 seconds\n",
      "Epoch 100/200, Loss_1: 0.012097283266484737, Loss_2: 0.01192393247038126, Total Loss: 0.024021215736865997, Epoch Time: 0.00 seconds\n",
      "Epoch 120/200, Loss_1: 0.0119327949360013, Loss_2: 0.011802359484136105, Total Loss: 0.023735154420137405, Epoch Time: 0.00 seconds\n",
      "Epoch 140/200, Loss_1: 0.011811467818915844, Loss_2: 0.011724952608346939, Total Loss: 0.023536421358585358, Epoch Time: 0.00 seconds\n",
      "Epoch 160/200, Loss_1: 0.011695814318954945, Loss_2: 0.011696442030370235, Total Loss: 0.02339225634932518, Epoch Time: 0.00 seconds\n",
      "Epoch 180/200, Loss_1: 0.011637351475656033, Loss_2: 0.011649111285805702, Total Loss: 0.02328646183013916, Epoch Time: 0.00 seconds\n",
      "Epoch 200/200, Loss_1: 0.011596539057791233, Loss_2: 0.011612337082624435, Total Loss: 0.023208875209093094, Epoch Time: 0.00 seconds\n",
      "Epoch 20/200, Loss_1: 0.049670446664094925, Loss_2: 0.016890259459614754, Total Loss: 0.06656070798635483, Epoch Time: 0.00 seconds\n",
      "Epoch 40/200, Loss_1: 0.032542914152145386, Loss_2: 0.00798074807971716, Total Loss: 0.04052366316318512, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01802106946706772, Loss_2: 0.009714549407362938, Total Loss: 0.027735618874430656, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.011673065833747387, Loss_2: 0.012762604281306267, Total Loss: 0.02443566918373108, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.01211701612919569, Loss_2: 0.01174433808773756, Total Loss: 0.02386135421693325, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011801977641880512, Loss_2: 0.0117508415132761, Total Loss: 0.023552820086479187, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011745406314730644, Loss_2: 0.011660444550216198, Total Loss: 0.023405849933624268, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011693663895130157, Loss_2: 0.011633441783487797, Total Loss: 0.02332710474729538, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011671687476336956, Loss_2: 0.011604780331254005, Total Loss: 0.023276466876268387, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011644971556961536, Loss_2: 0.011592617258429527, Total Loss: 0.02323758974671364, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.023480337113142014, Loss_2: 0.02194153144955635, Total Loss: 0.045421868562698364, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.02022242732346058, Loss_2: 0.015588704496622086, Total Loss: 0.035811133682727814, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.01694646291434765, Loss_2: 0.013253442011773586, Total Loss: 0.03019990399479866, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.0114384600892663, Loss_2: 0.01407445129007101, Total Loss: 0.02551291137933731, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011272168718278408, Loss_2: 0.013229095377027988, Total Loss: 0.024501264095306396, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.01138214860111475, Loss_2: 0.012612116523087025, Total Loss: 0.023994265124201775, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011474965140223503, Loss_2: 0.012223879806697369, Total Loss: 0.023698844015598297, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01162493135780096, Loss_2: 0.011888865381479263, Total Loss: 0.0235137976706028, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011700478382408619, Loss_2: 0.011695114895701408, Total Loss: 0.023395594209432602, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011740692891180515, Loss_2: 0.011577468365430832, Total Loss: 0.023318160325288773, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.021892139688134193, Loss_2: 0.023099474608898163, Total Loss: 0.04499161243438721, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.0151160703971982, Loss_2: 0.013988615013659, Total Loss: 0.0291046854108572, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012500562705099583, Loss_2: 0.0119862025603652, Total Loss: 0.024486765265464783, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.010887530632317066, Loss_2: 0.012933481484651566, Total Loss: 0.023821011185646057, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011633549816906452, Loss_2: 0.011996950022876263, Total Loss: 0.023630499839782715, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011637209914624691, Loss_2: 0.011890366673469543, Total Loss: 0.02352757751941681, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.01161198504269123, Loss_2: 0.011828938499093056, Total Loss: 0.023440923541784286, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011592105031013489, Loss_2: 0.011777381412684917, Total Loss: 0.02336948737502098, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011575186625123024, Loss_2: 0.01173377688974142, Total Loss: 0.02330896258354187, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.01157191302627325, Loss_2: 0.011685257777571678, Total Loss: 0.023257169872522354, Epoch Time: 0.01 seconds\n",
      "Epoch 20/200, Loss_1: 0.020740488544106483, Loss_2: 0.034826621413230896, Total Loss: 0.05556710809469223, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.012372341006994247, Loss_2: 0.019466038793325424, Total Loss: 0.03183837980031967, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.012301897630095482, Loss_2: 0.01446799747645855, Total Loss: 0.02676989510655403, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012928844429552555, Loss_2: 0.011920657008886337, Total Loss: 0.024849500507116318, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.013008923269808292, Loss_2: 0.011198517866432667, Total Loss: 0.02420744113624096, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.012435751035809517, Loss_2: 0.01140528917312622, Total Loss: 0.023841040208935738, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.012058448046445847, Loss_2: 0.011549406684935093, Total Loss: 0.023607853800058365, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.01189915556460619, Loss_2: 0.011562765575945377, Total Loss: 0.023461921140551567, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.011795063503086567, Loss_2: 0.011569604277610779, Total Loss: 0.02336466684937477, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011717689223587513, Loss_2: 0.011576775461435318, Total Loss: 0.023294463753700256, Epoch Time: 0.01 seconds\n",
      "Best decay coefficient: 0.6000000000000001, MSE: 0.09009374750908783\n",
      "Epoch 20/200, Loss_1: 0.032861802726984024, Loss_2: 0.025357255712151527, Total Loss: 0.0582190603017807, Epoch Time: 0.01 seconds\n",
      "Epoch 40/200, Loss_1: 0.016296548768877983, Loss_2: 0.012693905271589756, Total Loss: 0.028990454971790314, Epoch Time: 0.01 seconds\n",
      "Epoch 60/200, Loss_1: 0.013810970820486546, Loss_2: 0.01162564754486084, Total Loss: 0.02543661743402481, Epoch Time: 0.01 seconds\n",
      "Epoch 80/200, Loss_1: 0.012535223737359047, Loss_2: 0.011950962245464325, Total Loss: 0.024486185982823372, Epoch Time: 0.01 seconds\n",
      "Epoch 100/200, Loss_1: 0.011912964284420013, Loss_2: 0.012138064019382, Total Loss: 0.024051029235124588, Epoch Time: 0.01 seconds\n",
      "Epoch 120/200, Loss_1: 0.011747270822525024, Loss_2: 0.012060970067977905, Total Loss: 0.02380824089050293, Epoch Time: 0.01 seconds\n",
      "Epoch 140/200, Loss_1: 0.011672778986394405, Loss_2: 0.011964963749051094, Total Loss: 0.023637741804122925, Epoch Time: 0.01 seconds\n",
      "Epoch 160/200, Loss_1: 0.011601257137954235, Loss_2: 0.01191435195505619, Total Loss: 0.02351560816168785, Epoch Time: 0.01 seconds\n",
      "Epoch 180/200, Loss_1: 0.01156903337687254, Loss_2: 0.011858079582452774, Total Loss: 0.023427113890647888, Epoch Time: 0.01 seconds\n",
      "Epoch 200/200, Loss_1: 0.011557413265109062, Loss_2: 0.0118047334253788, Total Loss: 0.02336214669048786, Epoch Time: 0.01 seconds\n",
      "Training times per epoch for best decay coefficient (0.6000000000000001):\n",
      "Epoch 1: 0.01 seconds\n",
      "Epoch 2: 0.01 seconds\n",
      "Epoch 3: 0.01 seconds\n",
      "Epoch 4: 0.01 seconds\n",
      "Epoch 5: 0.01 seconds\n",
      "Epoch 6: 0.01 seconds\n",
      "Epoch 7: 0.01 seconds\n",
      "Epoch 8: 0.01 seconds\n",
      "Epoch 9: 0.01 seconds\n",
      "Epoch 10: 0.01 seconds\n",
      "Epoch 11: 0.01 seconds\n",
      "Epoch 12: 0.01 seconds\n",
      "Epoch 13: 0.01 seconds\n",
      "Epoch 14: 0.01 seconds\n",
      "Epoch 15: 0.01 seconds\n",
      "Epoch 16: 0.01 seconds\n",
      "Epoch 17: 0.01 seconds\n",
      "Epoch 18: 0.01 seconds\n",
      "Epoch 19: 0.01 seconds\n",
      "Epoch 20: 0.01 seconds\n",
      "Epoch 21: 0.01 seconds\n",
      "Epoch 22: 0.01 seconds\n",
      "Epoch 23: 0.01 seconds\n",
      "Epoch 24: 0.01 seconds\n",
      "Epoch 25: 0.01 seconds\n",
      "Epoch 26: 0.01 seconds\n",
      "Epoch 27: 0.01 seconds\n",
      "Epoch 28: 0.01 seconds\n",
      "Epoch 29: 0.01 seconds\n",
      "Epoch 30: 0.01 seconds\n",
      "Epoch 31: 0.01 seconds\n",
      "Epoch 32: 0.01 seconds\n",
      "Epoch 33: 0.01 seconds\n",
      "Epoch 34: 0.01 seconds\n",
      "Epoch 35: 0.01 seconds\n",
      "Epoch 36: 0.01 seconds\n",
      "Epoch 37: 0.01 seconds\n",
      "Epoch 38: 0.01 seconds\n",
      "Epoch 39: 0.01 seconds\n",
      "Epoch 40: 0.01 seconds\n",
      "Epoch 41: 0.01 seconds\n",
      "Epoch 42: 0.01 seconds\n",
      "Epoch 43: 0.01 seconds\n",
      "Epoch 44: 0.01 seconds\n",
      "Epoch 45: 0.01 seconds\n",
      "Epoch 46: 0.01 seconds\n",
      "Epoch 47: 0.01 seconds\n",
      "Epoch 48: 0.01 seconds\n",
      "Epoch 49: 0.01 seconds\n",
      "Epoch 50: 0.01 seconds\n",
      "Epoch 51: 0.01 seconds\n",
      "Epoch 52: 0.01 seconds\n",
      "Epoch 53: 0.01 seconds\n",
      "Epoch 54: 0.01 seconds\n",
      "Epoch 55: 0.01 seconds\n",
      "Epoch 56: 0.01 seconds\n",
      "Epoch 57: 0.01 seconds\n",
      "Epoch 58: 0.01 seconds\n",
      "Epoch 59: 0.01 seconds\n",
      "Epoch 60: 0.01 seconds\n",
      "Epoch 61: 0.01 seconds\n",
      "Epoch 62: 0.01 seconds\n",
      "Epoch 63: 0.01 seconds\n",
      "Epoch 64: 0.01 seconds\n",
      "Epoch 65: 0.01 seconds\n",
      "Epoch 66: 0.01 seconds\n",
      "Epoch 67: 0.01 seconds\n",
      "Epoch 68: 0.01 seconds\n",
      "Epoch 69: 0.01 seconds\n",
      "Epoch 70: 0.01 seconds\n",
      "Epoch 71: 0.01 seconds\n",
      "Epoch 72: 0.01 seconds\n",
      "Epoch 73: 0.01 seconds\n",
      "Epoch 74: 0.01 seconds\n",
      "Epoch 75: 0.01 seconds\n",
      "Epoch 76: 0.01 seconds\n",
      "Epoch 77: 0.01 seconds\n",
      "Epoch 78: 0.01 seconds\n",
      "Epoch 79: 0.01 seconds\n",
      "Epoch 80: 0.01 seconds\n",
      "Epoch 81: 0.01 seconds\n",
      "Epoch 82: 0.01 seconds\n",
      "Epoch 83: 0.01 seconds\n",
      "Epoch 84: 0.01 seconds\n",
      "Epoch 85: 0.01 seconds\n",
      "Epoch 86: 0.01 seconds\n",
      "Epoch 87: 0.01 seconds\n",
      "Epoch 88: 0.01 seconds\n",
      "Epoch 89: 0.01 seconds\n",
      "Epoch 90: 0.01 seconds\n",
      "Epoch 91: 0.01 seconds\n",
      "Epoch 92: 0.01 seconds\n",
      "Epoch 93: 0.01 seconds\n",
      "Epoch 94: 0.01 seconds\n",
      "Epoch 95: 0.01 seconds\n",
      "Epoch 96: 0.01 seconds\n",
      "Epoch 97: 0.01 seconds\n",
      "Epoch 98: 0.01 seconds\n",
      "Epoch 99: 0.01 seconds\n",
      "Epoch 100: 0.01 seconds\n",
      "Epoch 101: 0.01 seconds\n",
      "Epoch 102: 0.01 seconds\n",
      "Epoch 103: 0.01 seconds\n",
      "Epoch 104: 0.01 seconds\n",
      "Epoch 105: 0.01 seconds\n",
      "Epoch 106: 0.01 seconds\n",
      "Epoch 107: 0.01 seconds\n",
      "Epoch 108: 0.01 seconds\n",
      "Epoch 109: 0.01 seconds\n",
      "Epoch 110: 0.01 seconds\n",
      "Epoch 111: 0.01 seconds\n",
      "Epoch 112: 0.01 seconds\n",
      "Epoch 113: 0.01 seconds\n",
      "Epoch 114: 0.01 seconds\n",
      "Epoch 115: 0.01 seconds\n",
      "Epoch 116: 0.01 seconds\n",
      "Epoch 117: 0.01 seconds\n",
      "Epoch 118: 0.01 seconds\n",
      "Epoch 119: 0.01 seconds\n",
      "Epoch 120: 0.01 seconds\n",
      "Epoch 121: 0.01 seconds\n",
      "Epoch 122: 0.01 seconds\n",
      "Epoch 123: 0.01 seconds\n",
      "Epoch 124: 0.01 seconds\n",
      "Epoch 125: 0.01 seconds\n",
      "Epoch 126: 0.01 seconds\n",
      "Epoch 127: 0.01 seconds\n",
      "Epoch 128: 0.01 seconds\n",
      "Epoch 129: 0.01 seconds\n",
      "Epoch 130: 0.01 seconds\n",
      "Epoch 131: 0.01 seconds\n",
      "Epoch 132: 0.01 seconds\n",
      "Epoch 133: 0.01 seconds\n",
      "Epoch 134: 0.01 seconds\n",
      "Epoch 135: 0.01 seconds\n",
      "Epoch 136: 0.01 seconds\n",
      "Epoch 137: 0.01 seconds\n",
      "Epoch 138: 0.01 seconds\n",
      "Epoch 139: 0.01 seconds\n",
      "Epoch 140: 0.01 seconds\n",
      "Epoch 141: 0.01 seconds\n",
      "Epoch 142: 0.01 seconds\n",
      "Epoch 143: 0.01 seconds\n",
      "Epoch 144: 0.01 seconds\n",
      "Epoch 145: 0.01 seconds\n",
      "Epoch 146: 0.01 seconds\n",
      "Epoch 147: 0.01 seconds\n",
      "Epoch 148: 0.01 seconds\n",
      "Epoch 149: 0.01 seconds\n",
      "Epoch 150: 0.01 seconds\n",
      "Epoch 151: 0.01 seconds\n",
      "Epoch 152: 0.01 seconds\n",
      "Epoch 153: 0.01 seconds\n",
      "Epoch 154: 0.01 seconds\n",
      "Epoch 155: 0.01 seconds\n",
      "Epoch 156: 0.01 seconds\n",
      "Epoch 157: 0.01 seconds\n",
      "Epoch 158: 0.01 seconds\n",
      "Epoch 159: 0.01 seconds\n",
      "Epoch 160: 0.01 seconds\n",
      "Epoch 161: 0.01 seconds\n",
      "Epoch 162: 0.01 seconds\n",
      "Epoch 163: 0.01 seconds\n",
      "Epoch 164: 0.01 seconds\n",
      "Epoch 165: 0.01 seconds\n",
      "Epoch 166: 0.01 seconds\n",
      "Epoch 167: 0.01 seconds\n",
      "Epoch 168: 0.01 seconds\n",
      "Epoch 169: 0.01 seconds\n",
      "Epoch 170: 0.01 seconds\n",
      "Epoch 171: 0.01 seconds\n",
      "Epoch 172: 0.01 seconds\n",
      "Epoch 173: 0.01 seconds\n",
      "Epoch 174: 0.01 seconds\n",
      "Epoch 175: 0.01 seconds\n",
      "Epoch 176: 0.01 seconds\n",
      "Epoch 177: 0.01 seconds\n",
      "Epoch 178: 0.01 seconds\n",
      "Epoch 179: 0.01 seconds\n",
      "Epoch 180: 0.01 seconds\n",
      "Epoch 181: 0.01 seconds\n",
      "Epoch 182: 0.01 seconds\n",
      "Epoch 183: 0.01 seconds\n",
      "Epoch 184: 0.01 seconds\n",
      "Epoch 185: 0.01 seconds\n",
      "Epoch 186: 0.01 seconds\n",
      "Epoch 187: 0.01 seconds\n",
      "Epoch 188: 0.01 seconds\n",
      "Epoch 189: 0.01 seconds\n",
      "Epoch 190: 0.01 seconds\n",
      "Epoch 191: 0.01 seconds\n",
      "Epoch 192: 0.01 seconds\n",
      "Epoch 193: 0.01 seconds\n",
      "Epoch 194: 0.01 seconds\n",
      "Epoch 195: 0.01 seconds\n",
      "Epoch 196: 0.01 seconds\n",
      "Epoch 197: 0.01 seconds\n",
      "Epoch 198: 0.01 seconds\n",
      "Epoch 199: 0.01 seconds\n",
      "Epoch 200: 0.01 seconds\n",
      "Total optimization time by MCMC: 84.48 seconds\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dbb0cd7235260491"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
