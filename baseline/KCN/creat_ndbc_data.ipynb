{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from argument import parse_opt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw=np.load('all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(\"D:\\Spatial_interpolation\\SSIN\\data\\Station_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creat data with stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=stations[\"lat\"]\n",
    "lon=stations[\"lon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=list(lat)\n",
    "lon=list(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X_raw.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    x[i].append(lat)\n",
    "    x[i].append(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 20, 103)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    X[i]=X[i].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=X[0][[5,6,7,8,9,10,18,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_data = np.any(np.isnan(xx), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = np.where(columns_with_missing_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.delete(xx, missing_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=result[[1,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]]\n",
    "x_train=np.transpose(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]]\n",
    "y_train = y_train[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=result[[1,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test[:,[31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56]]\n",
    "x_test=np.transpose(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[[31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56]]\n",
    "y_test = y_test[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A dataset class for spatial data.\"\"\"\n",
    "\n",
    "    def __init__(self, coords, features, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coords: tensor with shape `(n, 2)`, coordinates of `n` instances\n",
    "            features: tensor with shape `(n, d)`, `d` dimensional feature vectors of `n` instances\n",
    "            y: tensor with shape `(n, )`, labels of `n` instances. Please provide zeros if unknown. \n",
    "            neighbors: tensor with shape `(n, num_neighbors)`, neighbors in an external training set. \n",
    "                       It can be none and computed later.  \n",
    "        \"\"\"\n",
    "        super(SpatialDataset, self).__init__()\n",
    "\n",
    "        if coords.shape[0] != features.shape[0] or features.shape[0] != y.shape[0]:\n",
    "            raise Exception(f\"Coordinates, features, and labels have different numbers of instances: \\\n",
    "                             coords.shape[0]={coords.shape[0]}, features.shape[0]={features.shape[0]}, \\\n",
    "                             y.shape[0]={y.shape[0]}\")\n",
    "\n",
    "        \n",
    "        self.coords = torch.Tensor(coords)\n",
    "        self.features = torch.Tensor(features)\n",
    "        self.y = torch.Tensor(y) \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.coords.shape[0] \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ins = (self.coords[idx], self.features[idx], self.y[idx])\n",
    "\n",
    "        return ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bird_count_data(X_train,Y_train,X_test,Y_test,args):\n",
    "    \"\"\"\n",
    "     Load data for training and testing\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    args : will use three fields, args.dataset, args.data_path, args.random_seed  \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords    : np.ndarray, shape (N, 2), coordinates of the data points\n",
    "    features  : np.ndarray, shape (N, D), features of the data points\n",
    "    y         : np.ndarray, shape (N, 1), labels of the data points\n",
    "    num_total_train : int, number of training data points. The first `num_total_train` \n",
    "                of instances from three other return values should form the training set\n",
    "    \"\"\"\n",
    "\n",
    "    # # data file path\n",
    "    # datafile = os.path.join(args.data_path, args.dataset + \".npz\")\n",
    "\n",
    "    # # download data if not finding it\n",
    "    # if not os.path.isfile(datafile):  \n",
    "    #     raise Exception(f\"Data file {datafile} not found. Please download the dataset from https://tufts.box.com/v/kcn-bird-count-dataset and save it to ./datasets/bird_count.npz\")\n",
    "\n",
    "    # load the data\n",
    "    # data = np.load(datafile)\n",
    "    # X_train = np.ndarray.astype(data['Xtrain'], np.float32)\n",
    "    # Y_train = data['Ytrain'].astype(np.float32)\n",
    "    # Y_train = Y_train[:, None]\n",
    "    # X_test = np.ndarray.astype(data['Xtest'], np.float32)\n",
    "    # Y_test = data['Ytest'].astype(np.float32)\n",
    "    # Y_test = Y_test[:, None]\n",
    "\n",
    "\n",
    "\n",
    "    num_total_train = X_train.shape[0]\n",
    "\n",
    "    # check and record shapes\n",
    "    assert (X_train.shape[0] == Y_train.shape[0])\n",
    "    assert (X_test.shape[0] == Y_test.shape[0])\n",
    "\n",
    "    if args.use_default_test_set:\n",
    "        print(\"Using the default test set from the data\") \n",
    "        trainset = SpatialDataset(coords=X_train[:, 19:21], features=X_train, y=Y_train) \n",
    "        testset = SpatialDataset(coords=X_test[:, 19:21], features=X_test, y=Y_test)\n",
    "    else:\n",
    "        X = np.concatenate([X_train, X_test], axis=0)\n",
    "        Y = np.concatenate([Y_train, Y_test], axis=0)\n",
    "\n",
    "        perm = np.random.RandomState(seed=args.random_seed).permutation(X.shape[0])\n",
    "\n",
    "        # include coordinates in features\n",
    "        trainset = SpatialDataset(coords=X[perm[0:num_total_train], 0:2], features=X[perm[0:num_total_train]], y=Y[perm[0:num_total_train]]) \n",
    "        testset = SpatialDataset(coords=X[perm[num_total_train:], 0:2], features=X[perm[num_total_train:]], y=Y[perm[num_total_train:]])\n",
    "\n",
    "    # feature normalization\n",
    "    feature_mean = torch.mean(trainset.features, axis=0, keepdims=True)\n",
    "    feature_std = torch.std(trainset.features, axis=0, keepdims=True)\n",
    "\n",
    "    trainset.features = (trainset.features - feature_mean) / (feature_std + 0.01)\n",
    "    testset.features = (testset.features - feature_mean) / (feature_std + 0.01)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=load_bird_count_data(x_train,y_train,x_test,y_test,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 7)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 31)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:, None]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
