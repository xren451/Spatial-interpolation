{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geographiclib.geodesic import Geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    " \n",
    "def generate_random_array(length):\n",
    "    array = []\n",
    "    for _ in range(length):\n",
    "        array.append(random.randint(0, 1))\n",
    "    return array\n",
    " \n",
    "# 生成长度为10的随机数组\n",
    "random_array = generate_random_array(10)\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw=np.load('data/all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 18, 103)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 103)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=5\n",
    "train_data=X_raw[:,j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_data = np.any(np.isnan(train_data), axis=0)\n",
    "missing_columns = np.where(columns_with_missing_data)[0]\n",
    "result = np.delete(train_data, missing_columns, axis=1)\n",
    "# result = (result - np.min(result)) / (np.max(result) - np.min(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 34, 38, 49, 50, 55, 56, 73, 81, 83], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 93)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = result.mean(axis=0)\n",
    "std = result.std(axis=0)\n",
    "result = (result - mean) / (std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_list=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71]\n",
    "# train_list=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]\n",
    "# test_list=[52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76]\n",
    "test_list=[72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=result[:,train_list]\n",
    "test_data=result[:,test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "test_data = np.expand_dims(test_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 72, 1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 21, 1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.transpose(train_data, (0, 2, 1))\n",
    "# test_data = np.transpose(test_data, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.reshape(train_data, (8784, 41,1))\n",
    "# test_data = np.reshape(test_data, (8784, 52,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestap_list=[0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestap=X_raw[:,timestap_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestap=timestap.astype(np.int32)\n",
    "timestap=timestap.astype(np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(timestap)):\n",
    "    for m in range(1,4):\n",
    "        timestap[i,m,1]=timestap[i,m,1].zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestap=timestap[:,:,1]\n",
    "timestap_result=[]\n",
    "for i in range(len(timestap)):\n",
    "    x=timestap[i,0]+timestap[i,1]+timestap[i,2]+'-'+timestap[i,3]\n",
    "    timestap_result.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestap_result=np.array(timestap_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestap_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invid_mask掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate1_random_array(length):\n",
    "    array = []\n",
    "    for _ in range(length):\n",
    "        array.append(False)\n",
    "    return np.array(array)\n",
    " \n",
    "# 生成长度为10的随机数组\n",
    "train_invid_mask=[]\n",
    "test_invid_mask=[]\n",
    "for i in range(len(timestap)):\n",
    "    random_array = generate1_random_array(train_data.shape[1])\n",
    "    random_array1 = generate1_random_array(test_data.shape[1])\n",
    "    train_invid_mask.append(random_array)\n",
    "    test_invid_mask.append(random_array1)\n",
    "train_invid_mask=np.array(train_invid_mask)\n",
    "test_invid_mask=np.array(test_invid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_mask掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "def generate_random_array(length):\n",
    "    array = []\n",
    "    for _ in range(length):\n",
    "            array.append(random.choice([False,True]))\n",
    "    return np.array(array)\n",
    "\n",
    "# 生成长度为10的随机数组\n",
    "test_mask=[]\n",
    "random_array=generate_random_array(test_data.shape[1])\n",
    "for i in range(len(timestap)):\n",
    "    test_mask.append(random_array)\n",
    "test_mask=np.array(test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 地理位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建r_pos_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(\"D:\\Spatial_interpolation\\SSIN\\data\\Station_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.drop([0, 34, 38, 49, 50, 55, 56, 73, 81, 83],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=stations.iloc[0:72]\n",
    "df_test=stations.iloc[72:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_angle_mat(df, out_path):\n",
    "    lons, lats = df[\"lon\"].values, df[\"lat\"].values\n",
    "    dist_angle_mat = np.zeros((len(lons), len(lons), 2))\n",
    "\n",
    "    for i in range(len(lons)):\n",
    "        for j in range(len(lons)):\n",
    "            dist = Geodesic.WGS84.Inverse(lats[i], lons[i], lats[j], lons[j])\n",
    "            dist_angle_mat[i, j, 0] = dist[\"s12\"] / 1000.0  # distance, km\n",
    "            dist_angle_mat[i, j, 1] = dist[\"azi1\"]  # azimuth at the first point in degrees\n",
    "\n",
    "    print(dist_angle_mat.shape)\n",
    "    # print(dist_angle_mat)\n",
    "    np.save(out_path, dist_angle_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 72, 2)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"../data\"\n",
    "\n",
    "    # HK dataset\n",
    "    # info_path = f\"{base_dir}/HK_123_data/hko_stations_info.csv\"\n",
    "    # out_dir = f\"{base_dir}\"\n",
    "\n",
    "    # BW dataset\n",
    "    # info_path = f\"{base_dir}/BW_132_data/BW_stations_info.csv\"\n",
    "    out_dir = f\"{base_dir}\"\n",
    "\n",
    "    # os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_name = \"dist_angle_mat_train.npy\"\n",
    "    out_path = f\"{out_dir}/{out_name}\"\n",
    "    calc_dist_angle_mat(df_train, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 21, 2)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"../data\"\n",
    "\n",
    "    # HK dataset\n",
    "    # info_path = f\"{base_dir}/HK_123_data/hko_stations_info.csv\"\n",
    "    out_dir = f\"{base_dir}\"\n",
    "\n",
    "    # BW dataset\n",
    "    # info_path = f\"{base_dir}/BW_132_data/BW_stations_info.csv\"\n",
    "    # out_dir = f\"{base_dir}/BW_132_data\"\n",
    "\n",
    "    # os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_name = \"dist_angle_mat_test.npy\"\n",
    "    out_path = f\"{out_dir}/{out_name}\"\n",
    "    calc_dist_angle_mat(df_test, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stat_from_train_data(train_info_df, r_pos_mat):\n",
    "    # info_df = pd.read_csv(info_path)\n",
    "    # ori_r_pos_mat = np.load(relative_pos_mat_path)\n",
    "\n",
    "    # is_test = info_df[\"is_test\"].values\n",
    "    # train_mask = np.where(is_test == 0, True, False)\n",
    "    # train_info_df = info_df.loc[train_mask, :]\n",
    "\n",
    "    lat_mean, lat_std, lat_max, lat_min = train_info_df[\"lat\"].mean(), train_info_df[\"lat\"].std(ddof=0), \\\n",
    "                                          train_info_df[\"lat\"].max(), train_info_df[\"lat\"].min()\n",
    "    lon_mean, lon_std, lon_max, lon_min = train_info_df[\"lon\"].mean(), train_info_df[\"lon\"].std(ddof=0), \\\n",
    "                                          train_info_df[\"lon\"].max(), train_info_df[\"lon\"].min()\n",
    "\n",
    "    # indexes = np.where(train_mask)[0]\n",
    "    # idx_i, idx_j = np.ix_(indexes, indexes)\n",
    "    # r_pos_mat = ori_r_pos_mat[idx_i, idx_j, :]\n",
    "\n",
    "    r_dist_mat = r_pos_mat[:, :, 0]\n",
    "    r_angle_mat = r_pos_mat[:, :, 1]\n",
    "\n",
    "    r_dist_mean, r_dist_std, r_dist_max, r_dist_min = np.mean(r_dist_mat), np.std(r_dist_mat), \\\n",
    "                                                      np.max(r_dist_mat), np.min(r_dist_mat),\n",
    "    r_angle_mean, r_angle_std, r_angle_max, r_angle_min = np.mean(r_angle_mat), np.std(r_angle_mat), \\\n",
    "                                                          np.max(r_angle_mat), np.min(r_angle_mat)\n",
    "\n",
    "    stat_dict = {}\n",
    "    stat_dict[\"lat_mean\"], stat_dict[\"lat_std\"], stat_dict[\"lat_max\"], stat_dict[\"lat_min\"] = \\\n",
    "        lat_mean, lat_std, lat_max, lat_min\n",
    "    stat_dict[\"lon_mean\"], stat_dict[\"lon_std\"], stat_dict[\"lon_max\"], stat_dict[\"lon_min\"] = \\\n",
    "        lon_mean, lon_std, lon_max, lon_min\n",
    "\n",
    "    stat_dict[\"r_dist_mean\"], stat_dict[\"r_dist_std\"], stat_dict[\"r_dist_max\"], stat_dict[\"r_dist_min\"] = \\\n",
    "        r_dist_mean, r_dist_std, r_dist_max, r_dist_min\n",
    "    stat_dict[\"r_angle_mean\"], stat_dict[\"r_angle_std\"], stat_dict[\"r_angle_max\"], stat_dict[\"r_angle_min\"] = \\\n",
    "        r_angle_mean, r_angle_std, r_angle_max, r_angle_min\n",
    "\n",
    "    print(\"Calculates the statistics of training data. Done!\")\n",
    "\n",
    "    # with open(\"./data/hk_data_stats.pkl\".format(out_name), \"wb\") as fp:\n",
    "    #     pickle.dump(stat_dict, fp)\n",
    "\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=np.load(\"D:\\Spatial_interpolation\\data\\dist_angle_mat_train.npy\")\n",
    "test_df=np.load(\"D:\\Spatial_interpolation\\data\\dist_angle_mat_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculates the statistics of training data. Done!\n"
     ]
    }
   ],
   "source": [
    "stat_dict=generate_stat_from_train_data(df_train, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df[:, :, 0] = (train_df[:, :, 0] - stat_dict[\"r_dist_mean\"]) / stat_dict[\"r_dist_std\"]\n",
    "train_df[:, :, 1] = (train_df[:, :, 1] - stat_dict[\"r_angle_mean\"]) / stat_dict[\"r_angle_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[:, :, 0] = (test_df[:, :, 0] - stat_dict[\"r_dist_mean\"]) / stat_dict[\"r_dist_std\"]\n",
    "test_df[:, :, 1] = (test_df[:, :, 1] - stat_dict[\"r_angle_mean\"]) / stat_dict[\"r_angle_std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建最后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test={\"test_data\":test_data,\"invalid_masks\":test_invid_mask,\"test_masks\":test_mask,\"r_pos_mat\":test_df,\"timestamps\":timestap_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train={\"train_data\":train_data,\"invalid_masks\":train_invid_mask,\"r_pos_mat\":train_df,\"timestamps\":timestap_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data', 'invalid_masks', 'test_masks', 'r_pos_mat', 'timestamps']\n"
     ]
    }
   ],
   "source": [
    "print(list(test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_data', 'invalid_masks', 'r_pos_mat', 'timestamps']\n"
     ]
    }
   ],
   "source": [
    "print(list(train.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "\n",
    "\n",
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# data = pd.read_pickle(\"2012-2014_data_train.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bw_train = pd.read_pickle(\"2012-2014_data_bw_train.pkl\")\n",
    "# data_bw_test = pd.read_pickle(\"2012-2014_data_bw_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_data', 'invalid_masks', 'test_masks', 'r_pos_mat', 'timestamps'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_data', 'invalid_masks', 'test_masks', 'r_pos_mat', 'timestamps'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_bw_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 132, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_bw_train[\"r_pos_mat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 41)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[\"invalid_masks\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
